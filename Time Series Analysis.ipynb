{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "370529cb-7968-47ac-a7fc-2568fa6ce72c",
   "metadata": {},
   "source": [
    "### Week 13: Time Series Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a55030-ffb6-4cdf-99cf-293f864f690e",
   "metadata": {},
   "source": [
    "Time Series Forecasting\n",
    "\n",
    "Time series forecasting occurs when you make scientific predictions based on historical time stamped data. \n",
    "\n",
    "It involves building models through historical analysis and using them to make observations and drive future strategic decision-making.\n",
    "\n",
    "An important distinction in forecasting is that at the time of the work, the future outcome is completely unavailable and can only be estimated through careful analysis and evidence-based priors.\n",
    "\n",
    "Types of models to use\n",
    "\n",
    "​\n",
    "ARIMA\n",
    "moving average( PACF)\n",
    "\n",
    "​\n",
    "auto regressive and intergrated moving average ( ACF for moving average)\n",
    "\n",
    "​\n",
    "base line model \n",
    "you can check whether base line or ARIMA model is better \n",
    "​\n",
    "Diference between machine learning and time series. \n",
    "\n",
    "Time series has to do with trends and seasons and it has just two few columns and it does not deal on dependent and independent variable.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "install the prediction on a list so as to test it\n",
    "\n",
    ".\n",
    "trends are patterns , we have upward and downward trend.\n",
    "\n",
    "5 ,3-6 and you put it in a loop.\n",
    "\n",
    "size dont have a bracket \n",
    "sampoo.size and shape are characterictics of the data,so they dont carry bracket\n",
    "\n",
    "​\n",
    "Sampoo.describe() is a function and you can manipulate it. \n",
    "​\n",
    "We smoothen our time series using the moving average\n",
    "​\n",
    "it uses the rolling function to achieve it\n",
    "\n",
    "​\n",
    "for e.g you choose 5 windows, ti will find the average of the 5 and plot the average as the point so as to have a smoother time series.\n",
    "\n",
    "​\n",
    "shift () shift the index by desired number  using the base line model. base model is an initial model, when we now access other models we can now choose to accept it or reject it.\n",
    "\n",
    "​\n",
    "We concatinate ie combine \n",
    "\n",
    "​\n",
    "THe drop any function is temporary, if you want it to be permament, you need to put inplace=True else if you run the code again ,it will return to the old code.\n",
    "\n",
    "​\n",
    "we now import the mean square metrics to calculate the error\n",
    "​\n",
    "We will implement the square root to give us our error\n",
    "\n",
    "​\n",
    "Auto regressive intergrated moving average (ARIMA)\n",
    "\n",
    "​\n",
    "ACF : Auto regression\n",
    "\n",
    "​\n",
    "PCAF  : Moving Average\n",
    "intergrated \n",
    "\n",
    "p auto regression\n",
    "\n",
    "d is the degree of differential\n",
    "\n",
    "​\n",
    "Moving average is the auto correllation\n",
    "in a situation you dont know the pvalue to use , you can use a range 0-5 ,6-10 and you put it in a loop.\n",
    "\n",
    "A baseline model is essentially a simple model that acts as a reference in a machine learning project.\n",
    "Its main function is to contextualize the results of trained models. Baseline models usually lack complexity and may have little predictive power. Regardless, their inclusion is a necessity for many reasons\n",
    "\n",
    "The CONCAT function combines the text from multiple ranges and/or strings, but it doesn't provide delimiter or IgnoreEmpty arguments. CONCAT replaces the CONCATENATE function. However, the CONCATENATE function will stay available for compatibility with earlier versions of Excel.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4626a0aa-3e59-4874-b4ae-8adcd627c8bf",
   "metadata": {},
   "source": [
    "We will be looking at the new dataset for forecasting and analyzing it within the python.\n",
    "we use pandas for the import of dataset\n",
    "we use matplotlib.pyplot to plot the data\n",
    "we use %matplotlib inline for graphiics like line chart within the command language.\n",
    "\n",
    "The %matplotlib inline enables “inline plotting”, where plotted graphics appear in your notebook. Suppose we want to draw a simple line graph using the following code. The code works fine, but it doesn't show the line graph inline with the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a23239-270d-426e-a753-3959724dc368",
   "metadata": {},
   "source": [
    "##### import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1d485c2-4b96-42ba-8402-b2c63496d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46f9bd5-cd12-479f-91e0-fc427e9e293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shampoo = pd.read_csv(\"C:\\\\Users\\\\user\\\\Downloads\\\\Shampoo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1eab2c2-0536-497d-8853-622279332961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-01</td>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-02</td>\n",
       "      <td>145.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-03</td>\n",
       "      <td>183.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-04</td>\n",
       "      <td>119.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-05</td>\n",
       "      <td>180.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Month  Sales\n",
       "0  1-01  266.0\n",
       "1  1-02  145.9\n",
       "2  1-03  183.1\n",
       "3  1-04  119.3\n",
       "4  1-05  180.3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shampoo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3f99bb5-27d1-4659-9894-f440729d0efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(shampoo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da0e21-f136-440c-8a16-1a2b26c637d9",
   "metadata": {},
   "source": [
    "How you can import a csv file as a time series dataset? To check your knowledge on data manipulation process.\n",
    "\n",
    "first, we need to keep our index as month because once we do that, we can do a better manipulation of the data, lets say you want to saerch for only  month two , we first do month 1, 01 , month 2 ,02 and we continuue to th last month, but we can do a better manipulation if we have the months through the index.\n",
    "\n",
    "we need to make suer this is going into series instead of data frame\n",
    "so after passing the pd.file we include ,index_col=[0],parse_dates=True ( we are specifying that there is a date column and we want it to be a property, and then the imported  parameter which will convert it into the time series  squeeze=True, by default is false but i want it to be true\n",
    "If you want to see all the parameters , just press shift+ tab tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3818eed-9afd-49f6-ada5-a7328d740e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shampoo = pd.read_csv(\"C:\\\\Users\\\\user\\\\Downloads\\\\Shampoo.csv\",index_col=[0],parse_dates=True,squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1db0df1f-479b-4678-9adc-9e864957c571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(shampoo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e196a3f-f1ce-4c9e-ad3a-08150d51ad56",
   "metadata": {},
   "source": [
    "Now it is pandas series instead of dataframe.\n",
    "\n",
    "+ Interview question when you are importing dataframe how you can convert it to time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d47f4b-e0f9-4f6b-bf1d-0816470ba2f7",
   "metadata": {},
   "source": [
    "+ Next, is how to plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "903a4333-f20d-4869-b0f8-e8f021c76a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Month'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shampoo.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167df61a-4999-4d98-a8b6-21962230711b",
   "metadata": {},
   "source": [
    "is a clear variation that a trend is present.\n",
    "You can as well decide to show just the lines with dot or circles use shampoo.plot(style = 'k.')\n",
    "sometimes, the dot representation is an easier one an sometimes the line representation is. But here we didint specify the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32656bda-f186-4223-83b0-398483cb1a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Month'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shampoo.plot(style = 'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fe75211-b9bd-45eb-b150-d3f1a4c1ab0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To find out how many datpoints it has\n",
    "shampoo.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b7f1e1d-84e3-49fa-b20d-82deaaf2e8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     36.000000\n",
       "mean     312.600000\n",
       "std      148.937164\n",
       "min      119.300000\n",
       "25%      192.450000\n",
       "50%      280.150000\n",
       "75%      411.100000\n",
       "max      682.000000\n",
       "Name: Sales, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use describe function to find out the statistics of the data point\n",
    "shampoo.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d57042-dc77-4dd2-bb3e-32c3b3126eff",
   "metadata": {},
   "source": [
    "describe () is a method but shamoo.size is a property\n",
    "\n",
    "Interview Question\n",
    "What is the difference betww\\een mean and median?\n",
    "mean is taking all the value and dividing by th ecount of value \n",
    "median is the middle value or 50% in an ordered list, first you need to put evert thing in an order, It should be an ordered list.\n",
    "\n",
    "The mean (average) of a data set is found by adding all numbers in the data set and then dividing by the number of values in the set. The median is the middle value when a data set is ordered from least to greatest. The mode is the number that occurs most often in a data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67925656-3585-4bf4-ba70-0cbce58c144f",
   "metadata": {},
   "source": [
    "+ Interview question: In which scenario will you use mean or median\n",
    "\n",
    "\n",
    "It’s best to use the mean to describe the center of a dataset when the distribution is mostly symmetrical and there are no outliers.\n",
    "\n",
    "When the data are skewed, the median is more useful because the mean will be distorted by outliers.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba11ebb-03f6-46ca-949c-965f07888e8b",
   "metadata": {},
   "source": [
    "Both the mean and the median can be used to describe where the “center” of a dataset is located.\n",
    "\n",
    "It’s best to use the mean when the distribution of the data values is symmetrical and there are no clear outliers.\n",
    "\n",
    "It’s best to use the median when the the distribution of data values is skewed or when there are clear outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5266cc2-c5d5-49e3-957e-712278583072",
   "metadata": {},
   "source": [
    "Mode is the most distributed value in the column.\n",
    "These are measures of central tendency in statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aea151-52a1-4a40-b6cf-3e2dd058ca50",
   "metadata": {},
   "source": [
    "Next is smothing of time series , which means calculating the moving average.\n",
    "\n",
    "window = means how many days moving average do you want to use ,5 or 6 days moving average , here we will use 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c05fec28-b1b1-4f31-9b51-babd1673d231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a moving average\n",
    "shampoo_ma = shampoo.rolling(window=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ebff684-bcc5-4cc7-8862-9b8d86fabd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Month'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shampoo_ma.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c849a3-0c56-493a-a9e1-91dd7497fe6f",
   "metadata": {},
   "source": [
    "Some of the values have gone we used 10 , the values started from 10, 11, 12 ,13 etc.\n",
    "This a very smooth as compared to the first one.\n",
    "So if it is not very clear, you can use the moving average.\n",
    "\n",
    "This is highly used in the stock market analysis and some business studies\n",
    "\n",
    "+ Interview question : How can you create a moving average? \n",
    "what is the down side of having a large window side and what is standard window sidze to create"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763835f7-8831-4935-acb7-885a8ef574f7",
   "metadata": {},
   "source": [
    "Next, we create a base line model\n",
    "Interview qestion: what is a base line model or naive or starting model or initial model?\n",
    "They are all command lines\n",
    "\n",
    "This means defining your base line\n",
    "It means below this , if there is any model just remove it.\n",
    "\n",
    "The assumption behind it is that the previous value is the best reflector of the next value.\n",
    "\n",
    "so for 266, 1-02 ie 2nd jan, the best predictor or reflector of the naive or base model is the previous value, so for second , it will be 266 , for 3rd jan ,it will be 145 and for 4th jan  it will be 183.1.\n",
    "\n",
    "What it basically assumes is that the previous values are related to the current values.\n",
    "What we have observed on the last day is going to reflect in the current ,even some more variation. with this assumption into the time series , we go ahead and create the naive or baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38c9bfe1-6515-432c-930e-cf313b97df93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Month\n",
       "1-01    266.0\n",
       "1-02    145.9\n",
       "1-03    183.1\n",
       "1-04    119.3\n",
       "1-05    180.3\n",
       "1-06    168.5\n",
       "1-07    231.8\n",
       "1-08    224.5\n",
       "1-09    192.8\n",
       "1-10    122.9\n",
       "1-11    336.5\n",
       "1-12    185.9\n",
       "2-01    194.3\n",
       "2-02    149.5\n",
       "2-03    210.1\n",
       "2-04    273.3\n",
       "2-05    191.4\n",
       "2-06    287.0\n",
       "2-07    226.0\n",
       "2-08    303.6\n",
       "2-09    289.9\n",
       "2-10    421.6\n",
       "2-11    264.5\n",
       "2-12    342.3\n",
       "3-01    339.7\n",
       "3-02    440.4\n",
       "3-03    315.9\n",
       "3-04    439.3\n",
       "3-05    401.3\n",
       "3-06    437.4\n",
       "3-07    575.5\n",
       "3-08    407.6\n",
       "3-09    682.0\n",
       "3-10    475.3\n",
       "3-11    581.3\n",
       "3-12    646.9\n",
       "Name: Sales, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shampoo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a059eac-277c-4d06-b2d4-93acfa90dcb1",
   "metadata": {},
   "source": [
    "To create the baseline, we will be using the shift method , this is because the shift method helps to shift the datapoint down\n",
    "We will be using the concat method to do this , because we are not going to creat a seperate column all together rather we will contatinate ie to create a multiple dataset.\n",
    "\n",
    "shampe,shamppp.shift(1) ,axis=1 , means to put the shift down by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e65e9806-5455-40ab-9d38-6f1394afb5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shampoo_base = pd.concat([shampoo,shampoo.shift(1)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "719c36fc-cc44-4489-9bb5-51ec057317dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-01</th>\n",
       "      <td>266.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-02</th>\n",
       "      <td>145.9</td>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-03</th>\n",
       "      <td>183.1</td>\n",
       "      <td>145.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-04</th>\n",
       "      <td>119.3</td>\n",
       "      <td>183.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-05</th>\n",
       "      <td>180.3</td>\n",
       "      <td>119.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-06</th>\n",
       "      <td>168.5</td>\n",
       "      <td>180.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-07</th>\n",
       "      <td>231.8</td>\n",
       "      <td>168.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-08</th>\n",
       "      <td>224.5</td>\n",
       "      <td>231.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-09</th>\n",
       "      <td>192.8</td>\n",
       "      <td>224.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-10</th>\n",
       "      <td>122.9</td>\n",
       "      <td>192.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-11</th>\n",
       "      <td>336.5</td>\n",
       "      <td>122.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-12</th>\n",
       "      <td>185.9</td>\n",
       "      <td>336.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-01</th>\n",
       "      <td>194.3</td>\n",
       "      <td>185.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-02</th>\n",
       "      <td>149.5</td>\n",
       "      <td>194.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-03</th>\n",
       "      <td>210.1</td>\n",
       "      <td>149.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-04</th>\n",
       "      <td>273.3</td>\n",
       "      <td>210.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-05</th>\n",
       "      <td>191.4</td>\n",
       "      <td>273.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-06</th>\n",
       "      <td>287.0</td>\n",
       "      <td>191.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-07</th>\n",
       "      <td>226.0</td>\n",
       "      <td>287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-08</th>\n",
       "      <td>303.6</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-09</th>\n",
       "      <td>289.9</td>\n",
       "      <td>303.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-10</th>\n",
       "      <td>421.6</td>\n",
       "      <td>289.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-11</th>\n",
       "      <td>264.5</td>\n",
       "      <td>421.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-12</th>\n",
       "      <td>342.3</td>\n",
       "      <td>264.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-01</th>\n",
       "      <td>339.7</td>\n",
       "      <td>342.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-02</th>\n",
       "      <td>440.4</td>\n",
       "      <td>339.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-03</th>\n",
       "      <td>315.9</td>\n",
       "      <td>440.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-04</th>\n",
       "      <td>439.3</td>\n",
       "      <td>315.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-05</th>\n",
       "      <td>401.3</td>\n",
       "      <td>439.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-06</th>\n",
       "      <td>437.4</td>\n",
       "      <td>401.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-07</th>\n",
       "      <td>575.5</td>\n",
       "      <td>437.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-08</th>\n",
       "      <td>407.6</td>\n",
       "      <td>575.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-09</th>\n",
       "      <td>682.0</td>\n",
       "      <td>407.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-10</th>\n",
       "      <td>475.3</td>\n",
       "      <td>682.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-11</th>\n",
       "      <td>581.3</td>\n",
       "      <td>475.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-12</th>\n",
       "      <td>646.9</td>\n",
       "      <td>581.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sales  Sales\n",
       "Month              \n",
       "1-01   266.0    NaN\n",
       "1-02   145.9  266.0\n",
       "1-03   183.1  145.9\n",
       "1-04   119.3  183.1\n",
       "1-05   180.3  119.3\n",
       "1-06   168.5  180.3\n",
       "1-07   231.8  168.5\n",
       "1-08   224.5  231.8\n",
       "1-09   192.8  224.5\n",
       "1-10   122.9  192.8\n",
       "1-11   336.5  122.9\n",
       "1-12   185.9  336.5\n",
       "2-01   194.3  185.9\n",
       "2-02   149.5  194.3\n",
       "2-03   210.1  149.5\n",
       "2-04   273.3  210.1\n",
       "2-05   191.4  273.3\n",
       "2-06   287.0  191.4\n",
       "2-07   226.0  287.0\n",
       "2-08   303.6  226.0\n",
       "2-09   289.9  303.6\n",
       "2-10   421.6  289.9\n",
       "2-11   264.5  421.6\n",
       "2-12   342.3  264.5\n",
       "3-01   339.7  342.3\n",
       "3-02   440.4  339.7\n",
       "3-03   315.9  440.4\n",
       "3-04   439.3  315.9\n",
       "3-05   401.3  439.3\n",
       "3-06   437.4  401.3\n",
       "3-07   575.5  437.4\n",
       "3-08   407.6  575.5\n",
       "3-09   682.0  407.6\n",
       "3-10   475.3  682.0\n",
       "3-11   581.3  475.3\n",
       "3-12   646.9  581.3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shampoo_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaf1136-c797-4d0b-a33d-5a4f13798291",
   "metadata": {},
   "source": [
    "The strcture of our naive or base line is created\n",
    "Now we will need to remove the nan value because if we dont ,it will give an error when we evaluate the error matric but before that we will need to give a name to the two columns.\n",
    "\n",
    "We will need to rename the columns\n",
    "\n",
    "+ INTERVIEW QUESTION\n",
    "How do you rename the column\n",
    "data manipulation techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dd9fe65-76fe-4bd7-a293-d8dcf4886d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sales', 'Sales'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shampoo_base.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61847861-fa37-4d6d-bae0-1c3189a9cebe",
   "metadata": {},
   "source": [
    "We wil be using the same methodology above, we will just specify the new names we got as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a4f1a0f-3ba6-4a3c-8be4-ba4037892578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To rename the columns\n",
    "shampoo_base.columns = ['Actual_sales', 'Forecast_sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b70b464-1f6e-408f-95ef-373dd79fc6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual_sales</th>\n",
       "      <th>Forecast_sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-01</th>\n",
       "      <td>266.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-02</th>\n",
       "      <td>145.9</td>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-03</th>\n",
       "      <td>183.1</td>\n",
       "      <td>145.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-04</th>\n",
       "      <td>119.3</td>\n",
       "      <td>183.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-05</th>\n",
       "      <td>180.3</td>\n",
       "      <td>119.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual_sales  Forecast_sales\n",
       "Month                              \n",
       "1-01          266.0             NaN\n",
       "1-02          145.9           266.0\n",
       "1-03          183.1           145.9\n",
       "1-04          119.3           183.1\n",
       "1-05          180.3           119.3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shampoo_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3a5b1b5-0381-411a-9f99-1d6202566a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the NaN value\n",
    "# if you use this the NaN value will drop but when \n",
    "# you chech with shampp_base you will notice that the\n",
    "# missing value have come back\n",
    "#shampoo_base.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23fa1605-37da-49d0-b3e1-e2daa09e533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shampoo_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c244b38e-e940-4a25-880a-523ac466bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So what you need so as to remove the NaN value parmanently is dropna(inplace =True)\n",
    "# this saves your data\n",
    "shampoo_base.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fb08ffc-bfb7-407c-83f8-d69b9acb61ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual_sales</th>\n",
       "      <th>Forecast_sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-02</th>\n",
       "      <td>145.9</td>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-03</th>\n",
       "      <td>183.1</td>\n",
       "      <td>145.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-04</th>\n",
       "      <td>119.3</td>\n",
       "      <td>183.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-05</th>\n",
       "      <td>180.3</td>\n",
       "      <td>119.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-06</th>\n",
       "      <td>168.5</td>\n",
       "      <td>180.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-07</th>\n",
       "      <td>231.8</td>\n",
       "      <td>168.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-08</th>\n",
       "      <td>224.5</td>\n",
       "      <td>231.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-09</th>\n",
       "      <td>192.8</td>\n",
       "      <td>224.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-10</th>\n",
       "      <td>122.9</td>\n",
       "      <td>192.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-11</th>\n",
       "      <td>336.5</td>\n",
       "      <td>122.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-12</th>\n",
       "      <td>185.9</td>\n",
       "      <td>336.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-01</th>\n",
       "      <td>194.3</td>\n",
       "      <td>185.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-02</th>\n",
       "      <td>149.5</td>\n",
       "      <td>194.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-03</th>\n",
       "      <td>210.1</td>\n",
       "      <td>149.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-04</th>\n",
       "      <td>273.3</td>\n",
       "      <td>210.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-05</th>\n",
       "      <td>191.4</td>\n",
       "      <td>273.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-06</th>\n",
       "      <td>287.0</td>\n",
       "      <td>191.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-07</th>\n",
       "      <td>226.0</td>\n",
       "      <td>287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-08</th>\n",
       "      <td>303.6</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-09</th>\n",
       "      <td>289.9</td>\n",
       "      <td>303.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-10</th>\n",
       "      <td>421.6</td>\n",
       "      <td>289.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-11</th>\n",
       "      <td>264.5</td>\n",
       "      <td>421.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-12</th>\n",
       "      <td>342.3</td>\n",
       "      <td>264.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-01</th>\n",
       "      <td>339.7</td>\n",
       "      <td>342.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-02</th>\n",
       "      <td>440.4</td>\n",
       "      <td>339.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-03</th>\n",
       "      <td>315.9</td>\n",
       "      <td>440.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-04</th>\n",
       "      <td>439.3</td>\n",
       "      <td>315.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-05</th>\n",
       "      <td>401.3</td>\n",
       "      <td>439.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-06</th>\n",
       "      <td>437.4</td>\n",
       "      <td>401.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-07</th>\n",
       "      <td>575.5</td>\n",
       "      <td>437.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-08</th>\n",
       "      <td>407.6</td>\n",
       "      <td>575.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-09</th>\n",
       "      <td>682.0</td>\n",
       "      <td>407.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-10</th>\n",
       "      <td>475.3</td>\n",
       "      <td>682.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-11</th>\n",
       "      <td>581.3</td>\n",
       "      <td>475.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-12</th>\n",
       "      <td>646.9</td>\n",
       "      <td>581.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual_sales  Forecast_sales\n",
       "Month                              \n",
       "1-02          145.9           266.0\n",
       "1-03          183.1           145.9\n",
       "1-04          119.3           183.1\n",
       "1-05          180.3           119.3\n",
       "1-06          168.5           180.3\n",
       "1-07          231.8           168.5\n",
       "1-08          224.5           231.8\n",
       "1-09          192.8           224.5\n",
       "1-10          122.9           192.8\n",
       "1-11          336.5           122.9\n",
       "1-12          185.9           336.5\n",
       "2-01          194.3           185.9\n",
       "2-02          149.5           194.3\n",
       "2-03          210.1           149.5\n",
       "2-04          273.3           210.1\n",
       "2-05          191.4           273.3\n",
       "2-06          287.0           191.4\n",
       "2-07          226.0           287.0\n",
       "2-08          303.6           226.0\n",
       "2-09          289.9           303.6\n",
       "2-10          421.6           289.9\n",
       "2-11          264.5           421.6\n",
       "2-12          342.3           264.5\n",
       "3-01          339.7           342.3\n",
       "3-02          440.4           339.7\n",
       "3-03          315.9           440.4\n",
       "3-04          439.3           315.9\n",
       "3-05          401.3           439.3\n",
       "3-06          437.4           401.3\n",
       "3-07          575.5           437.4\n",
       "3-08          407.6           575.5\n",
       "3-09          682.0           407.6\n",
       "3-10          475.3           682.0\n",
       "3-11          581.3           475.3\n",
       "3-12          646.9           581.3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shampoo_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8863cc3b-dd31-4fc7-aade-88c287426bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual_sales</th>\n",
       "      <th>Forecast_sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-02</th>\n",
       "      <td>145.9</td>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-03</th>\n",
       "      <td>183.1</td>\n",
       "      <td>145.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-04</th>\n",
       "      <td>119.3</td>\n",
       "      <td>183.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-05</th>\n",
       "      <td>180.3</td>\n",
       "      <td>119.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-06</th>\n",
       "      <td>168.5</td>\n",
       "      <td>180.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual_sales  Forecast_sales\n",
       "Month                              \n",
       "1-02          145.9           266.0\n",
       "1-03          183.1           145.9\n",
       "1-04          119.3           183.1\n",
       "1-05          180.3           119.3\n",
       "1-06          168.5           180.3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# check you can see it is not there again\n",
    "shampoo_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e990403d-c105-49bd-9539-f3c31026e73d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6ab6321-8481-4d6d-b82f-826d1b479eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets import the mean squared error metrics and \n",
    "# numpy maths for the calculation of error \n",
    "#between the actual and forecast sales\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b8ce9c-ee25-467b-b06d-a3f0acd8a31b",
   "metadata": {},
   "source": [
    "###### Note ,the mean squared error simply gives us mean squared error,the problem here is that our error metrcs will give us the mean squared erroe and because it is squared we cannot interprete it, so to remove it we use np.sqrt , the squareroot method which will keep it in the form similar to the value we are working with or in the same matrix system in which this value is been calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b42cc515-33c3-4be7-b2eb-8d32f129e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shampoo_error = mean_squared_error(shampoo_base.Actual_sales,shampoo_base.Forecast_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41fd74e1-4fec-449d-8607-af50219eea69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11715.388285714285"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shampoo_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967740bb-cb63-4074-8fe0-12f78a9e6fff",
   "metadata": {},
   "source": [
    "The value 11715 is not in any where related to the matrix system the dataset we have follows, thus what we need is np.sqrt(shampoo_error) so as to be able to relate it with the dataset we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e66e0485-646e-4889-bfeb-10d33b76f2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108.23764726616282"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(shampoo_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8d189d-b21d-4d38-927b-dc94fa6a4516",
   "metadata": {},
   "source": [
    "We can create different types of mode , for example, we have \n",
    "\n",
    "+ Moving Average model\n",
    "\n",
    "+ Auto regressive model\n",
    "\n",
    "+ There is differencing you can do to make the series stationary\n",
    "\n",
    "But at the end of the day most of the practitioners basically use the ARIMA method , which is 'AUTO REGRESSIVE INTERGRATED MOVING AVERAGE'\n",
    "\n",
    "It is auto intensive\n",
    "is intergrated \n",
    "it is moving average\n",
    "\n",
    "All of thes is part of one single model\n",
    "\n",
    "+ How to create Auto regressive model using ARIMA\n",
    "\n",
    "All you need do is to specify the term or the parameter , for example you have \n",
    "ARIMA(p,d,q) , parameter p is auto regressive.\n",
    "\n",
    "Lets say we have the model\n",
    "ARIMA(0,0,2)\n",
    "\n",
    "So you can create the ARIMA or the moving average or auto regressivr or  a combination of every thing.\n",
    "\n",
    "Hence, we need to calculate the auto regressive and the moving average by having the ACF and the PACF.\n",
    "\n",
    "Note, PACF is used to evaluate the parameter for p, which is auto regressive\n",
    "\n",
    "ACF is for moving Average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29a15f17-c148-4004-9db5-7e6c459543d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2ad4491-1c27-456a-a2b7-281f719efa32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acf(shampoo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbdc5a6-750a-425f-9bfe-7c0cd6c1ee7e",
   "metadata": {},
   "source": [
    "At the thumb we have 0, what it basically mean is that 266 = 266 = 0, what is the correlation between then? then the second one, 266 -- 145.9, what is the coerrelation between them .\n",
    "\n",
    "It basically calculate the correlation between the one previous and the second previous and the third previous thumb and so on, from the 3rd previous turn, it shows that it is going below the range.\n",
    "What value do you have out of this crritical range, you need to consider that.\n",
    "\n",
    "In this case the q will be the 3 ie 0,1, 2, 3\n",
    "\n",
    "We are simply differencing thumb d to make the series stationary, thumb d is usually between 0 - 2, so we will experiment it between 0-2, one may be sufficient but we can try it with 2.\n",
    "\n",
    "Ths helps to remove the seasonality function so that we can do a better prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62bc81d3-3b74-4e90-9a7d-5ea2e2869060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Q -3 p-2, d - 0-2\n",
    "\n",
    "plot_pacf(shampoo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764cd732-6f95-4539-9e2d-28b1bf8572c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now ,we will input the ARIMA from the statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17306c36-73dd-4a0f-80b1-e618c9f8883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "937f24ea-fd23-487a-bdc2-b80882aaf290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE need to trian and test our model\n",
    "shampoo_train = shampoo[0:25]\n",
    "shampoo_test = shampoo[25:36]\n",
    "# We have some data we keep for the calculation in the error matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d481c79-058b-4d26-b6d1-a9a745797197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cf9aee7c-15c1-4688-9cd2-eaf09478dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ARIMA model using the train and test , the reason wy we create our train and test is that so that when we evaluate\n",
    "#our model we will have some unseen data that ew  are keeping in the test ,for the calculation of error matrix which is the best practice.\n",
    "\n",
    "shampoo_model = ARIMA(shampoo_train,order=(3,1,2))\n",
    "#order is what we need to specify(2,1,3) we can type that first\n",
    "# it didnt work we tried 3,1,3, it didnt then 3,1,2 and it worked , so you keep trying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6af80d4e-ad05-423e-9f23-b09dd2e18bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# once model is created we need to fit it\n",
    "shampoo_model_fit = shampoo_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeece6e5-de22-4188-9a53-c44d8ffdc84a",
   "metadata": {},
   "source": [
    "This result is based on ARIMA's dependency on the model creation and you fit the data , it basically gives a warning like in this case, whtaevr order we have created is not consistent, so generally in the case of Arima , we need to make sure we specify or experiment with a couple of orders to get the right fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eb56da-5f87-4cc1-a683-9fc9d7a76f14",
   "metadata": {},
   "source": [
    "Alternatively, we can use model tunning to achieve the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "715d05cd-74e9-4a35-8eb4-743ba1fc35df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272.3891948071348"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we use aic information to view how good the model is when you fit it\n",
    "shampoo_model_fit.aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5e426cba-bfc4-4386-b59a-72ba9b98b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the forecast to test the model\n",
    "# o has residuals and couple of other things\n",
    "shampoo_forecast = shampoo_model_fit.forecast(steps=11)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aed4eb20-9876-413f-b2fc-325adfd0e34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130.9271065518346"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have the observed values test_shampoo, then the forcast values shampoo_forecast\n",
    "np.sqrt(mean_squared_error(shampoo_test,shampoo_forecast))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4244576-8eb0-42c7-b9b3-f4005c3782fc",
   "metadata": {},
   "source": [
    "Here, 130 is the error rate that the ARIMA model contains and we need to test it against the base line model.\n",
    "If it is better than the ARIMA we accept it otherwise ,we reject it.\n",
    "Our baseline model error is 108 and the ARIMA model is 130, this shows that our baseline model is better than ARIMA model when it comes to doing the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1b6dbf-a2ee-494d-823e-725e5351f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the parameter to specify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c084ea-9eca-425a-9f09-41e961c76dd9",
   "metadata": {},
   "source": [
    "You need to choose a range you want to evaluate the p-value eg(0,5) the d-values(0-3) q_values (0,5)\n",
    "This process may show alot of warnings so is important to import the warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8be9de2b-31a7-4cc1-b720-e403d143b8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = range(0,5)\n",
    "d_values = range(0,3)\n",
    "q_values = range(0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "25b8e723-1b3c-4190-802a-65ed64ca595b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA(0, 0, 0) MSE = 77950.15\n",
      "ARIMA(0, 0, 1) MSE = 70119.47\n",
      "ARIMA(0, 0, 2) MSE = 58566.44\n",
      "ARIMA(0, 0, 3) MSE = 62031.20\n",
      "ARIMA(0, 1, 0) MSE = 33849.87\n",
      "ARIMA(0, 1, 1) MSE = 40653.60\n",
      "ARIMA(0, 1, 2) MSE = 34511.76\n",
      "ARIMA(0, 1, 3) MSE = 41465.63\n",
      "ARIMA(0, 1, 4) MSE = 14452.71\n",
      "ARIMA(0, 2, 0) MSE = 34017.03\n",
      "ARIMA(0, 2, 1) MSE = 28392.33\n",
      "ARIMA(0, 2, 2) MSE = 24225.79\n",
      "ARIMA(0, 2, 3) MSE = 23015.02\n",
      "ARIMA(1, 0, 0) MSE = 61158.66\n",
      "ARIMA(1, 0, 1) MSE = 46528.71\n",
      "ARIMA(1, 0, 2) MSE = 43922.43\n",
      "ARIMA(1, 0, 3) MSE = 34856.73\n",
      "ARIMA(1, 0, 4) MSE = 25186.07\n",
      "ARIMA(1, 1, 0) MSE = 31687.08\n",
      "ARIMA(1, 1, 1) MSE = 42176.66\n",
      "ARIMA(1, 2, 0) MSE = 18845.87\n",
      "ARIMA(1, 2, 1) MSE = 26129.55\n",
      "ARIMA(2, 0, 0) MSE = 45248.82\n",
      "ARIMA(2, 0, 1) MSE = 29637.25\n",
      "ARIMA(2, 0, 3) MSE = 43808.33\n",
      "ARIMA(2, 0, 4) MSE = 22341.60\n",
      "ARIMA(2, 1, 0) MSE = 35488.37\n",
      "ARIMA(2, 1, 1) MSE = 39633.99\n",
      "ARIMA(2, 1, 2) MSE = 35884.80\n",
      "ARIMA(2, 2, 0) MSE = 34024.26\n",
      "ARIMA(3, 0, 0) MSE = 46326.48\n",
      "ARIMA(3, 1, 0) MSE = 22024.88\n",
      "ARIMA(3, 1, 1) MSE = 22841.66\n",
      "ARIMA(3, 1, 2) MSE = 18095.37\n",
      "ARIMA(3, 1, 4) MSE = 37610.99\n",
      "ARIMA(3, 2, 0) MSE = 24695.27\n",
      "ARIMA(3, 2, 1) MSE = 16368.68\n",
      "ARIMA(3, 2, 2) MSE = 15804.22\n",
      "ARIMA(3, 2, 3) MSE = 14492.82\n",
      "ARIMA(4, 0, 0) MSE = 33233.21\n",
      "ARIMA(4, 0, 1) MSE = 33240.66\n",
      "ARIMA(4, 1, 0) MSE = 22339.38\n",
      "ARIMA(4, 1, 1) MSE = 22615.98\n",
      "ARIMA(4, 1, 2) MSE = 19179.63\n",
      "ARIMA(4, 1, 3) MSE = 20601.63\n",
      "ARIMA(4, 1, 4) MSE = 19303.91\n",
      "ARIMA(4, 2, 0) MSE = 20052.27\n",
      "ARIMA(4, 2, 1) MSE = 15572.78\n",
      "ARIMA(4, 2, 2) MSE = 16401.78\n",
      "ARIMA(4, 2, 3) MSE = 16154.18\n"
     ]
    }
   ],
   "source": [
    "# we need a loop to loop in this values\n",
    "# Iterate it in the same order in which they go in the \n",
    "# order parameter of the arima method\n",
    "# Store the prediction in a list so as to test it\n",
    "# we need to loop through the number of time\n",
    "for p in p_values:\n",
    "    for d in d_values:\n",
    "        for q in q_values:\n",
    "            order = (p,d,q)\n",
    "            train,test = shampoo[0:25], shampoo[25:36]\n",
    "            predictions = list()\n",
    "            for i in range(len(test)):\n",
    "                try:\n",
    "                    model = ARIMA(train, order)\n",
    "                    model_fit = model.fit(disp=0)\n",
    "                    pred_y = model_fit.forecast()[0]\n",
    "                    predictions.append(pred_y)\n",
    "                    error = mean_squared_error(test,predictions)\n",
    "                    print('ARIMA%s MSE = %.2f'% (order,error))\n",
    "                except:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80785b15-d621-43cc-a04a-74cd61cc8c36",
   "metadata": {},
   "outputs": [],
   "source": [
    " QUESTION : PLs how did he do the calculation !!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6f7d19-7fe6-4c4c-8ed3-b80f56df3a0f",
   "metadata": {},
   "source": [
    "From the result, we can see that the baseline model is still better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85454793-c09c-4d0d-822d-10317cfe6830",
   "metadata": {},
   "source": [
    "#### Time Series Analysis with Python "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c4186e-7b7a-42aa-822f-fdc0b13104a0",
   "metadata": {},
   "source": [
    "In this tutorial, we are going to build a time series model using Python. First, let's import the\n",
    "necessary libraries to perform our little time series analysis.\n",
    "\n",
    "In [1]:\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 15, 6\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "Loading Time Series Data in Pandas\n",
    "\n",
    "This tutorial draws from this one and we \n",
    "will be using this dataset which records the daily passenger\n",
    "count for a certain airline company.\n",
    "\n",
    "A cool thing with jupyter notebook is that you can run linux\n",
    "command right here on the notebook simply by preceeding the command with the exclamation\n",
    "sign !.\n",
    "\n",
    "For instance, let's look at the first 10 rows of our dataset using the linux command head\n",
    "\n",
    "In [2]:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c54d09f-54d7-47ee-a3de-aa5bf0105ee2",
   "metadata": {},
   "source": [
    "! head AirPassengers.csv\n",
    "\n",
    "Month,#Passengers\n",
    "\n",
    "1949-01,112\n",
    "\n",
    "1949-02,118\n",
    "\n",
    "1949-03,132\n",
    "\n",
    "1949-04,129\n",
    "\n",
    "1949-05,121\n",
    "\n",
    "1949-06,135\n",
    "\n",
    "1949-07,148\n",
    "\n",
    "1949-08,148\n",
    "\n",
    "1949-09,136\n",
    "\n",
    "See that the data is in csv format, with 2 columns. \n",
    "\n",
    "The first column is a string for the month in %Y-\n",
    "%m format and the second column is the number of passengers. \n",
    "\n",
    "So here is a useful thing to know\n",
    "when working with time series: converting strings to datetime.\n",
    "\n",
    "The python datetime utility handles\n",
    "this task using the strptime function. \n",
    "\n",
    "See Chris Albon's site for a quick guide. Now back to parsing\n",
    "the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d12507-765c-4c8e-874e-7126d93d580c",
   "metadata": {},
   "source": [
    "+ define a lambda function that converts a string with format %Y-%m to datetim\n",
    "e\n",
    "\n",
    "custom_date_parser = lambda dates: \n",
    "\n",
    "pd.datetime.strptime(dates, '%Y-%m')\n",
    "\n",
    "#parse the data using pandas read_csv\n",
    "AirPassengers =\n",
    "pd.read_csv('AirPassengers.csv',\n",
    " parse_dates = ['Month'],\n",
    " index_col = 'Month',\n",
    " date_parser = custom_date_parser)\n",
    "AirPassengers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622c5ce-5e52-490f-bf34-e29adeb6b03e",
   "metadata": {},
   "source": [
    "+ Let's see the data types\n",
    "\n",
    "AirPassengers.dtypes\n",
    "\n",
    "#Passengers int64\n",
    "\n",
    "dtype: object\n",
    "\n",
    "Let's walk through the parameters in the read_csv code above\n",
    "\n",
    "• parse_dates tells pandas to parse the specified column as date. values can be\n",
    "boolean or list of ints or names or list of lists or dict, and the default is False."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02c2bef-1b1a-410d-82a5-6b0b7bdb0b41",
   "metadata": {},
   "source": [
    " index_col specifies which column to use as index. When analyzing Time Series in\n",
    "Pandas, it's important that the variable containing the time information be used as\n",
    "the dataFrame index. \n",
    "\n",
    "In the present case, this variable is called Month\n",
    "\n",
    "• date_parser This specifies how to parse the date. By default, Pandas usses the\n",
    "format ‘YYYY-MM-DD HH:MM:SS'. So if the date we want to parse are not in this\n",
    "format, we need to define a custom parser, just like\n",
    "\n",
    "the custom_date_parser above.\n",
    "\n",
    "We see that the datatype of the Month is now datetime64[ns]\n",
    "In [5]:\n",
    "    \n",
    "#Let's convert the dataFrame to a Series, since there is only one column anyw\n",
    "ays\n",
    "\n",
    "ts = AirPassengers['#Passengers']\n",
    "\n",
    "ts.head()\n",
    "\n",
    "Out[5]:\n",
    "\n",
    "Month\n",
    "\n",
    "1949-01-01 112\n",
    "\n",
    "1949-02-01 118\n",
    "\n",
    "1949-03-01 132\n",
    "\n",
    "1949-04-01 129\n",
    "\n",
    "1949-05-01 121\n",
    "\n",
    "Name: #Passengers, dtype: int64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9550f466-2f80-49d9-aca6-aff6f530411c",
   "metadata": {},
   "source": [
    "+ Check for Stationarity in Time Series\n",
    "\n",
    "A Time Series is said to be stationary if it's desciptive statistical properties\n",
    "such mean, variance remain constant in time. We can assume a series to be stationary if the\n",
    "followings are true (more details here):\n",
    "    \n",
    "• constant mean\n",
    "\n",
    "• constant variance\n",
    "\n",
    "• an autocovariance that does not depend on time. \n",
    "\n",
    "\n",
    "But why should we care about stationarity? Well, most of the statistical methods used in the analysis\n",
    "of time series assume that the series is stationary. In addition, having a stationay series has practical\n",
    "advantage since it would mean that the average behavior of the series at time t will be the same at a\n",
    "time in the future. Hence we can make predictions.\n",
    "Let's test stationarity in the present data. First we create a simple plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cacf54-e876-4da1-8f2c-c3f361a7dab0",
   "metadata": {},
   "source": [
    "#visualize the time series with a simple line plot\n",
    "ts.plot()\n",
    "Out[6]:\n",
    "<matplotlib.axes._subplots.AxesSubplot at 0x7f2ac3a2d828>\n",
    "\n",
    "We see a clear trend and some seasonality. But it might always be easy to create a visual like this.\n",
    "We can test stationarity using the following methods:\n",
    "    \n",
    "• Plotting Rolling Statistics: Plot the moving average or moving variance and see\n",
    "if it varies with time. see pandas documentation for rolling\n",
    "\n",
    "• Dickey-Fuller Test: This is one of the statistical tests for checking stationary.\n",
    "\n",
    "The\n",
    "null hypothesis H0H0 is defined as The Time Series is non-stationary. i.e. if\n",
    "the p value is less than some confidence level αα (usually α=0.05α=0.05), we\n",
    "reject the null hypothesis and say that the series is stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9932d9a-f414-4efd-a567-e91f0824fa23",
   "metadata": {},
   "source": [
    "see here or thi post\n",
    "\n",
    "In [22]:\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "def test_stationarity(timeseries):\n",
    "\n",
    " #Perform Dickey-Fuller test:\n",
    " print('Results of Dickey-Fuller Test:')\n",
    " dftest = adfuller(timeseries, autolag='AIC')\n",
    " \n",
    " dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lag\n",
    "s Used','Number of Observations Used'])\n",
    " for key,value in dftest[4].items():\n",
    " dfoutput['Critical Value (%s)'%key] = value\n",
    " print(dfoutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a324b556-5036-4d3d-9d3e-1781e95c59c2",
   "metadata": {},
   "source": [
    "test_stationarity(ts)\n",
    "\n",
    "Results of Dickey-Fuller Test:\n",
    "\n",
    "Test Statistic 0.815369\n",
    "\n",
    "p-value 0.991880\n",
    "\n",
    "#Lags Used 13.000000\n",
    "\n",
    "Number of Observations Used 130.000000\n",
    "\n",
    "Critical Value (1%) -3.481682\n",
    "\n",
    "Critical Value (5%) -2.884042\n",
    "\n",
    "Critical Value (10%) -2.578770\n",
    "\n",
    "dtype: float64\n",
    "\n",
    "We may conclude that this is a non-stationary series because:\n",
    "\n",
    "• The p-value is greater than the typical confidence level of 0.05, hence we donot\n",
    "reject the null hypothesis\n",
    "\n",
    "• The critical values from the Dickey-Fuller Test are way smaller than the Test\n",
    "Statistics\n",
    "\n",
    "+ Making a Time Series Stationary\n",
    "\n",
    "There are a number of reasons why a time series might be non-stationary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c548be-24b4-42ff-bbd8-c2e84f505550",
   "metadata": {},
   "source": [
    "• Trends\n",
    "\n",
    "• Seasonality\n",
    "\n",
    "Hence the basic idea of forecasting with time series data is as follows\n",
    "\n",
    "• Estimate trends and seasonalities and remove them to get a \"stationary series\".\n",
    "This process is know as deseasonalization\n",
    "\n",
    "• Make predictions using the stationary series. Calculate means etc ..\n",
    "\n",
    "• Apply the deseasonalization contraints on the predicted value\n",
    "\n",
    "+ Differencing\n",
    "\n",
    "Differencing is a popular method to remove trend and seasonality in a time series. In python, this\n",
    "can be achieved using the diff() method of either a series or a dataframe. Check out this post or this\n",
    "one for an overview of performing differencing of time series.\n",
    "\n",
    "More details about other methods of\n",
    "differencing and when to use them can be found here\n",
    "\n",
    "In [9]:\n",
    "\n",
    "nonseasonal_diff = ts.diff(periods=1)\n",
    "\n",
    "plt.plot(nonseasonal_diff)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db94aea-5bd6-4206-8b8f-56db00c673bb",
   "metadata": {},
   "source": [
    "test_stationarity(nonseasonal_diff.dropna(inplace=False))\n",
    "\n",
    "Results of Dickey-Fuller Test:\n",
    "\n",
    "Test Statistic -2.829267\n",
    "\n",
    "p-value 0.054213\n",
    "\n",
    "#Lags Used 12.000000\n",
    "\n",
    "Number of Observations Used 130.000000\n",
    "\n",
    "Critical Value (1%) -3.481682\n",
    "\n",
    "Critical Value (5%) -2.884042\n",
    "\n",
    "Critical Value (10%) -2.578770\n",
    "\n",
    "dtype: float64\n",
    "\n",
    "In [11]:\n",
    "\n",
    "seasonal_diff = \n",
    "\n",
    "nonseasonal_diff.diff(periods=12)\n",
    "\n",
    "plt.plot(seasonal_diff)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "test_stationarity(seasonal_diff.dropna(inplace=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c86ac89-1d6a-44d6-b185-1e4db85809b4",
   "metadata": {},
   "source": [
    "Results of Dickey-Fuller Test:\n",
    "    \n",
    "Test Statistic -1.559562e+01\n",
    "\n",
    "p-value 1.856512e-28\n",
    "\n",
    "#Lags Used 0.000000e+00\n",
    "\n",
    "Number of Observations Used 1.300000e+02\n",
    "\n",
    "Critical Value (1%) -3.481682e+00\n",
    "\n",
    "Critical Value (5%) -2.884042e+00\n",
    "\n",
    "Critical Value (10%) -2.578770e+00\n",
    "\n",
    "dtype: float64\n",
    "\n",
    "The Autocorrelation and Partial Autocorrelation plots\n",
    "\n",
    "These plots help in identifying the order of an Autoregressive ARMA(p, q)\n",
    "see also pandas visualization documentation for the autocorrelation_plot\n",
    "\n",
    "In [12]:\n",
    "#ACF and PACF plots:\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "In [13]:\n",
    "lag_acf = acf(seasonal_diff.dropna(inplace=False), nlags=20)\n",
    "\n",
    "lag_pacf = pacf(seasonal_diff.dropna(inplace=False), nlags=20, method='ols')\n",
    "\n",
    "In [14]:\n",
    "p=plot_acf(lag_acf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d08dcfd-b9ae-413a-942b-0e5d4b67249e",
   "metadata": {},
   "source": [
    "def PlotAcf(data):\n",
    "    \n",
    " fig, axes = plt.subplots(nrows=4, \n",
    " \n",
    " figsize=(8, 12))\n",
    " \n",
    " fig.tight_layout()\n",
    " \n",
    " axes[0].plot(data)\n",
    " \n",
    " axes[0].set_title('Raw Data')\n",
    " \n",
    " axes[1].acorr(data, maxlags=data.size-1)\n",
    " \n",
    " axes[1].set_title('Matplotlib \n",
    " Autocorrelation')\n",
    " \n",
    " plot_acf(data, lags=20, ax=axes[2])\n",
    " \n",
    " axes[2].set_title('Statsmodels Autocorrelation')\n",
    " pd.tools.plotting.autocorrelation_plot(data, ax=axes[3])\n",
    " \n",
    " axes[3].set_title('Pandas Autocorrelation')\n",
    " \n",
    " Remove some of the titles and labels that were automatically added\n",
    " \n",
    " #for ax in axes.flat:\n",
    " \n",
    " ax.set(title='', xlabel='')\n",
    " \n",
    " #plt.show()\n",
    " \n",
    "In [17]:\n",
    "#PlotAcf(ts_log_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1d60ae-fa2d-4625-be91-b0e0d7343953",
   "metadata": {},
   "source": [
    "Forcasting: ARIMA\n",
    "\n",
    "In [18]:\n",
    "    \n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "• Combined AR and MA\n",
    "\n",
    "In [19]:\n",
    "\n",
    "model = SARIMAX(ts, trend='n', order=\n",
    "\n",
    "(0,1,0), seasonal_order=(1,1,1,12))\n",
    "\n",
    "results_ARIMA = model.fit(disp=-1)\n",
    "\n",
    "plt.plot(ts, label='original')\n",
    "\n",
    "plt.plot(results_ARIMA.fittedvalues, color='red', label='fitted')\n",
    "\n",
    "plt.title('RSS: %.4f'% \n",
    "\n",
    "sum((results_ARIMA.fittedvalues-ts)**2))\n",
    "\n",
    "plt.legend()\n",
    "Out[19\n",
    "<matplotlib.legend.Legend at 0x7f2ab1a178d0>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16efde03-5ecb-4205-a75e-765fce87e4ae",
   "metadata": {},
   "source": [
    "df = pd.DataFrame(ts)\n",
    "\n",
    "df['forecast'] = \n",
    "\n",
    "results_ARIMA.predict(start = '1959-05-\n",
    "\n",
    "01', end= '1960-12-01\n",
    "\n",
    "', dynamic= True)\n",
    "\n",
    "df[['#Passengers', \n",
    "\n",
    "'forecast']].plot(figsize=(12, 8))\n",
    "\n",
    "#plt.title('RMSE: %.4f'% \n",
    "\n",
    "np.sqrt(sum((predictions-\n",
    "\n",
    "original_TS)**2)/len(origin\n",
    "al_TS)))\n",
    "\n",
    "Out[20]:\n",
    "\n",
    "<matplotlib.axes._subplots.AxesSubplot at 0x7f2ab2827048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c969542e-6d0d-4b0f-b879-26256ecf52ef",
   "metadata": {},
   "source": [
    "#predict(results_ARIMA.fittedvalues, ts)\n",
    "\n",
    "+ Other Tutorials\n",
    "\n",
    "• Sean Abu's Seaonal ARIMA with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b735d566-2b36-4b5d-80be-a3e0e8f4500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Times Series Analysis: Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2bd918-100b-4658-bc30-0d5d3bd67d82",
   "metadata": {},
   "source": [
    "1. A restaurant has been experiencing higher sales during the weekends as compared to the weekdays. Daily restaurant sales patterns for this restaurant over a week are an example of the _seasonality________ component of time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f70380a-5dbe-48fe-ad8d-97aab718796d",
   "metadata": {},
   "source": [
    "2.  Which of the following is not one of the four types of variation that is estimated in time-series analysis?\n",
    "\n",
    "four types of variations estimated in time-series analysis are :-\n",
    "1. Trend\n",
    "2. Seasonal\n",
    "3. Cyclical\n",
    "4. Irregular\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697d5d0b-b6eb-4677-8ae9-663f2a83c5c8",
   "metadata": {},
   "source": [
    " 3. The cyclical_________ component of a time series measures the fluctuations in a time series due to economic conditions of prosperity and recession with a duration of approximately 2 years or longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2c8ab3-ba22-4d5f-a3a7-8efd9724acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rend is a pattern in data that shows the movement of a series to relatively higher or lower values over a long period of time. In other words, a trend is observed when there is an increasing or decreasing slope in the time series. Trend usually happens for some time and then disappears, it does not repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2654413d-4d24-4315-9c1c-6c2992c60ba4",
   "metadata": {},
   "source": [
    "Seasonality is a characteristic of a time series in which the data experiences regular and predictable changes that recur every calendar year. Any predictable fluctuation or pattern that recurs or repeats over a one-year period is said to be seasonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233edcf0-2809-4279-aa44-e16889c7aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "A cyclic pattern exists when data exhibit rises and falls that are not of fixed period. The duration of these fluctuations is usually of at least 2 years. Think of business cycles which usually last several years, but where the length of the current cycle is unknown beforehand.14 Dec 2011"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa22c18c-6976-43f2-933b-dcb6ccc39c27",
   "metadata": {},
   "source": [
    " 4. Which term most closely relates to associative forecasting techniques?\n",
    " \n",
    " Associate techniques use predictor variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be69877-60c5-4f9c-902f-a605b69bf18d",
   "metadata": {},
   "source": [
    "5. The number of daily births in a particular country hospital over a period of 10 days.\n",
    "random pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71143617-e4ec-47d9-9c6d-50d51cdaea8c",
   "metadata": {},
   "source": [
    "6. The sales of a new popular ice-cream flavour in a beach resort. Choose the true statement.\n",
    "\n",
    "seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337abb30-9b5b-428b-b9e8-0edae4951522",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. This time series plot is an example of:\n",
    "    \n",
    "    irregular change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a6f07a-025c-438e-8ac8-bec6236fa6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. cyclical variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6422804a-0431-4741-8bb7-ae296117ca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. a decreasing trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b954f5-a2dc-47eb-9b30-7ef9cc2256ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. multiple trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c83b8e-9b38-4a5f-8b92-d199d9338659",
   "metadata": {},
   "source": [
    "###  Weeek 13 Day 2 – Neural Networks Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf70a54-05fa-4615-85e7-015d753bd10f",
   "metadata": {},
   "source": [
    "####  Introduction to neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4ec76f-9bdb-4fa4-ae63-a1aebb811fad",
   "metadata": {},
   "source": [
    "We will be setting our goals and introducing the frame work.\n",
    "\n",
    "Creating a machine learning algorithm ultimately means building a model that outputs correct information,given that we have provided input data.\n",
    "\n",
    "Think of the modeel as a black box, we feed input and it delivers an output.\n",
    "For instance, we may want to create a model that will predict the weather tommorow given mediological information for the past few days, the input we feed to the model could be matrix such as temperature, humidity and precipitation, the output we will obtain wil be the weather forecast for tommorrow\n",
    "\n",
    "Before we get confortable and confident  about the model's output ,we must train the model.\n",
    "Training is an essential concept in machine learning as this is the process through which the model learns how to make sense of the input data.\n",
    "\n",
    "Once , we have trained our model, we can simply fed it with data and obtain an output\n",
    "\n",
    "The basic logic behind training an algorithm involves four incredients.\n",
    "\n",
    "+ Data\n",
    "\n",
    "+ Model\n",
    "\n",
    "+ objective function which is to minimize the error \n",
    "\n",
    "+ Optimize the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eda045-1c3a-4674-a964-9eea86c65011",
   "metadata": {},
   "source": [
    "+ Data : we must employ a certain amount of data to train with. Usually,this is historical data which is readily available.\n",
    "\n",
    "+ Model : \n",
    "We need a model, the simplest model we can train is a linear model.\n",
    "\n",
    "In the weather forcast example, that will mean to find some coefficient, multiply each variable with them and sum up everything to get the output\n",
    "Examplw W1(temperature) + W2(humidity) + W3(precipitation).\n",
    "\n",
    "The linear model is just a tip of the eye bear.\n",
    "Stepping on the linear model , deep machine learning helps us to create non complicated non linear models.\n",
    "\n",
    "They usually fit the data much better than a simple linear relationship\n",
    "\n",
    "+ Objective functon:\n",
    "\n",
    "So far we took data, feed it ti the model and obtained an output.\n",
    "\n",
    "We need this output to be as close to reality as possible and this is where the objective function comes in. \n",
    "It estimates how correct the models output are on average. the entire machine learning framework boils down to optimizing this function.\n",
    "\n",
    "For example , if our function is measuring the prediction error of the model, be it worth to minimize this error or in othrwords, minimize the objective .\n",
    "\n",
    "+ Optimization algorithm\n",
    "\n",
    "It consists of the mecahnics to which we varies the parameters of the model to optimize the objective function.\n",
    "\n",
    "For instance, if our weather forcast model is  weather tommorrwo equals W1 x temp. + W2 X humidty\n",
    "\n",
    "The optimization algorithm may go through values like\n",
    "\n",
    "1.05 X temp + 1.2 X humidty or \n",
    "\n",
    "1.05 X temp - 1.2 X humity or \n",
    "\n",
    "1.04 X temp - 1.19 X humidity and so on \n",
    "\n",
    "W1 and W2 are the parameters that will change.\n",
    "\n",
    "For each set of parameters we will calculate the objective function, then we will choose the moel with the highest predictive power.\n",
    "\n",
    "How do we know which one is the best?\n",
    "It will be the one with the opti,al objective function.\n",
    "\n",
    "WE used the word ingredients instead of process because the machine learning process is iterative(Continuous or repeatedly)\n",
    "\n",
    "We feed data into the model and compare the accuracy through the objective function, then we vary the model's parameters and repeat the operation, when we reach a point after which we can no longer optimize or we don't need to , we will stop, since we woulld have found a good enough solution to our problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1023ca90-fcb5-4381-b939-870aae4cddc9",
   "metadata": {},
   "source": [
    "#### Training the model theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c8f71c-711e-4380-83ba-cdd1f5ffaf08",
   "metadata": {},
   "source": [
    "We will be exploring the concept of training the model through the data.\n",
    " For example, you have a coffee making machine that doesn't know how to make coffee,\n",
    " \n",
    " In a non machine learning setting , we will need to incorporate the instructions in the machine's electronics.\n",
    "For instance, the engineers may set the machines electronics too.\n",
    "First, grind 20 grams of coffee beans, second heat the water to 200degrees farenhight, pour 10ml  grinded coffee into the cup.\n",
    "\n",
    "In amachine learning setting, we will notexclusively provide instructions to the machine, instead we just need to state our goal.\n",
    "\n",
    "In the coffee machine case , that will be a cup of coffee, then we will let the machine work out the problem on its own.\n",
    "The machine learning process is a kind of \n",
    "trail and error training.\n",
    "The machine will try various combinations of grinding, heating and pouring some of those will not make sense.\n",
    "\n",
    "The machine wil try heating the water ,pouring it before grinding the coffee, resulting in a cup of hot water.\n",
    "or may grind the coffee and pour the water without heating the water. after a thousans of tials and errors, the algorithmn will train itself to reach the set goal every time which is to make a cup of coffee .\n",
    "\n",
    "It is possible that it will learn to make the best cofee you have ever tried much better than the one obtained by following a set of instructions. \n",
    "This is because it would have gone through so many more recipes than a human would ever be able to  do.\n",
    "\n",
    "A reasonable optimization algorithmn  will not try all combinations,as there are usually inexhaustible many other options.\n",
    "\n",
    "In the coffee example, if the coffee machine learns that grinding the coffee  has to go before pouring the water, it will not waste time attempting it in the wrong order\n",
    "This example shows us why machine learning is so powerful, it allows systems to learn on there own situation\n",
    "ww humans cannot define the original set of rules for the computer to follow, even if we can define the set of rules, an algorithm can probably provide a better one\n",
    "\n",
    "\n",
    "Another exampl , is self driving cars, contrary to what many people think,self driivng cars don't follow rules such as a voice clip. Essentially, they train on hours on footage of real people while driving and learn how to mimick them efficiently.\n",
    "\n",
    "It is not the set of rules they know but the final goal. The final goal fundamentally is to drive safe and efficiently. Avoid curves , dont bomb into other cars, dont go over the speed limit,stop in red lights and so on\n",
    ".\n",
    "\n",
    "Training Data is at the core of the process.\n",
    "\n",
    "+ After trying the algorithm will learn \n",
    "+ why machine learning is so powerful is that it allows systems to learn on its own ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee976f56-a35a-46e8-b1e4-8669f1d0d638",
   "metadata": {},
   "source": [
    "#### Types of Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765586ac-b022-4af9-9b58-642a8cbac1ee",
   "metadata": {},
   "source": [
    "+ There are three major types of machine learning:\n",
    "\n",
    "+ Supervised\n",
    "\n",
    "+ Unsupervised\n",
    "\n",
    "+ Reinforcement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec16d09-8023-4576-8ec3-d53c1424144b",
   "metadata": {},
   "source": [
    "supervised learning :\n",
    "\n",
    "This refers to the case where we provide the algorithm with inputs and the corresponding desired output.\n",
    "Base on this information , it learns ohw to produce output close to the ones we are looking for,\n",
    "\n",
    "Those example, the one about the weather fircast and that of preparing coffee demonstrates supervised learning.\n",
    "\n",
    "\n",
    "Unsupervised :-\n",
    "\n",
    "Here we feed input but there are no target output. This means we dont tell the algorithm exactly what our goal is instead we ask it to provide dependence or underlining logic in the data provided.\n",
    "\n",
    "For instance, imagine , we administer the website cancerdagos.com  , users have the option to submit photos of their cats or dogs to the website. once a photo has been submitted we will like it to be automatically classified in the cell page cat or the cell page dogs\n",
    "\n",
    "In supervised learning , we will train the algorithm on a dataset of say 1000 cat photos and 1000 dog photos, each will be labbelled cat or dog. the model will then learn hpw to input pictures as cat or dog, minimizing mismatches over the trained set.\n",
    "\n",
    "Sometimes however, we may not have the resources or the need to label the whole dataset.\n",
    "\n",
    "In the previous dataset, there was a person who mnually labelled all 2000 pictures.\n",
    "\n",
    "Now imagine a dataset of 2 million pictures , if it takes a person 5 seconds to label a picture, a dataset of 2 million observations will take around 2800 hours or 345 working days to label all pictures.\n",
    "\n",
    "\n",
    "With unsupervised learning though we can \n",
    "train the algorithm without labelling the photos or in an unsupervised way.\n",
    "we can simply  ask it to split them into two groups base on visual similarities\n",
    "The result will be two groups thaat are unlabelled. once, we have obtained that,we can examine them and say oh,yes!\n",
    "The first set is dogs and the second set is cat.\n",
    "Thanks to algorithm\n",
    "\n",
    "Unsupervised learning is especially useful \n",
    "when our goal is to split a  data into a certain number of categories whcih we do not prior to implementing it . This is called clustering.\n",
    ".\n",
    "\n",
    "\n",
    "+ Reinforcement learning :\n",
    "\n",
    "With reinforcement learning ,we will train a model to act in an enviromnment base on the reward it receives\n",
    "It is much like training your pet and rewarding it with a treats every time it achieves a goal. maybe to sit! or stand!\n",
    "\n",
    "in thesame way the machine learning algorithm could be thought how to play super mario by rewarding it for progressing with an increase in score \n",
    "\n",
    "supervised learning  is the focus of the course and this is because it is the simplest and most commonly used.\n",
    "\n",
    "Supervised learning can be divided into additional sub type:\n",
    "\n",
    "Classification and regression\n",
    "The difference is very trsight forward\n",
    "Classification supervised learning provides output which are \n",
    "categorical such as cats and dogs\n",
    "\n",
    "In regression supervised learning models \n",
    "The output will be of numerical type fr example predicting the eur/usd exchange rate will always give us a continuous number like 1.21 or 1.19\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0004afe0-1f0f-4097-9b37-2ac21f23c2fa",
   "metadata": {},
   "source": [
    "#### The Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38189209-a9a8-4a89-8b17-70430cac954e",
   "metadata": {},
   "source": [
    "Let's consider a variable X the function fof x gives us a variable y\n",
    "f(x) -> y \n",
    "y is a function of X but we dont know this function.\n",
    "\n",
    "\n",
    "\n",
    "We want to make the algorithm find that on its own.\n",
    "This is done by providing it with many pairs of x and y as possible and following the methodologies to come"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe5e6bc-5684-4c9a-a009-172b30a551c1",
   "metadata": {},
   "source": [
    "Let's start with the simplest model possible , the linear model. it is extremely important as it is the basis for more complicated models including non linear ones\n",
    "\n",
    "y = f(x) \n",
    "In the linear model universe\n",
    "f(x) = xw + b\n",
    "\n",
    "x is the input we have , in the traditional statistical jog in we will call w the coefficint of x and b the intercept\n",
    "\n",
    "In machine learning though \n",
    "w = weight(s) when we have more than one parameter.\n",
    "b = bias or biases\n",
    "\n",
    "There are many ways to define the linear model: \n",
    "wx + b\n",
    "xw + b\n",
    "x^Tw + b (t stands for transpose)\n",
    "w^T x + b\n",
    "\n",
    "It deosnt matter , we will keep the linear model simple and represent it in the following way.\n",
    "\n",
    "xw + b\n",
    "the goal of the machine learning algorithm is to find such values for W and B , so the output of :\n",
    "xw + b\n",
    "\n",
    "is as close to the observed values as possible.\n",
    "\n",
    "\n",
    "Example: say our goal is to predict the price of an apartment,we may do that base on its size,so the input x , is the size, xw is the model we are using\n",
    "\n",
    "The calculation of this expression gives us the price or the output y.\n",
    "\n",
    "Let's inprt real values\n",
    "\n",
    "The size of an apartment is 743sqft\n",
    ",The possible model for predicting its price is\n",
    "\n",
    "743 X 336.1 - 3237.51\n",
    "\n",
    "input x = size\n",
    "\n",
    "size = 743\n",
    "\n",
    "weight =\n",
    "336.1\n",
    "\n",
    "b = -3237.51\n",
    "\n",
    "If we calculate the output following this model for 743sqft apartment,we will obtain a price of $ 246,484.79\n",
    "\n",
    "y = $ 246,484.79\n",
    "\n",
    "Similarly, given an apartment of a different size, our model will predict a price of $332,862.49\n",
    "say 1000ft X 336.1 - 3237.51 =  $332,862.49\n",
    "\n",
    "+ Knowing the size of any apartment, we can get a prediction about the price based on the linear model.\n",
    "Though this example may over simplify how things work in real life. This is just to show us the principle behind it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2db3de-494e-43cb-aec7-d7041d03564d",
   "metadata": {},
   "source": [
    "#### The linear model. Multiple inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a4710-2943-4921-a59b-da6288451a32",
   "metadata": {},
   "source": [
    "linear model multiple inputs:\n",
    "What if we have\n",
    "additional information saying that the apartment\n",
    "we are valueing is located by the sea, the closer the apartment is to the beach,the higher the price.\n",
    "\n",
    "+ Well a better linear model will predict the price based on both size and proximity to the beach.\n",
    "\n",
    "The linear model tackling this issue is \n",
    "price of apartment equals its size X the weight of size + the appartment proximity to the beach X the weigth of proximity + the bias.\n",
    "\n",
    "if we want to state this expresion \n",
    "in linear algebraic term, we can use the same frame work as before,\n",
    "x times w plus b\n",
    "\n",
    "y = xw + b\n",
    "\n",
    "X and W are both vectors\n",
    "X is 1 by 2 , W is 2 by 1\n",
    "multiplying x and w , will give us a  scalars.\n",
    "( 1x2 x 2x1 = 1x1) shape\n",
    "\n",
    "let's continue our housing example\n",
    "The output y = xw + b\n",
    "x has 2 elements , a size of 743 and a distance from the beach of 1.21 miles\n",
    "W has two elements too, one for each input.\n",
    "the values are 403.77 and -15,212\n",
    "\n",
    "and the bias is 1212.45\n",
    "\n",
    "To calculate the new projected price, we must multiply\n",
    "\n",
    "y = 743 X 403.77 -1.21 X 15,21+ 1212.45\n",
    "\n",
    "     x1     w1      x2   w2         B\n",
    "     \n",
    " =   $282,444.04\n",
    " \n",
    " similarly , if 1000sqft apartment is 2 miles away from the beach , its price becomes $ 373,958.45\n",
    " \n",
    " y = 1000 X 403.77 - 2 X 15,21+ 1212.45\n",
    " \n",
    " Notice that te weigth of the distance from the beach is negative. this is because we expect this variable to have a negative impact on our apartment price.\n",
    "\n",
    "The greater the distance from the beach the lower the price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdad7f68-fed7-4735-8486-8168495658d6",
   "metadata": {},
   "source": [
    "#### The linear model. Multiple inputs and multiple outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983218b5-f951-4e67-9bee-76209f60defe",
   "metadata": {},
   "source": [
    "Multiple input and output:\n",
    "    \n",
    "Here is our new situation, we may be interested in knowing the price for buying the property but also price  for which we can rent it out.\n",
    "Our input are unchanged, size and proximity to the beach\n",
    "\n",
    "This time though we have two outputs, therefore, we can create two linear models.\n",
    "The price as a function of the size and proximity to the beach and the \n",
    "rent as a function of the size and proximity to the beach.\n",
    "\n",
    "Price = size x Weigth of size + proximity x weigth of proximity + bias\n",
    "\n",
    "Rent = size x Weigth of size + proximity x weigth of proximity + bias\n",
    "\n",
    "\n",
    "y1 = X1W11 + X2w21 + B1\n",
    "\n",
    "y2 = X1W12 + X2W22 + B2\n",
    "\n",
    "Notice the indices oof the weigth, the first number refers to the respective input and the second refers to the output\n",
    "\n",
    "We have 2 outputs, 2 inputs, 4 weights and 2 bias.\n",
    "\n",
    "There is a different weigth for each input in each equation.\n",
    "\n",
    "Lets see this in linear algebraic terms\n",
    "y = xw + B\n",
    "\n",
    "In general , if we have k-imputs and m- outputs the number of weigths will be \n",
    "k x m.\n",
    "The number of biases will be equal to the number of outputs - m.\n",
    "\n",
    "Two outputs, 2 inputs, 4 weigths and 2 biases\n",
    "\n",
    "\n",
    "Let the weight for price  W1 and W2 be equal to 403.77 and -15.512 as before and the weigth for the rent W11 and W12 be equal to 13.9 and -484.73\n",
    "\n",
    "The biases B1B2 are 1,112.45 and 212.34\n",
    "\n",
    "The inputs are same as before\n",
    "743 and 1.21 miles\n",
    "\n",
    "the first output \n",
    "y1 = 743 X 403.77 -1.21 X 15,21+ 1,112.45\n",
    "\n",
    "= $ 282,444.04\n",
    "\n",
    "The second output is found by :\n",
    "y2 = 743 X 13.9 -1.21 X 484.75 + 212.34 = \n",
    "$9952.79.\n",
    "\n",
    "Basically, you can buy the house around 282k and rent it out for 10k\n",
    "This is how we use thesame model\n",
    "XW + B =Y to represent linear relationship.\n",
    "\n",
    "Notice , how the previous exampke is actually part of this one, here aree the respective output, input ,weight and bias.\n",
    "\n",
    "Finally, is important to note that this was only one observation we could extend this example to many input, output and observation .\n",
    "\n",
    "YN1 YN2 ....YNM = XN1 XN2 ...xNK * WK1 WK2 ...WKM + B1B2 ... BM \n",
    "\n",
    "The output matrix( will be B1B2 ... Bm where m is the number of output variables and n is number of observations \n",
    "\n",
    "The input matrix will be N by K , where K is the number of input variables\n",
    "\n",
    "The weigth matrix (K X M)remains the same as the weigth dont change depending on the number of observations\n",
    "the same applies to the biasses (1 X M).\n",
    "\n",
    "This shows that we can feed as much data as we want to in our model, it will not change as each model is determined by the weigth and biases\n",
    "\n",
    "This property will help us greatly when creating machine learning algorithms.\n",
    "\n",
    "In machine learning, we vary only the weights and the biases but the logi of the model remains the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b6d96d-3211-4cc8-b88b-5a12074124ed",
   "metadata": {},
   "source": [
    "#### Graphical representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd66e64-60a5-4cc7-ac7a-d38e3eac64e6",
   "metadata": {},
   "source": [
    "We will be looking at two situations in which Machine learning and Neural network come in handy.\n",
    "\n",
    "We may be wondering how our linear model will solve our cats and dogs problem.\n",
    "Y = XW + B\n",
    "\n",
    "It depends on the data.\n",
    "\n",
    "We have a scatter plot of  a dataset consisting of animal photos.\n",
    "\n",
    "Let the blue dots represents the dogs and the orange dots represent the cats.\n",
    "\n",
    "A linear model or a straigth line can solve this problem easily.\n",
    "Every thing below the line is one category and every thing above it is the other.\n",
    "\n",
    "In this situation, we have a classification problem.\n",
    "\n",
    "We are trying to classify the photos into dogs and cats.\n",
    "\n",
    "Such a model is called the linear classifier.\n",
    "\n",
    "This is because the data represented in the graph is linearly seperable.\n",
    "\n",
    "What about in a case ,we have about 4 categories all twined together.\n",
    "\n",
    "The data is non linearly seperable , therefore,we must use a non linear model. We will learn this under deep neural networks\n",
    "\n",
    "In our apartment picture y = XW + B\n",
    "A linear model represents the data well. this is the well known linear relationships.\n",
    "\n",
    "However, different regresion problems may not necessarily be solved by a linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df0f61c-7725-47da-a4c4-01e5a922ecac",
   "metadata": {},
   "source": [
    "#### The Objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05795b2b-5733-468d-8c4f-34ce94c47aa6",
   "metadata": {},
   "source": [
    "Objective function is the third building block of the machine learning algorithm\n",
    "\n",
    "This  is a measure used to  evaluate how well the model output match the desired  \n",
    "correct values.\n",
    "\n",
    "Objective funs=ctions are generally split into two types\n",
    "\n",
    "+ loss or cost function\n",
    "\n",
    "the lower the loss function the higher the level of accuracy of the model.\n",
    "Most often we work with loss function.\n",
    "An intuitive example is the loss function that \n",
    "measure the error of prediction.\n",
    "We want to minimize the error of prediction thus minimize the loss\n",
    "\n",
    "+ Reward functions:\n",
    "\n",
    "They are basically the opposite of loss functions.\n",
    "\n",
    "The higher the reward function the higher the level of accuracy of the model.\n",
    "Usually reward functions are used in\n",
    "reinforced learning where the goal is  to maximize the specific result. eg is the algorithm we mentioned earler , the one playing super mario, the score obtained by the algorithm for playing the game is the reward function.\n",
    "\n",
    "Maximizing the final score will mean maximizing the reward function.\n",
    "\n",
    "when dealing with surpervised learning we normally \n",
    "enconter loss function therefore we will be dealing mostly with loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d1107a-3a55-4d17-9c1d-ee332c0d94c0",
   "metadata": {},
   "source": [
    "#### L2- norm Loss "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c206d93-0404-4333-9498-dde3a0058a14",
   "metadata": {},
   "source": [
    "Earlier we divided supervised learning into two types:\n",
    "\n",
    "+ Regression \n",
    "+ Classification\n",
    "\n",
    "\n",
    "We will be discussing two of the most common type of loss function, each is used with two tyoes of machine learning\n",
    "\n",
    "I.Categorical - Cross - entropy\n",
    "\n",
    "Ii. Regression - L2 norm continuous number\n",
    "\n",
    "Note that the objective function is a seperate block in our framework from the  model\n",
    "\n",
    "This is to say that this lecture applies to all model regardless of this  linearity .\n",
    "\n",
    "We will define another concept called the target denoted by T\n",
    "\n",
    "The target is the desired value at which we are aiming.\n",
    "\n",
    "Generally ,we want our output  to be as close as possible to the target T.\n",
    "\n",
    "In the cats and dogs example we have been employing so far, the target will be the lebals we asign to each foyer, so we are 100 % sure that thses values are correct. They are the values we aspire to \n",
    "\n",
    "The y values are the output of our models. The machine learning algorithm aims to find a function of x that outputs values close to the target as possible using this new notation , the loss function evaluates the accuracy of the output regarding the target.\n",
    "\n",
    "Looking at the two common function we talked about that are involed with loss function.\n",
    "\n",
    "I .Regression \n",
    "Ii.Classification\n",
    "\n",
    "+ Regresion : The output of a regression are a continuous number. a commonly used loss function is the squared loss also called the L2- Norm loss in  machine learning.\n",
    "THe method for calculating it equals the \n",
    "least squared method used in statistics.\n",
    "L2-norm ->  OLS(statistics)\n",
    "\n",
    "Mathematically , it looks like this \n",
    "L2-norm = Σi (yi -ti)2 \n",
    "\n",
    "Naturally,he lower the sum is ,\n",
    "the lower the error of prediction, therefore  the lower the cost function(The loss)\n",
    "\n",
    "\"norm\" comes from the fact it is the vector norm, or Euclidean distance of the outputs and the targets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c50ba3-7e09-4f01-8e0c-5d0cc24732ec",
   "metadata": {},
   "source": [
    "#### Cross-entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974d04fd-3d71-49b0-a9b3-de9032af6c1f",
   "metadata": {},
   "source": [
    "We discussed that the output of a \n",
    "\n",
    "regression is number( Numbers 1, \n",
    "\n",
    "10,1.21) but \n",
    "\n",
    "for classification things are different sinnce the outputs are categories like cats and dogs. we need a beter suited strategy.\n",
    "\n",
    "The most common loss function used for classification is Cross-entropy loss, and it is defined as Lof y and t minus the sum of the target ,times the natural log of the output.\n",
    "\n",
    "Cross-entropy = L(y,t) = - Σi t, in yi \n",
    "\n",
    "for exampl:\n",
    "Let's consider our cats and dogs problem, we will introduce a 3rd category Horse\n",
    "\n",
    "Cat       Dog        Horse\n",
    "\n",
    "We have an image labelled as dog but how does it look in numerical terms.\n",
    "\n",
    "The target vectoe t will be \n",
    "\n",
    "T = [ 0, 1  , 0]\n",
    "\n",
    "The fiest zero means ti is not a cat, the second the 1 chosen is a Dog and the 3rd 0 means ,it is not a horse\n",
    "\n",
    "Lets examine a different image\n",
    "\n",
    "Cat     Dog         Horse\n",
    "\n",
    "This time the target image is horse and is labelled 1,\n",
    "\n",
    "Imagine , if the output of our model for the two images are  as follows;"
   ]
  },
  {
   "cell_type": "raw",
   "id": "357746a3-d521-4e31-ab14-e7c4e7962bce",
   "metadata": {},
   "source": [
    "Dogs   y = [0.4, 0.4, 0.2]\n",
    "\n",
    "       t =[0, 1, 0]\n",
    "    \n",
    "     \n",
    "Horse   y = [0.1 ,0.42 0.7]\n",
    "\n",
    "        t = [0. 0 .1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7736bd-32a3-439f-bb4e-52ef0dd83d2e",
   "metadata": {},
   "source": [
    "After some machine learning transformations, this vectors show that the probability for each photo to be a cat ,a dog or a horse.\n",
    "\n",
    "We wiil learn how to create this vectors later in the course, for now all we nee to know is how to inerprete them.\n",
    "\n",
    "The first vector shows that according\n",
    "\n",
    "to our algorithm, there is a 0.4 or a \n",
    "\n",
    "4o% chance that our first photo is a \n",
    "\n",
    "cat, 40% it is a dog and 20% ,it is a Horse.\n",
    "\n",
    "The cross entropy of each photo\n",
    "\n",
    "Cross-entropy = L(y,t) = - Σi t, inyi \n",
    "\n",
    "the cross entropy loss of the first \n",
    "\n",
    "image is -0 times 0.4 minus 1 times \n",
    "\n",
    "natural log of 0.4- 0 times natural log\n",
    "\n",
    "of 0.2 = 0.92\n",
    "\n",
    "L(y,t) = -0 x in 0.4 - 1 x in 0.4- 0 x\n",
    "\n",
    "0.2 = 0.92\n",
    "\n",
    "\n",
    "the cross entropy loss of the second \n",
    "\n",
    "image is -0 times 0.1 minus 0 times \n",
    "\n",
    "natural log of 0.2 -0 times natural log\n",
    "\n",
    "of 0.7 = 0.36\n",
    "\n",
    "\n",
    "L(y,t) = -0 x in 0.1 -0 x in 0.2 - \n",
    "\n",
    "1x0.7 = 0.36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0f7705-cc0b-4351-89c9-87ced319d209",
   "metadata": {},
   "source": [
    "As we already know the lower the loss function or the cross entropy in this case, the more accurate the model.\n",
    "\n",
    "What is the meaning of this two cross entropies, They show that the second loss is lower , therefore its prediction is superior. \n",
    "\n",
    "The first image the model is not sure if it is a dog or a cat. There was an eqaul 40% probability for both assumptions.\n",
    "\n",
    "We can oppose this with the second photo where the model was 70% sure it was a horse, thus the cross entropy was lower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67077a6-858d-4284-80a1-797ddd99c55d",
   "metadata": {},
   "source": [
    "An important note is that with classification our target vectors consists of a bunch of zeros and ones which indicates the correct categories ,therfore we can simplify the above formulas too. Minus the log of the probability  of the output for the correct answer\n",
    "Here is how our initial formula will change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc800474-e64f-4276-97d2-07cfd7870448",
   "metadata": {},
   "source": [
    "L(y,t) = -1 x in 0.4\n",
    "  \n",
    "L(y,t)  = -1 x in 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133c5220-2970-486c-86f8-cb0040fb940b",
   "metadata": {},
   "source": [
    "Those were examples of commonly used loss functions for regression and classification problems . Most regression and classification problems are solved by using them but there are other loss functions that can help us solve our problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c5ac3d-72b4-4b8c-a162-77914b7048b2",
   "metadata": {},
   "source": [
    "+ WE must emphasize that any function that holds the basic property : \n",
    "\n",
    "+ Of being higher for worse results \n",
    "\n",
    "+ And lower for better results can be a loss function.\n",
    "\n",
    "+ We will often use this observation when coding.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d29ca1-52ee-4290-8f01-8e08590a115a",
   "metadata": {},
   "source": [
    "#### One-parameter gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217062d8-124f-42e7-8868-6b2d5b092432",
   "metadata": {},
   "source": [
    "We have learnt conceptually , how to input data into a model. We also measured how close to the target are the output we obtained through the objective function.\n",
    "However,the actual optimization process happens when the optimization algorithm varies the model's pararmeter till the loss function has been minimized.\n",
    "\n",
    "In the context of the linear model,this immplies\n",
    "varying w and b.\n",
    "\n",
    "The simplest and the most fundamental optimization algorithm is the \"Gradient Descent\"\n",
    "\n",
    "The gradient is the multi -variance generallization of the derivative concept.\n",
    "\n",
    "f'(X) -> ▽Fx(X1,X2,...,XN)\n",
    "\n",
    "Let's consider a non machine learning example so as to understand the logic behind the gradient descent.\n",
    "Here is a function of F of x equal to 3 x X2 plus 3 x X \n",
    "minus 4\n",
    "\n",
    "f(X) = 5X^2 + 3X - 4\n",
    "\n",
    "Goal: To find the minimum of this function using the gradient descent methodology.\n",
    "\n",
    "Step 1:\n",
    "Find the first derivative of the function in our case, it is 10 times x plus 3\n",
    "f(X) = 10X + 3\n",
    "\n",
    "Step 2:\n",
    "Choose any arbitrary number\n",
    "For example x non = 4\n",
    "x non is the proper way to say x zero.\n",
    "X0 = 4\n",
    "then we calculate a different number X1 following the update rule\n",
    "X1 =?\n",
    "\n",
    "Xi plus 1 = Xi- eta times the first derivative of the function and xi\n",
    "\n",
    "Xi+1 = Xi -ηf'(Xi)\n",
    "\n",
    "X1 = 4 - η[10*4 +3] =\n",
    "\n",
    "X1 = 4 - η43\n",
    "\n",
    "η(eta) is the learning rate\n",
    "\n",
    "It is the rate at which the machine learning algorithm forgets old believes for new ones.\n",
    "\n",
    "We choose the learning rate for each case\n",
    "\n",
    "Using the update rule , we can find X2 X3 and so on.\n",
    "\n",
    "X2 = X1 -ηf'(X1)\n",
    "\n",
    "X3 = X2 -ηf'(X2)\n",
    "\n",
    "After conducting the updat operation long enough, the values will evantually stop updating.That is the point at which we know we have reached the minimum of the function.\n",
    "This is because the first derivative of the fuction is 0 when we have reached the minimum.\n",
    "So the first derivative :\n",
    "Xi+1 = Xi -ηf'(Xi)\n",
    "\n",
    "Will now become xi plus 1 = xi- 0 \n",
    "or Xi plus 1 = xi\n",
    "\n",
    "Xi + 1 = Xi-o \n",
    "\n",
    "or\n",
    "\n",
    "Xi + 1 = Xi\n",
    "\n",
    "\n",
    "Therefore, the update rule will no longer update."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aba8ce-65c7-4b44-8e33-8fd99018561d",
   "metadata": {},
   "source": [
    "+ Gradint descent function example:\n",
    "\n",
    "Searching for the minimum of 5x^2+3x-4 \n",
    "Update rule: Xi+1 = Xi -η*f'(Xi)\n",
    "    \n",
    "Let's take an eta of 0.01 , we start descending.\n",
    "Learning rate η(eta) = 0.01"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0065650-5071-4718-b36a-98b73901c0fd",
   "metadata": {},
   "source": [
    "Xi       Value        F(xi)                   \n",
    "\n",
    " 0       4.00          43.00\n",
    " \n",
    " 1       3.57          38.70\n",
    " 2        3.18         34.83\n",
    " 3        2.83          31.35\n",
    " 4        2.52         28.21\n",
    " 5        2.24         25.39\n",
    " 6        1.99         22.85\n",
    "    \n",
    ".\n",
    ".\n",
    ".\n",
    ".\n",
    "    \n",
    "    \n",
    "85         -0. 30            0.01\n",
    "86          -0.30            0.00\n",
    "87          -0.30            0.00\n",
    "88          -0.30            0.00\n",
    "89          -0.30            0.00\n",
    "90          -0.30            0.00\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4eaa75-4a1a-4526-8e95-fd5658b7d0ae",
   "metadata": {},
   "source": [
    "Around the 86th observation,ouer sequence doesnt change anymore, it is coverged to -0.30 , once the minimum is reached all subsequent values are equal to it.\n",
    "\n",
    "Hence ,pur update rule has become \n",
    "\n",
    "Xi+1 = Xi - 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582bfc3e-2f04-4a0f-9805-d75952fde0f4",
   "metadata": {},
   "source": [
    "Graphically ,gradent descent has an oval shape. we start from any arbitrary point and descend to the minimum.\n",
    "\n",
    "The speed of minimization depends on the etta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74130065-8ac8-47fd-b8f4-54563d2d87ef",
   "metadata": {},
   "source": [
    "Let's try with an etta of 0.1, we hvave converged to the minimal of -0.3 after the first iteration. Now knowing the minimal is -0.3.\n",
    "\n",
    "Lets check out an eta of 0.001, this step is so small that we need at least 900 iterations before we reached the desires value, we descend to the same extreme but in a much slower manner.\n",
    "\n",
    "Finally, lets try with an eta of 0.2, we obtained a sequence of 4 and -4.6 until infinity.\n",
    "\n",
    "No matter how many iterations we excute , our seqeunce will never raech -0.3, we already know -0.30 is the desired value, but if we didnt, we will be deceived.\n",
    "\n",
    "This situation is called Oscilliation, we built around the minimum value but we never reach it.\n",
    "\n",
    "We can use 4 or -4.6 in the algorithm but this will not be its true minimum.\n",
    "\n",
    "Grapghically we are stuck into these 2 points.\n",
    "Never reaching the minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d22a1f3-4140-4955-a9d4-ab4abb61669c",
   "metadata": {},
   "source": [
    "Now that we have seen different learning rate and its performance,lets state this rule.\n",
    "\n",
    "Generally, we want the learning rate to be high enough so that we can reach the closest minimum after repeating the operation in a rational amount of time.\n",
    "\n",
    "So perhaps,0.001 was too small for this function.\n",
    "\n",
    "At the same time, we want eta to be low enough so we are sure enough we reach the minimum , so we don't oscillate around the minimum.\n",
    "\n",
    "Like in the case where we choose an eta of 0.2.\n",
    "\n",
    "In deep learning, we will discuss a few smaller techniques that will allow us to chose the right rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc519db3-c4a9-4640-b686-dbe8baf87ca9",
   "metadata": {},
   "source": [
    "+ Key take aways\n",
    "\n",
    "1. Using gradeint descent,we can find the minimum value of our function through a trial and error method.(that's just how computers think)\n",
    "\n",
    "2. There is an updaterule tha allows us to chery -pick the trials so we can reach the minimum faster, Each consequent trial is better than the previous one with a nice update rule.\n",
    "\n",
    "3. We must think about the learning rate which has to be high enough so we don't iterate forever but low enough so we don't oscillate forever.\n",
    "\n",
    "4. Finally, once we have converged we should stop updating or as we see in the coding example we should break the loop.\n",
    "One way to know we have converged is when the diffence between the terminal place i +1 and place 1 is 0.001\n",
    "\n",
    "Xi+1 = Xi = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c5d93b-9fc8-4da9-ac70-b675cc6edf21",
   "metadata": {},
   "source": [
    "+ Download and look at the excel file available in the course resources. you can play around with the learning rate and arbitrary choose the number X9 and see what happens . this will give you a good intuition about the learning rate which is essential to teaching the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a8c8c3-c348-4178-899e-fef9a176ac39",
   "metadata": {},
   "source": [
    "#### N-parameter gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0b59f6-0d21-4c98-8c74-8df2a0979fd6",
   "metadata": {},
   "source": [
    "If we want to create working models that can be easily adapted to \"Different problems\", you must understand the drivers of a machine learning algorithm. This is why we have covered several theoritical steps. This is where the introductory part ends .\n",
    "We will step on the 1 - Dimentional gradient descent concept and explain the concept (N- Dimentional) of the gradient descent used in machine learning.\n",
    "\n",
    "In addition ,we will enploy what we have learnt about linear model and loss functons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ada8a9-865b-4f8b-8415-447ae90ae879",
   "metadata": {},
   "source": [
    "Let's consider the linear model we have studied so far\n",
    "\n",
    "Xw + B = y  - > Model\n",
    "\n",
    "Now each output can be represented using the linear model equation with the input which is just a corresponding xi\n",
    "\n",
    "Xiw + B = yi ->  Single observation\n",
    "\n",
    "Weigth and bias remain unchanged.\n",
    "\n",
    "Using our apartment size example,yi will be the price of a single apartment, the corresponding xi will be information we have about the apartment.\n",
    "\n",
    "743 X 336.1 - 3237.51 = 246.484.79\n",
    "\n",
    "In essence, we are taking a single observation, Therefore the output yi is a scaler and it is equal to the corresponding xi x w plus the bias\n",
    "\n",
    "Naturally , we are interested in the i of target ,so ti. This will be the target to which we will compare the output y \n",
    "\n",
    "model :Xiw + B = yi -> ti\n",
    "\n",
    "\n",
    "Now, is time to pick the loss function we will use.\n",
    "\n",
    "Usually,we denote the loss function with L and in bracket we put the output and the target as the loss function depends on this arguement.\n",
    "\n",
    "L(y,t) -> loss\n",
    "\n",
    "L is for loss but we can have C for cost\n",
    "C(y,t) -> cost\n",
    "\n",
    "And E for error and so on\n",
    "E(y,t) -> error.\n",
    "\n",
    "Depending on the frame work you are using, notations could differ though bearing thesame meaning.\n",
    "\n",
    "Since, we have only discussed two types of loss function\n",
    "\n",
    "+ L2-norm loss\n",
    "\n",
    "+ Cross -entropy\n",
    "\n",
    "Our choice will be limited to them\n",
    "\n",
    "We will look into a regression example  using the l2-norm loss.\n",
    "\n",
    "Loss: L(y,t) = L2-norm /2  = Σi (yi - ti)2 / 2\n",
    "\n",
    "This is conventional \n",
    "\n",
    "This is because a division by the constant of two does not change the nature of the loss function as it is still lower for better predictions,. The machine learning algorithm will not be affected we emphasize this in the  objective function lecture.\n",
    "\n",
    "\" Any function that holds the basic property :\n",
    "\n",
    "+ higher or worse results \n",
    "\n",
    "+ lower for better results \n",
    "\n",
    "Can be a loss function\n",
    "Division by some constant changes nothing.\n",
    "Make sure you know what the gradient(▽) is, unless you are working in the Multi dimensional space.\n",
    "\n",
    "To perform the gradient descent we need old believes to be updated on each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31272dc7-517f-443e-82e9-788fa9846376",
   "metadata": {},
   "source": [
    "#### Update Rule:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc124d5a-5585-435a-92cd-79bd7a54c9eb",
   "metadata": {},
   "source": [
    "xi plus 1 = xi minus eta times the first derivative\n",
    "Xi + 1 = xi-ηf'(xi)\n",
    "\n",
    "becomes wi plus 1 = wi minus eta times the gradient of the loss function with wi for the weight\n",
    "\n",
    "wi + 1 = wi - η▽wL(y,t)\n",
    "\n",
    "bi plus 1 equals bi minus eta times the gradient of the loss function with respect to bi for the biases\n",
    "\n",
    "bi + 1 = bi- η▽bL(y,t)\n",
    "\n",
    "It is basically thesame but for a matrix w and a vector b instead of a number x\n",
    "\n",
    "We want to minimize the loss function by varying the weight and the biases, which means we are trying to optimize the loss function regarding w and b\n",
    "\n",
    "automatically it looks likes this\n",
    "\n",
    "          wi + 1 = wi - η▽wL(y,t)\n",
    "Optimization:\n",
    "         bi + 1 = bi- η▽bL(y,t)\n",
    "         \n",
    "The gradient with respect to w of the loss function is equal to the sum of the gradient of 1/2 times (yi minus ti)2 with respect to w\n",
    " \n",
    " ▽wL= Σi▽w1/2(yi-ti)2 = \n",
    " \n",
    " from the linear model yi= xi times w plus the bias where w and x are matrics and this is why we requrie both formating\n",
    "    |\n",
    "    xiw + b\n",
    "so let's plot that in the formula:\n",
    "so running the operation we obtain the sum of xi times yi minus ti\n",
    "             \n",
    "full derivation in\n",
    "course notes         = ΣiXi (yi-ti) =\n",
    "                     \n",
    "                     = ΣiXiði\n",
    "\n",
    "It is useful to combine yi minus ti into a new variable called delta  (ð ) .\n",
    "delta is often used to measure differences.\n",
    "This notion will come in handy when we start coding in python and when we  start dealing with dipper neural networks.\n",
    "\n",
    "The final output becomes the sum of xi times delta i with respect to i,\n",
    "\n",
    "▽wL=ΣiXiði\n",
    "\n",
    "So we calculate that observation for each expression and then sum them all.\n",
    "\n",
    "In  analogically the gradient of the loss function with respect to the bias  is the sum of delta i, notice that the 1/2 we introduced cancelled out the two we obtained when differentiating the square , that is why we included it to get a neater result.\n",
    "\n",
    "▽wL=Σiði\n",
    "\n",
    "Finally, lets go back to our Update rule,\n",
    "We said that the generalized rule is wi plus 1 equals wi minus eta times the gradient of the loss function with respect to wi\n",
    "\n",
    "wi + 1 = wi - η*▽l(wi)\n",
    "\n",
    "Replacing the gradient with what we found here \n",
    "\n",
    "wi + 1 = wi - η*ΣiXiði\n",
    "\n",
    "\n",
    "         wi + 1 = wi -η*ΣiXiði\n",
    "         \n",
    "Optimization:\n",
    "\n",
    "         bi + 1 = bi- η Σiði\n",
    "\n",
    "\n",
    "In anologically, the update rule for the biases is bi plus 1 equals b1 minus eta times the sum of delta i\n",
    "  \n",
    "     bi + 1 =  bi- η Σiði\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bbac05-c8b0-43d9-a4c8-2380d505aa6c",
   "metadata": {},
   "source": [
    "This was the generalized gradient descent of a linear model, we can use it to minimize the cost function and train our model to enable it to produce valuable insight from our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23543cbd-13e7-4c90-b90b-cc41a7238183",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Required Reading: Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d53dc9-4a7f-4cf1-9394-af38a5a55cc4",
   "metadata": {},
   "source": [
    "+ Neural Networks\n",
    "\n",
    "Perceptrons\n",
    "\n",
    "The perceptron is a binary linear classifier that is only capable of predicting\n",
    "classes of samples if those samples can be separated via a straight line. The\n",
    "perceptron algorithm was introduced by Frank Rosenblatt in 1957. It\n",
    "classifies samples using hand crafted features which represents information\n",
    "about the samples, weighs the features on how important they are to the\n",
    "final prediction and the resulting computation is compared against a\n",
    "threshold value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a2aa08-5c54-41a4-ab29-3692a807d885",
   "metadata": {},
   "source": [
    "In the image above, X represents the inputs to the model and W represents\n",
    "the weights (how important are individual features). A linear computation\n",
    "of the weighted sum of features is carried out during the formula below:\n",
    "\n",
    "Z = W0X0 + W1X1 + ...+ WmXm\n",
    "\n",
    "\n",
    "The value of z is then passed through a step function to predict the class of\n",
    "the sample. A step function is an instant transformation of a value from 0 to\n",
    "1. What this means is that if z is greater than or equal to 0, its predicts one\n",
    "class, else it predicts the other. The step function can be represented\n",
    "mathematically as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9921888a-445d-4064-a753-75053e87cdc8",
   "metadata": {},
   "source": [
    "f(x) = {1  if w .x+ b > 0\n",
    "        \n",
    "       {0  otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf9254d-48e3-445f-9ac4-76cb5c35d330",
   "metadata": {},
   "source": [
    "At each iteration, the predicted class gets compared to the actual class and\n",
    "the weights gets updated if the prediction was wrong else it is left\n",
    "unchanged in the case of a correct prediction. Updates of weights continue\n",
    "until all samples are correctly predicted, at which point we can say that the\n",
    "perceptron classifier has found a linear decision boundary that perfectly\n",
    "separates all samples into two mutually exclusive classes.\n",
    "\n",
    "\n",
    "During training the weights are updated by adding a small value to the\n",
    "original weights. The amount added is determined by the perceptron\n",
    "learning rule. The weight update process can be experienced\n",
    "mathematically as shown below.\n",
    "\n",
    "\n",
    "Wj := wj + Δwj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cc2f07-7264-449b-a84f-0aca42020d34",
   "metadata": {},
   "source": [
    "The amount by which weights are updated is given by the perceptron\n",
    "learning rule below.\n",
    "\n",
    "\n",
    "Δwj = η(y^(i)-ŷ^(i)) x^(i)j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd18d15d-95b1-4bc1-bb6a-0524c0ca82c0",
   "metadata": {},
   "source": [
    "The first coefficient on the right hand side of the equation is called the\n",
    "learning rate and acts as a scaling factor to increase or decrease the extent\n",
    "of the update.\n",
    "\n",
    "The intuitive understanding of the above equation is that with\n",
    "each pass through the training set, the weights of misclassified examples are\n",
    "nudged in the correct direction so that the value of z can be such that the\n",
    "step function correctly classifies the sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddaab74-1b0f-4730-b27e-ea0c3ae2d6e3",
   "metadata": {},
   "source": [
    "It should be noted that the perceptron learning algorithm described is severely limited as it can only\n",
    "learn simple functions that have a clear linear boundary. The perceptron is\n",
    "almost never used in practice but served as an integral building block\n",
    "during the earlier development of artificial neural networks.\n",
    "\n",
    "\n",
    "Modern iterations are known as multi-layer perceptrons. Multi-layer\n",
    "perceptrons are feed forward neural networks that have several nodes in the\n",
    "structure of a perceptron. However, there are important differences. A\n",
    "multilayer perceptron is made up of multiple layers of neurons stacked to\n",
    "form a network. The activation functions used are non-linear unlike the\n",
    "perceptron model that uses a step function. Nonlinear activations are\n",
    "capable of capturing more interesting representations of data and as such do\n",
    "not require input data to be linearly separable. The other important\n",
    "difference is that multi-layer perceptrons are trained using a different kind\n",
    "of algorithm called backpropagation which enables training across multiple\n",
    "layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58d46d2-5d36-4a5e-b51b-b24af48a0e42",
   "metadata": {},
   "source": [
    "+ Backpropagation\n",
    "\n",
    "Backpropagation is an algorithm technique that is used to solve the issue of\n",
    "credit assignment in artificial neural networks. What that means is that it is\n",
    "used to determine how much an input’s features and weights contribute to\n",
    "the final output of the model. Unlike the perceptron learning rule,\n",
    "backpropagation is used to calculate the gradients, which tell us how much\n",
    "a change in the parameters of the model affects the final output. The\n",
    "gradients are used to train the model by using them as an error signal to\n",
    "indicate to the model how far off its predictions are from the ground truth.\n",
    "The backpropagation algorithm can be thought of as the chain rule of\n",
    "derivatives applied across layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9a1803-8043-481c-88bc-95937729ffba",
   "metadata": {},
   "source": [
    "Let us look at a full fledged illustration of a multi-layer perceptron to\n",
    "understand things further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3270854-a2af-4865-bf95-d8b7b874d2e8",
   "metadata": {},
   "source": [
    "In the diagram , we have \n",
    "\n",
    "inputs-> input layer -> Hidden layer-> output layer -> outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ef364d-6b0a-4102-8700-52776562997c",
   "metadata": {},
   "source": [
    "The network above is made up of three layers, the input layer which are the\n",
    "features fed into the network, the hidden layer which is so called because\n",
    "we cannot observe what goes on inside and the output layer, through which\n",
    "we get the prediction of the model. \n",
    "\n",
    "During training, in order to calculate by\n",
    "how each node contributes to the final prediction and adjust them\n",
    "accordingly to yield a higher accuracy across samples, we need to change\n",
    "the weights using the backpropagation algorithm. It is the weights that are\n",
    "learned during the training process hence they are sometimes referred to as\n",
    "the learnable parameters of the model. To visually understand what goes on\n",
    "during backpropagation, lets us look at the image of a single node below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fdc1c2-5ece-453e-8e8b-725d49a48961",
   "metadata": {},
   "source": [
    "In the node above x and y are the input features while f is the nonlinear\n",
    "activation function. During training computations are calculated in a\n",
    "forward fashion from the inputs, across the hidden layers, all the way to the\n",
    "output. This is known as the forward pass denoted by green arrows in the\n",
    "image. The prediction of the model is then compared to the ground truth\n",
    "and the error is propagated backwards. This is known as the backward pass\n",
    "and assigns the amount by which every node is responsible for the\n",
    "computed error through the backpropagation algorithm. It is depicted with\n",
    "red arrows in the image above. This process continues until the model finds\n",
    "a set of weights that captures the underlying data representation and\n",
    "correctly predicts majority of samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d9d1ac-2d20-4810-9498-cfc1feff4266",
   "metadata": {},
   "source": [
    "+ How to run the Neural Network using TensorFlow\n",
    "\n",
    "For our hands on example, we would do image classification using the\n",
    "MNIST handwritten digits database which contains pictures of handwritten\n",
    "digits ranging from 0 to 9 in black and white. The task is to train a neural\n",
    "network that given an input digit image, it can predict the class of the\n",
    "number contained therein.\n",
    "\n",
    "+ How to get our data\n",
    "\n",
    "TensorFlow includes several preloaded datasets which we can use to learn\n",
    "or test out our ideas during experimentation. The MNIST database is one of\n",
    "such cleaned up datasets that is simple and easy to understand. Each data\n",
    "point is a black and white image with only one color channel. Each pixel in\n",
    "the image denotes the brightness of that point with 0 indicating black and\n",
    "255 white. The numbers range from 0 to 255 for 784 points in a 28 × 28\n",
    "grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923e2678-6878-4aa9-8f69-767faa6f82e4",
   "metadata": {},
   "source": [
    "Let’s go ahead and load the data from TensorFlow along with importing\n",
    "other relevant libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2387b039-d090-42f5-8468-c27b54a8fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8c2b88-53db-4718-89e1-3d582a4c4c3b",
   "metadata": {},
   "source": [
    "Let us use the matplotlib library to display an image to see what it looks\n",
    "like by running the following lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cda269-3dc7-43d4-a04c-f788ee759efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(mnist.train.images[8], [28, 28]), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a1c7c4-66be-4228-b301-eb9ec5ec0715",
   "metadata": {},
   "source": [
    "The displayed image is a handwritten digit of number 9.\n",
    "\n",
    "How to train and test the data\n",
    "\n",
    "In order to train an artificial neural network model on our data, we first\n",
    "need to define the parameters that describe the computation graph such as\n",
    "number of neurons in each hidden layer, number of hidden layers, input\n",
    "size, number of output classes etc. Each image in the dataset is 28 by 28\n",
    "pixels therefore, the input shape is 784 which is 28 × 28."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c699918d-80a1-4025-92dd-72ad99113cc4",
   "metadata": {},
   "source": [
    "+ Parameters\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "num_steps = 500\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "display_step = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11a1171-8edd-44c7-8330-b7b3357e3e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 10 # 1st layer number of neurons\n",
    "n_hidden_2 = 10 # 2nd layer number of neurons\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ce3c7e-510a-427b-b70f-2c85236858bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb04b6ee-475c-4a72-bc0e-fc6608261829",
   "metadata": {},
   "source": [
    "We then declare weights and biases which are trainable parameters and\n",
    "initialise them randomly to very small values. The declarations are stored in\n",
    "a Python dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c65746-03d3-4ffe-9636-1c554e9cfd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    " 'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    " 'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    " 'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n",
    "    }\n",
    "biases = {\n",
    " 'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    " 'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    " 'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddb7628-a1bc-4b36-baa5-9e42df33e0c9",
   "metadata": {},
   "source": [
    "We are would then describe a 3-layer neural network with 10 units in the\n",
    "output for each of the class digits and define the model by creating a\n",
    "function which forward propagates the inputs through the layers. Note that\n",
    "we are still describing all these operations on the computation grap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e88e644-3ded-42bf-9800-7b8937292c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "def neural_net(x):\n",
    " # Hidden fully connected layer with 10 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb27178-59d4-4286-a08c-72c3621b858c",
   "metadata": {},
   "outputs": [],
   "source": [
    " layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    " # Hidden fully connected layer with 10 neurons\n",
    " layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    " # Output fully connected layer with a neuron for each class\n",
    " out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    " return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f3bbee-b703-4591-9aef-582b33377755",
   "metadata": {},
   "source": [
    "Next we call our function, define the loss objective, choose the optimizer\n",
    "that would be used to train the model and initialise all variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64036f2f-8f0a-4712-8dc9-a331e41756e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "logits = neural_net(X)\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    " logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13784041-580a-4deb-9462-4d4db888cced",
   "metadata": {},
   "source": [
    "Finally, we create a session, supply images in batches to the model for\n",
    "training and print the loss and accuracy for each mini-batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3993778-8b98-4b4f-918a-ea83ad27ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922102a2-1f0f-41ea-b068-05cddc69634c",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Run the initializer\n",
    " sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a410c37-2635-458b-adf1-497db2958b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(1, num_steps+1):\n",
    " batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    " # Run optimization op (backprop)\n",
    " sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    " if step % display_step == 0 or step == 1:\n",
    " # Calculate batch loss and accuracy\n",
    " loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    " Y: batch_y})\n",
    "    \n",
    " print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    " \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    " \"{:.3f}\".format(acc))\n",
    "\n",
    " print(\"Optimization Finished!\")\n",
    "    \n",
    "    \n",
    " # Calculate accuracy for MNIST test images\n",
    " print(\"Testing Accuracy:\", \\\n",
    " sess.run(accuracy, feed_dict={X: mnist.test.images,\n",
    " Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30967156-1127-4de1-bbbe-f42e4547ccb6",
   "metadata": {},
   "source": [
    "The session was created using with , so it automatically closes after\n",
    "executing. This is the recommended way of running a session as we would\n",
    "not need to manually close it. Below is the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca7bfa-e1c4-4db8-aa11-26c082948462",
   "metadata": {},
   "source": [
    "The loss drops to 0.4863 after training for 500 steps and we achieve an\n",
    "accuracy of 85% on the test set.\n",
    "Here is the code in full:\n",
    "    \n",
    "    # Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da1827c-cf35-4b30-a941-16dce73933ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "num_steps = 500\n",
    "batch_size = 128\n",
    "display_step = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a83671-2e04-46cd-a48d-b286af51f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 10 # 1st layer number of neurons\n",
    "n_hidden_2 = 10 # 2nd layer number of neurons\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c2d4eb-6633-4b70-992d-11d7ff8d0cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6a9bce-9abb-4fbe-b49d-a815035b3d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    " 'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    " 'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    " 'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n",
    "}\n",
    "biases = {\n",
    " 'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    " 'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    " 'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eb045f-fd02-485f-9e28-e4aed2899020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "def neural_net(x):\n",
    " # Hidden fully connected layer with 10 neurons\n",
    " layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    " # Hidden fully connected layer with 10 neurons\n",
    " layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    " # Output fully connected layer with a neuron for each class\n",
    " out_layer = tf.matmul(layer_2, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed4a16e-e1f2-43c3-8eaa-0e5360c64187",
   "metadata": {},
   "outputs": [],
   "source": [
    " return out_layer\n",
    "\n",
    "# Construct model\n",
    "logits = neural_net(X)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    " logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f114e12-55b7-4c63-8b4c-6afcb26499b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e8aef8-0d66-4b27-90ad-26bee815cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    " # Run the initializer\n",
    " sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97092bd-109d-424d-bb3c-d163b48272cd",
   "metadata": {},
   "outputs": [],
   "source": [
    " for step in range(1, num_steps+1):\n",
    " batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    " # Run optimization op (backprop)\n",
    " sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    " if step % display_step == 0 or step == 1:\n",
    " # Calculate batch loss and accuracy\n",
    " loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    " Y: batch_y})\n",
    " print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    " \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    " \"{:.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129821b7-377d-4a63-8b0d-b70c537895d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimization Finished!\")\n",
    " # Calculate accuracy for MNIST test images\n",
    " print(\"Testing Accuracy:\", \\\n",
    " sess.run(accuracy, feed_dict={X: mnist.test.images,\n",
    " Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a689022-8dc4-4eef-8265-12fd7f37c7fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc05802-0d68-42c6-b137-616f7c28a292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67a645e6-d93f-441f-8e8f-e37af089db8e",
   "metadata": {},
   "source": [
    "feed compare  optimization   - gradient descent\n",
    "\n",
    "is a derivative concept\n",
    "\n",
    "it means finding the smallest number or the minimum number. once it gets to the minimun the gradient stops . -0.3 is the desired minimum\n",
    "\n",
    "you start from any point and descend to the minmal\n",
    "\n",
    "f'(x) = 10x + 3\n",
    "x0 \n",
    "n(eta) = learning rate\n",
    "\n",
    "generally we want the learning rate to be high\n",
    "\n",
    "find the gradient descent using trial and error method\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b7d4c6-b67f-4df0-9a09-d9e1d2b7c524",
   "metadata": {},
   "source": [
    "N- parameter gradient descent\n",
    "\n",
    "\n",
    "N-Dimentional\n",
    "\n",
    "xw + b = y\n",
    "model: xi w + b = yi -> ti\n",
    "\n",
    "ti = target\n",
    "\n",
    "two types of loss function\n",
    "\n",
    "optimization algorithm\n",
    "\n",
    "tunning \n",
    "\n",
    "The learning rate is one of the parameters very \n",
    "important in training neural network\n",
    "\n",
    "the learning rate is an optimization tuning parameter..\n",
    "\n",
    "back propagation is an algorithm used to to determine input features.\n",
    "can be thought of as the chain rule derivaties applied accross layers \n",
    "\n",
    "it worked with chain room derivative.\n",
    "\n",
    "The library is a soft ware that you can use across a range of task\n",
    "\n",
    "tensoflow is used for training neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2fbe9-fcbd-4080-a700-eb5121838296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q git+https://github.com/tensorflow/examples.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6149365c-0601-411a-b135-a54070142f3e",
   "metadata": {},
   "source": [
    "Tensowflow is very important for neural networkimport MNIST data \n",
    "it is used for training models\n",
    "various image processing sysytems\n",
    "\n",
    "Tensowflow is designed for training neural network models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd07ad55-f94e-435d-ada6-58964db6615c",
   "metadata": {},
   "source": [
    "### Week 13 day 2 : MInimal Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273e9bf4-b64e-4a55-8cc8-c7a86168fe24",
   "metadata": {},
   "source": [
    "#### Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8c563e-768d-46d8-8b56-92679df0e0c8",
   "metadata": {},
   "source": [
    "#### Simple linera Regression minimal example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f58a6f2-5ea1-45cd-89f1-624a39bc89f0",
   "metadata": {},
   "source": [
    "+ We will be creating our first machine learning algorithm.\n",
    "We will build the model and we will feed it with input.\n",
    "What we expect from the algorithm is to learn the underlying relationship about the data.\n",
    "\n",
    "Here is how we are going to approach the problem.\n",
    "\n",
    "+ First we will import the necessary libraries from python for the problem at hand.\n",
    "\n",
    "+Second, we will generate random data to train them. We have decided to make this example with random data as we running the code will always yield different inputs , however,the model will remain the same.In this way ,you can see the same methodology applied for a potentially infinite number of dataset as this simple examples is the basis for more sophisticated machine learning algorithms.\n",
    "It is more important to see how it works and prove that it works and acquire dep insight.\n",
    "we wil leave the wao effect for a bit later when we will deal with deep learning.\n",
    "\n",
    "+ Third , we will create the targets, these are the correct values,in our apartment example they will be the actual prices properties have. Essentially ,we will use fixed targets to be sure there is a linear relationship. In this way , when we train the algorithm we will be certain about the dependence it has to learn.\n",
    "That is a god way to prove that the optimization is actually working. We know where we want to get by creating fake targets which we would like the algorithm to figure on its ownm if he does that then we can be certain it works .\n",
    "\n",
    "+ Fourth, we will plot the training data so we can visually see it . This is the preparation phase of the lesson.\n",
    "\n",
    "In the second part, we will define the variables we need.\n",
    "\n",
    "+ fifth, we must create weigths.\n",
    "\n",
    "+ sixth, Create biases.\n",
    "\n",
    "+ seveth,Set a learning rate.\n",
    "\n",
    "At the end, we will conclude with an actual regression.\n",
    "\n",
    "Along the way, each line of code will be explained to make sure that everything is understood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e417433-6de5-4947-8342-5bbe37ae6197",
   "metadata": {},
   "source": [
    "The relevant python libraries are numpy and matplotlib.pyplot .\n",
    "\n",
    "Generally, numpy contains all the mathematical operations you will need.\n",
    "Moreover, it is extremely fast and because of this two reasons it is heavily used in data science.\n",
    "\n",
    "Matplot lib is a library used for plotting data. it provides a nice interface and requires very few arguement. it is helpful when plotting data.It creates nice graphs\n",
    "\n",
    "finally, we will import the mpl_toolkits.mplot3d as it provides us with the ability to create nice 3d graphs.\n",
    "\n",
    "This is the tool we will use to visualize the operations we are carrying out.\n",
    "\n",
    "pyplot and mplot 3d are not essential for themachine learning algorithm, the will just provide us wtih good looking plots of our data.\n",
    "\n",
    "This will provide us with an intuition about what is going on there.\n",
    "Any how , numpy is sufficient in bringing a nice algorithm on its own"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f73e893-bf61-4343-a057-fa0a3f17b77e",
   "metadata": {},
   "source": [
    "#### Generating the data (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a287ecbc-54da-4a1b-863c-b035314d38ad",
   "metadata": {},
   "source": [
    "WE will be genrating the data we will train on. This step is now part of the machine learning algorithm. Essentially, we will create a fake data with a linear realtionship. Once again we will do that to prove that the methodology is working.\n",
    "\n",
    "In real life, we will normally load the data from some external source.\n",
    "\n",
    "+ Generating the data:\n",
    "\n",
    "1.Declare a variable called observations\n",
    "This variable willcontain the size of the data set  we want o generate.\n",
    "Let's work with 1000 observations\n",
    "You can do the same with 100,000 or 10 million if you like.\n",
    "Note, that this choice will affect the speed of the algorithm.\n",
    "\n",
    "You can play around with the number  of observations , you can try 100,000 or 10 million if you like. But be careful as 10 milion may cause computers to feeze!\n",
    "\n",
    "We will create a two variable linear model called x and z\n",
    "f(x,z) = a*x + b* z + c\n",
    "\n",
    "Let's work on the inputs\n",
    "We will use the numpy method np.random.uniform(low,high,size)draw a random value from a specified interval  (low,high),where each number has an equal chance to be selected.\n",
    "This method requires three arguement:\n",
    "\n",
    "i. The lowest point of the interval\n",
    "\n",
    "ii. The highest point of the interval\n",
    "\n",
    "Iii.The size(shape)\n",
    "\n",
    "The size is actually the shape we want to generate the data, lets choose an interval from -10 to 10( you can play around with these numbers for homework.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065b5a75-1d80-4880-8042-5cdb6e60afb3",
   "metadata": {},
   "source": [
    "According to our theorem , the appropraite size is the number of observations by the number of variables.\n",
    "\n",
    "so observations by 1 as we are only talking about one varaible x.\n",
    "\n",
    "We will generate the z's in the same manner\n",
    "\n",
    "size =  n            x         k\n",
    "     number of                 number of \n",
    "     observations              variables\n",
    "     \n",
    "These are the two input variables we will feed to the algorithm   .\n",
    "\n",
    "Lets combine them in one matrix called inputs, As the theorem suggested, the input matrix should be of shape, the number of observations by the number of variables or 1000 x 2\n",
    "\n",
    "From the linear model \n",
    "inputs = n x 1 = 1000 x 2\n",
    "\n",
    "The appropriate method to use is np column stack , it literally stacks the observations into a matrix. This results in a matrix 1000 by 2\n",
    "\n",
    "np.column_stack(appropriate turples)takes a sequence of !D arrays and stacks them into a single 2D array/\\.\n",
    "\n",
    "Dimensionality is very important in linear algebra.\n",
    "We can only multiply matricesthat are compatible .\n",
    "\n",
    "We want to make sure we can multiply x times w since our linear model relies on that.\n",
    "\n",
    "In this lecture , we will print the shape of each variable , using the shape method to make sure we are working properly.\n",
    "\n",
    "The approriate method is the object in question .shape, As expected , input is a matrix of size 1000 x 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c380285-f0db-4587-9255-3926f5aba765",
   "metadata": {},
   "source": [
    "In supervised learning we must note, two major parameters : Inputs and targets\n",
    "\n",
    "We also need to generate targets\n",
    "\n",
    "the weigths and the biases are varied through the algorithm \n",
    "And the outputs are the results from the model employed, we will leave them for the computer. since we have only seen the linear model , we will do that in alinear model friendly way.\n",
    "\n",
    "Say our target will be defined by a function f(x)\n",
    "\n",
    "targets = F(x,z) = 2 * x - 3* z + 5 + noise\n",
    "(completely, arbitrary chosen , you can try different functions for homework)\n",
    "Conceptually , the algorithm mus learn that this is the function. the weigths are 2 and -3 and the bias is 5, that's the correct result. if we don't get that as the result, we haven't worked properly.\n",
    "\n",
    "\n",
    "targets = f(x,z) 2*X - 3*z + 5 + noise\n",
    "\n",
    "                  w1    w2   b      \n",
    "\n",
    "You may be wondering about the noise. It is introduced to randomize our data a bit.\n",
    "Real data always contains noise.\n",
    "It's never perfect.\n",
    "\n",
    "Introducing some small noise will make the data a bit random but the underlying linear relationship will be retained.\n",
    "\n",
    "Let's decalre the noise variable using the random. uniform vaiable once again.\n",
    "I will constraint it from -1 to +1 and it's size will match the sizes of the  x's and z's.\n",
    "\n",
    "The target value will be given according to the function we want it.\n",
    "\n",
    "The proper line of code is \n",
    "\n",
    "targets = f(x,z) 2*X - 3*z + 5 + noise\n",
    "\n",
    "                        \n",
    "The targets or a linear combination of two vectors ,1000 by 1 , a scaler an d noise, 1000 by 1 , the shape shoulfd be 1000 by 1\n",
    "We have our input and the desired targts .\n",
    "It is time to create our algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fb5eb8-4117-45c5-b739-39a1968fa80c",
   "metadata": {},
   "source": [
    "targets =f(x,z) 2* X -3*z +  5 + noise\n",
    "\n",
    "1000X1         1000X1 1000X1 scalar 1000X1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cda512-113f-4ac2-955e-2f2d042309e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Initializing the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722f511b-e4f7-41b3-8e7d-47463016197d",
   "metadata": {},
   "source": [
    "From the #D plot we can see that thier is a strong linear relationship.\n",
    "Note, that  Simple linear problems are quite visual so we can afford to plot them. let's re-examine the linear model. \n",
    "y = xw + b\n",
    "\n",
    "Our algorithm will try to find such values for w and b so the output y are closest to the target.\n",
    "\n",
    "Remember when we performed the gradient descent we started from arbitrary number then proceeded.\n",
    "Well we must do thesame thing now however , this is tricky, conventionally , we dont want to start from an arbitrary number we choose ,rather we randomly select small initial weigths. so we declare a variable called init_range and set it to 0.1.\n",
    "\n",
    "'Our initial weigths and biases will be picked randomly from the interval \n",
    "[ -0, 1,0. 1  ]\n",
    "\n",
    "that will be the radius of the range we will use to initialize the weigth and the biases.\n",
    "Our initial weigths and biases will be picked randomly from the interval -0.1 to 0.1.\n",
    "\n",
    "We will generate them as we did so far by using the random.uniform method.\n",
    "\n",
    "The size of the weigth matrix is 2 x 1 as we have 2 variables so there are two weights , one for each input variable and a single output.\n",
    "\n",
    "Let's declare the bias analogically, the appropriate shape is 1 X 1, so the bias is a scalar.  In machine learning, there are many biases as there are outputs.\n",
    "\n",
    "Each  bias refers to an output.\n",
    "If you recall the example we saw earlier about apartment prices and apartment rents, it involves two biases as there were two outputs. Let's put the weigth and biases so you see how they look like. They are small and close to zero.\n",
    "\n",
    "The first two output is the weigth(-0.02758852, - 0.0355697811)and the last is the bias (-0.05488636)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfdf16d-1ce3-4895-9c35-f290de7b1bc4",
   "metadata": {},
   "source": [
    "##### Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9953839-89d5-4010-b08f-9a25be8c439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff73eed-bf15-4f5e-a775-77d7df0a9ff6",
   "metadata": {},
   "source": [
    "##### Generate random input data to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea0926bf-5835-4646-86af-285c2244db12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "observations = 1000\n",
    "\n",
    "xs=np.random.uniform(low=-10,high=10,size=(observations,1))\n",
    "zs=np.random.uniform(-10,10,(observations,1))\n",
    "\n",
    "inputs = np.column_stack((xs,zs))\n",
    "print (inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f39a5f-91cd-4ab3-80d8-9bbc7b41aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets = f(x,z) = 2*X-3*z + 5 + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f38fb6a-28ec-42e2-b962-67345144ec9c",
   "metadata": {},
   "source": [
    "##### Create the targets we will aim at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ad8033a-449c-4ef3-8ae4-56e0f3905fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "noise= np.random.uniform(-1,1,(observations,1))\n",
    "\n",
    "targets = 2*xs-3*zs + 5 + noise\n",
    "                              \n",
    "print(targets.shape)                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f383b7-fb28-4c95-9b75-7e7d8dc1f16d",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Plot the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098d667b-0489-46a7-9db1-89e212448db4",
   "metadata": {},
   "source": [
    "The point is to see that there is a strong trend that our model should learn to reproduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24ccdb79-ee00-4d98-b161-a9cbb1227efd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with remapped shapes [original->remapped]: (1000,)  and requested shape (1000,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12084/3155651701.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Choose the axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Set labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mpl_toolkits\\mplot3d\\axes3d.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, xs, ys, zdir, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m         \u001b[1;31m# Match length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1570\u001b[1;33m         \u001b[0mzs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1572\u001b[0m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbroadcast_to\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_to\u001b[1;34m(array, shape, subok)\u001b[0m\n\u001b[0;32m    409\u001b[0m            [1, 2, 3]])\n\u001b[0;32m    410\u001b[0m     \"\"\"\n\u001b[1;32m--> 411\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_broadcast_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_to\u001b[1;34m(array, shape, subok, readonly)\u001b[0m\n\u001b[0;32m    346\u001b[0m                          'negative')\n\u001b[0;32m    347\u001b[0m     \u001b[0mextras\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m     it = np.nditer(\n\u001b[0m\u001b[0;32m    349\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'multi_index'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'refs_ok'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'zerosize_ok'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mextras\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         op_flags=['readonly'], itershape=shape, order='C')\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with remapped shapes [original->remapped]: (1000,)  and requested shape (1000,1)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In other to use the 3D plot, the objects should have a certain shape, so \n",
    "# The proper method to use is reshape and takes as arguements the dimensions\n",
    "\n",
    "targets = targets.reshape(observations,)\n",
    "\n",
    "# plotting according to the convertional matplotlib.pyplot syntax\n",
    "\n",
    "# Declare the figure\n",
    "fig = plt.figure()\n",
    "\n",
    "# A method allowing us to create the 3D plot\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Choose the axes\n",
    "ax.plot(xs, zs, targets)\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('xs')\n",
    "ax.set_ylabel('zs')\n",
    "ax.set_zlabel('Targets')\n",
    "\n",
    "# You can fiddle with the azim parameter to  plot the dat from diferent angles .Just change the value of azim=100\n",
    "# to azim = 0 ; azim = 200, or whatever. Check and see what happens.\n",
    "ax.view_init(azim=100)\n",
    "\n",
    "# So far we were just describing the plot. This mehod actually shows the plot.\n",
    "plt.show()\n",
    "targets = targets.reshape(observations,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd73d75-76a6-485c-b6f2-dee80a032fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear relationship in 2D isa straight line.\n",
    "# Linear relationship in 3D is a plane(like in the graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfa19df-b22c-4c57-8a14-0cd4420a91bf",
   "metadata": {},
   "source": [
    "##### Initializing the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5501b194-70b9-40dd-b35c-d2bfd24e49db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00578878]\n",
      " [-0.03779326]]\n",
      "[0.93875556]\n"
     ]
    }
   ],
   "source": [
    "init_range = 0.1\n",
    "\n",
    "weights = np.random.uniform(-init_range,init_range, size=(2,1))\n",
    "\n",
    "biases = np.random.uniform(-init_range,size=1)\n",
    "\n",
    "print(weights)\n",
    "print(biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b3b94a-0a1a-4b84-ab3c-6b3dd7c00c73",
   "metadata": {},
   "source": [
    "### Set a learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e7ee442-0b61-4949-8b8e-a2d85ae30b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42780e64-9d06-4258-8164-abd8f961ff5b",
   "metadata": {},
   "source": [
    "Finally , we must asssign a learning rate which we denoted with eta earlier. This learning rate is useful for this demonstartion(nothing special about it)\n",
    "\n",
    "For home work you can play around with it so as to see how eta works and how different learning rate effects the speed of optimization .\n",
    "\n",
    "We are now set, we have inputs ,, targets and arbitrary numbers for weigth and biases.  What is left is to vary the weight and biases so that our output are closest to the target.\n",
    "\n",
    "\n",
    "as we know by now,the problem boils down to minimizing the loss function with respect to weigth and biases and because this is a regression we use one last, the L2-norm function.\n",
    "\n",
    "next, let's make our model learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476b7286-1570-4e87-908f-d3a08509f782",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3af5e89-7dac-4e57-a0f2-e9701004a118",
   "metadata": {},
   "source": [
    "Since this is an iterative problem we must create a loop and alculate the loss function. We will use a fore loop with 100 iterations to complete this task.\n",
    "\n",
    "Game plan for each iteration :\n",
    "\n",
    "+ Calculate outputs \n",
    "At each iteration we will calculate the output \n",
    "\n",
    "+ compare outputs to the target through the loss function\n",
    "\n",
    "+ Print the loss\n",
    "We will print the loss for each iteration so we know how the algorithm is doing\n",
    "\n",
    "+ Adjust the weigth and biases to get a better fit of the data\n",
    "\n",
    "At the next iteration, this updated  weigth and biases will provide different output, then the procedure will be repeated.\n",
    "\n",
    "The out put creation is done following the well known linear model creation.\n",
    "\n",
    "The outputs are equal to the inputs times the weigth plus the biases.\n",
    "\n",
    "Multiplying matrices requires the dot method. we will use the numpy one\n",
    "\n",
    "np.dot(A,B) is a method used for multiplying matrices.\n",
    "Alternatively, we can use the A.dot(B) to perform the same operation.\n",
    "Now, the dot product of the input is 1000 X 2 * 2 X 1 so is a 100 X 1 matrix.\n",
    "\n",
    "When we add the bias which is the csalar , python has the element wise.\n",
    "\n",
    "This means it is added to each element of the output matrix \n",
    "Outputs = np.dot(inputs,weigths) + biases\n",
    "  |                |      |          |\n",
    "1000X1           1000X2  2X1       Scalar\n",
    "\n",
    "For simplicity lets declar a variable called deltas which will recall the difference between the outputs and the targets.\n",
    "\n",
    "We already introduced such variable in the gradient descent lecture.\n",
    "\n",
    "deltas = output - targets\n",
    "\n",
    "1000X1    1000X1   1000X1\n",
    "\n",
    "This is useful as it is part of the update rule\n",
    "\n",
    "Then we must calculate the loss, we said we will use the L2-norm loss.\n",
    "\n",
    "Pythonically speaking, deltas is a 1000 X 1  array. We are interested in the sum of its terms  \"sqaured\", following the formula for the L2-norm loss.\n",
    "\n",
    "Σi(yi-ti)2\n",
    "\n",
    "There is a numpy method called sum which will allow us to sum all the variabless in the array.\n",
    "\n",
    "np.sum(a) ia s method that allows us to sum  all the values in the array.\n",
    "\n",
    "The L2- norm requires this values to be squared.\n",
    "the code looks like this , then divide the whole expression by 2 to get the elegant update rule from the gradient descent.let's further augument the loss by dividing it by the number of observations we have. This will give us the average loss per observation or the mean loss. similarly, to the division by 2, this dooes not change the logic of the loss function. It is still lower than some accurate result will be obtained. this little improvement makes the learning independent of the number of observations.\n",
    "\n",
    "\" Division by a constant doesn't change the value of the loss as it is still lower for some more accurate result that will be obtained\" \n",
    "\n",
    "loss = np.som(deltas**2 )/ 2 / observations.\n",
    "\n",
    "\n",
    "Instead of adjusting the learning rate,we adjust the loss. That' valuable as thesame learning rate should give us similar results for both 1000 and 1 million observations.\n",
    "\n",
    "We will print the loss as we obtained at each step, as we want to keep an eye on whether it is decreasing as iterations are performed .\n",
    "\n",
    "If it is decreasing , our machine learning algorithm functions well.\n",
    "\n",
    "Finally, we must update the weigth and biases so that they are ready for the next generation\n",
    "\n",
    "Using thesame rescaliing tricks, i will also rescale the deltas.\n",
    "This is yet another way to make the algorithm more universal so the new variable is \n",
    "deltas_scaled= deltas / observations\n",
    "\n",
    "We will follow the gradient descent logic to update the weigth.\n",
    "\n",
    "The new weigth = old weigth minus the learning rate times the dot products of the input and the deltas _ scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a55604-3d79-4508-a4b4-bd6b5185744d",
   "metadata": {},
   "source": [
    "Let's update the weigths\n",
    "\n",
    "wi + wi - η Σi xiδi\n",
    "\n",
    "Note, that algebraically , dot product means sum of products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323a4811-2c71-472f-ae61-4735e88a3ed0",
   "metadata": {},
   "source": [
    "weigths= \n",
    "2X1\n",
    "\n",
    "\n",
    "weigths - learning_rate * np.dot \n",
    "2X1          Scalar\n",
    "\n",
    "(inputs,deltas_scaled)\n",
    "1000 X2      100)X1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0c78a6-3d93-4f51-8fdf-13e35e8d79ef",
   "metadata": {},
   "source": [
    "We cannot simply multiply the inputs and the deltas. This is an issue that may arise ocassionally due to the linear algebra involved.To fix it we must transpose the imput matirx using the object .T method\n",
    "\n",
    "\"inputs.T is a method used for transposing matrices\"\n",
    "\n",
    "Now the matrices are compatible\n",
    "\n",
    "2 X 1000  X 1000 X 1 = 2 X 1\n",
    "\n",
    "\n",
    "Weigths= \n",
    "2X1\n",
    "\n",
    "\n",
    "weigths - learning_rate * np.dot \n",
    "2X1          Scalar\n",
    "\n",
    "(inputs.T,deltas_scaled)\n",
    "             2 X 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7694c37-69fa-4656-9821-1e7c805f2ae8",
   "metadata": {},
   "source": [
    "Often when dealing with matrices, you find the correct way to code it through dimentionality check and Compability error, however, transposing matrices doesn't affect the information they hold, so we can do it freely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866c2ce6-bfea-46d8-bf71-0c898223909e",
   "metadata": {},
   "source": [
    "Dimentionality check :\n",
    "\n",
    "print (weigths.shape, inputs.shape, deltas_scaled.shape\n",
    "\n",
    "\n",
    "Compatibility error:\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "911aa0c0-25d7-4c56-af9e-053721e7e411",
   "metadata": {},
   "source": [
    "A = 5\n",
    "    7\n",
    "    9\n",
    "    \n",
    "    \n",
    "AT   =  5  7  9    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e0de05-d3c7-432a-89c3-d0e5427fb454",
   "metadata": {},
   "source": [
    "Now , let's update the biases, the new bias is equal to the old biases minus the learning rate times the sum of the deltas as explained in the gradient descent lecture.\n",
    "\n",
    "bi + 1 = bi - η Σi δi\n",
    "\n",
    "This is the entire algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb28960-1b86-4f1f-923f-556a6e29a11d",
   "metadata": {},
   "source": [
    "Let's recap what it does, \n",
    "first,it calculates the output for given weigth and biases\n",
    "\n",
    "Second,it calculates the loss function that compares the output to the target\n",
    "\n",
    "Third, it prints the loss so we can later analyze it.\n",
    "\n",
    "Fourth, we upate the weigth and the biases following the gradient descent methodology.\n",
    "\n",
    "When we run the code, what w get is a list of numbers that appears to be indescending order.\n",
    "\n",
    "these are the values of our average loss function.\n",
    "\n",
    "It started at a high value and at each iteration it became lower and lower until it reached the point where it almost stopped changing.\n",
    "\n",
    "This means we have almost minimized the loss function with respect to the weigth and biases.\n",
    "\n",
    "Therefore, we have found a linear function that fits the model well.\n",
    "\n",
    "The weight and the biases are optimized so are the outputs. Since the optimization process has ended we can check these values.\n",
    "\n",
    "Here we observe the values from the last iteration of the fore loop.\n",
    "\n",
    "The one that gave us the lowest loss function,\n",
    "\n",
    "In the memory of the computer, the weigth, biases and output variables are optimized as now.\n",
    "\n",
    "\"CONGRATULATIONS ! You have learnt how to create your first machine learning algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bf228c2-b67e-42a1-9d3e-6195d5a6fd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215338.56893899842\n",
      "2269638.4531803685\n",
      "744009868.1644828\n",
      "268533015371.95135\n",
      "96947863401390.97\n",
      "3.50008936253978e+16\n",
      "1.2636302794373343e+19\n",
      "4.562059186859486e+21\n",
      "1.647031126357358e+24\n",
      "5.9462436151719905e+26\n",
      "2.1467604688912212e+29\n",
      "7.750406490301115e+31\n",
      "2.7981137921701427e+34\n",
      "1.0101974398027474e+37\n",
      "3.647095662226635e+39\n",
      "1.3167036705250005e+42\n",
      "4.753668991823308e+44\n",
      "1.7162076319581002e+47\n",
      "6.195990173185164e+49\n",
      "2.2369259704553259e+52\n",
      "8.075929201684294e+54\n",
      "2.915636607202587e+57\n",
      "1.052626467241303e+60\n",
      "3.8002763334762693e+62\n",
      "1.3720061826517964e+65\n",
      "4.953326548000902e+67\n",
      "1.7882896011232775e+70\n",
      "6.4562262683374115e+72\n",
      "2.3308784886848227e+75\n",
      "8.415124103778848e+77\n",
      "3.038095465969836e+80\n",
      "1.0968375447014136e+83\n",
      "3.959890704364619e+85\n",
      "1.4296314405231282e+88\n",
      "5.161369866798319e+90\n",
      "1.8633990654364603e+93\n",
      "6.727392468820232e+95\n",
      "2.4287770810348935e+98\n",
      "8.76856543854184e+100\n",
      "3.1656976858999732e+103\n",
      "1.1429055195805187e+106\n",
      "4.126208994957355e+108\n",
      "1.4896770011501852e+111\n",
      "5.378151156346695e+113\n",
      "1.9416631818965165e+116\n",
      "7.009947847009679e+118\n",
      "2.530787485489573e+121\n",
      "9.136851566510349e+123\n",
      "3.298659291903886e+126\n",
      "1.1909083829211969e+129\n",
      "4.2995127747594785e+131\n",
      "1.5522445190095841e+134\n",
      "5.604037417774821e+136\n",
      "2.023214448188775e+139\n",
      "7.304370756655602e+141\n",
      "2.637082401148772e+144\n",
      "9.520605979799216e+146\n",
      "3.4372053820958656e+149\n",
      "1.2409274014465566e+152\n",
      "4.4800954394000574e+154\n",
      "1.617439918139937e+157\n",
      "5.8394110665259696e+159\n",
      "2.108190926997748e+162\n",
      "7.61115964271337e+164\n",
      "2.74784178060029e+167\n",
      "9.920478357645871e+169\n",
      "3.581570508874802e+172\n",
      "1.2930472551412018e+175\n",
      "4.668262707338037e+177\n",
      "1.6853735714665211e+180\n",
      "6.084670579770212e+182\n",
      "2.196736479741136e+185\n",
      "7.930833885189097e+187\n",
      "2.863253134571499e+190\n",
      "1.0337145666288311e+193\n",
      "3.731999076010966e+195\n",
      "1.3473561806107e+198\n",
      "4.8643331374300855e+200\n",
      "1.7561604876577995e+203\n",
      "6.340231171008709e+205\n",
      "2.289001010120861e+208\n",
      "8.263934678427068e+210\n",
      "2.9835118493767625e+213\n",
      "1.0771313305039081e+216\n",
      "3.88874575241081e+218\n",
      "1.4039461204622583e+221\n",
      "5.068638668236588e+223\n",
      "1.8299205058299712e+226\n",
      "6.606525493011752e+228\n",
      "2.385140717903385e+231\n",
      "8.611025947327788e+233\n",
      "3.1088215176978113e+236\n",
      "1.1223716300495107e+239\n",
      "4.052075903260149e+241\n",
      "1.4629128789594633e+244\n",
      "5.281525179979e+246\n",
      "1.9067784984293083e+249\n",
      "6.884004370280764e+251\n",
      "2.485318363359e+254\n",
      "8.972695302047778e+256\n"
     ]
    }
   ],
   "source": [
    "#create a loop with 100 iteration\n",
    "for i in range (100):\n",
    "    outputs = np.dot(inputs,weights) + biases\n",
    "    deltas = outputs - targets\n",
    "    \n",
    "    #deltas is 1000 x1 array\n",
    "    loss=np.sum(deltas ** 2) / 2 / observations\n",
    "    \n",
    "    print(loss)\n",
    "    \n",
    "    deltas_scaled=deltas / observations\n",
    "    \n",
    "    weights = weights - learning_rate * np.dot(inputs.T,deltas_scaled)\n",
    "    biases = biases - learning_rate * np.sum(deltas_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2833be-c188-4868-9a60-2d8839134b44",
   "metadata": {},
   "source": [
    "###### Print weights and biases and see if we have worked correctly.\n",
    "\n",
    "The weight seems about right , the bias is close to 5 as we want it but not really, this is because we used few iterations or inappropriate learning rate.\n",
    "\n",
    "Let's re-run the code for the loop. this will continue optimizing the algorithm for another 100 iterations\n",
    "\n",
    "The sought dependence was : \n",
    "\n",
    "t = F( xs, zs) = 2 * XS - 3* zs + 5 + noise\n",
    "\n",
    "\n",
    "We can see that the bias improved when we increase the number of iterations increased.\n",
    "\n",
    "We strongly encourage you to play around with the code for homework.Try different\n",
    "\n",
    " 1) numbers of observations\n",
    " \n",
    " 2) learning rate \n",
    " \n",
    " 3) number of iterations\n",
    " \n",
    " May be initial range for initializing the weight and biases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f41c18d1-c67f-4f93-9813-3b326a9cad2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.77451892e+124  2.77451892e+124  2.77451892e+124 ...  2.77451892e+124\n",
      "   2.77451892e+124  2.77451892e+124]\n",
      " [-4.11888741e+124 -4.11888741e+124 -4.11888741e+124 ... -4.11888741e+124\n",
      "  -4.11888741e+124 -4.11888741e+124]] [-2.54525111e+128]\n"
     ]
    }
   ],
   "source": [
    "print (weights,biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d63df6d-fd95-4373-acc3-eee351f07596",
   "metadata": {},
   "source": [
    "#### plot last outputs vs targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89f2425-81e9-40c6-8b08-aba159583d12",
   "metadata": {},
   "source": [
    "Since they are the last ones at the end of the training, they represent the final model accuracy. The closer this plot is to a 45 degree line, the closer target and output values are.\n",
    "Obviously,our model worked !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88fe5d18-8a13-48ec-939e-70d8db39efa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(outputs,targets)\n",
    "plt.xlabel('outputs')\n",
    "plt.ylabel('targets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c444305-d52c-48c9-a626-ab646f1d80d3",
   "metadata": {},
   "source": [
    "### Introduction to Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de1e128-fb7f-4773-966c-372ab1441a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a49c05b-40c0-4631-a6fe-af3b5280cdde",
   "metadata": {},
   "source": [
    "#### TensorFlow 2 Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa09e4d-c886-4575-aded-254c73433994",
   "metadata": {},
   "source": [
    "It is most widely used \n",
    "but very hard to use\n",
    "\n",
    "kios was introduced \n",
    "tf 2.0 was introduced and it has the best\n",
    "simplifies api\n",
    "simple execution\n",
    "it is an interface for tf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16036436-68ad-4bc9-b0fb-77594d33109e",
   "metadata": {},
   "source": [
    "Installing the TensorFlow package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c643050f-87a0-4832-bdc3-0a360cc706b3",
   "metadata": {},
   "source": [
    "#### A note on coding in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba15e48-11f4-47a6-a0f7-7afe7644b3c4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Tensorflow is a deep learning library developed by google"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7033ab12-bd92-4643-836e-915aa7602f21",
   "metadata": {},
   "source": [
    "Types of file formats in Tensorflow and data handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0366b43-fa60-4663-ae63-bb05cbebf362",
   "metadata": {},
   "source": [
    "Minimal example with Tensor flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c3e0f9-012f-44d0-a971-0372324d73bd",
   "metadata": {},
   "source": [
    "Tensor flow is tensor based\n",
    "tensor flow can be represented by n-dimensional array.\n",
    "\n",
    "npz files helps to organise data in a given way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de745b7e-45d0-4000-9089-4ad55f5d3fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model layout – inputs, outputs, target, weights, bias, optimizer, and loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7493aa50-eeb7-43c9-862b-f66ee41e4aca",
   "metadata": {},
   "source": [
    "We must build the model\n",
    "tf 2 is based on keras\n",
    "\n",
    "linear combination + output = output layer\n",
    "\n",
    "We must specify our output size\n",
    "\n",
    "modl.compile\n",
    "\n",
    "Stochaitic gradient descentloss function use l2-nirm loss or least sum of square\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec8b89f-aca5-4fe8-bad0-4e8c4eb096ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "You load your data from npz,s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4c8d7c-63b3-4437-a80d-32143e142c47",
   "metadata": {},
   "source": [
    "verbose = o  you will not see any result but if you cahnge it to 1 ,you will see the result, if you change it to 2 \n",
    " when it is 2 we can track the last function\n",
    "Use get weight to get the weigth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c09d83-394f-4e25-9693-113f9e4d40c6",
   "metadata": {},
   "source": [
    "#### Customizing your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293930f8-575b-4bf0-8b47-97d727b2b501",
   "metadata": {},
   "source": [
    "The learning rate is an intergral part of the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7f9cca-85a4-4a1e-bbfd-b1ac40d92069",
   "metadata": {},
   "source": [
    "#### Neural Networks (Tensor Flow): Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb2aa06-1fe5-48d7-8a14-4911bac3384d",
   "metadata": {},
   "source": [
    "1. What two types of Neural Networks are there"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929dba8b-02fd-4acf-802f-9aade8c029ed",
   "metadata": {},
   "source": [
    "Biological Neural network and Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a2669-9842-413b-bc3e-df06f2716d6b",
   "metadata": {},
   "source": [
    "\n",
    "2.  What are ANNs used for?\n",
    "\n",
    "Reproduce Human Brain Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86f06dd-0f19-4ec2-9a5e-1552f4ff649a",
   "metadata": {},
   "source": [
    "3. What are the Three Parts of a Neuron?\n",
    "\n",
    "Dendrite, Soma, Axon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109de5c4-1839-4c47-902a-96a76ad9b1f3",
   "metadata": {},
   "source": [
    "ANNs are efficient data-driven modelling tools widely used for nonlinear systems dynamic modelling and identification, due to their universal approximation capabilities and flexible structure that allow to captu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3594f5a-a969-4c9e-89c5-1b5e5afdc75c",
   "metadata": {},
   "source": [
    "4. What Problems do ANNs not solve?\n",
    "\n",
    "Geometric problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3863f5-f057-474b-9775-52025418a76d",
   "metadata": {},
   "source": [
    "5. What futuristic actions can not be performed by ANNs?\n",
    "\n",
    "Function Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e696c0-68b4-4c2c-a525-c0a70094378d",
   "metadata": {},
   "source": [
    "6. The best type of ANN is one that is built for a specific purpose and not a general purpose. \n",
    "true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18aad76-faad-47fc-85da-241e40f63efd",
   "metadata": {},
   "source": [
    "7. What 2 subjects are neural networks usually associated with?\n",
    "\n",
    "Biology & Artificial-engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcb4f84-480f-442b-aadf-9415eeb5c040",
   "metadata": {},
   "source": [
    "8. Which of the following is/are true for neural networks\n",
    "\n",
    "The training time depends on the size of the network.\n",
    "\n",
    "Neural networks can be simulated on a conventional computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99708540-2171-4267-9d3a-bbb45530b4e0",
   "metadata": {},
   "source": [
    "9. What is/are the advantages of neural networks over conventional computers?\n",
    "\n",
    "\n",
    "They have the ability to learn by example\n",
    "They are more fault tolerant\n",
    "They are more suited for real time operation due to their high 'computational' rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914b8312-4880-4348-b937-555de9853ece",
   "metadata": {},
   "source": [
    "10. What is an activation value?\n",
    "\n",
    "weighted sum of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431f2a42-aed6-4942-b49c-9eb1c0bdb9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### THe layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69549ec4-3524-407a-8cb6-aab1d43bf4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8020acf-f1e8-4fa9-ab18-5686fcd1b2b6",
   "metadata": {},
   "source": [
    "You can combine lineear and non linear function\n",
    "\n",
    "non linearity is sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d0dc4a-bab0-4796-85cb-27f5abc37039",
   "metadata": {},
   "source": [
    "Input layer  : is our first layer\n",
    "    \n",
    "output layer is the last layer\n",
    "is what we compare our output to.\n",
    "\n",
    "Hidden layers are the hidden units or nodes\n",
    "the weighrt is the number of the hidden units\n",
    "we know the input but we dont know what is inside\n",
    "Hypaparemeters are set by us before we start optimizing.\n",
    "parameters are derived through optimazation\n",
    "The weight is done with the same weigth\n",
    "\n",
    "Depth and weigth and learning rate \n",
    "are hyper parameters and they  are set by us before we start optimizing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c3f5c0-339b-411e-bb7d-c13b642005ee",
   "metadata": {},
   "source": [
    "Input layer  : is our first layer\n",
    "    \n",
    "output layer is the last layer\n",
    "is what we compare our output to.\n",
    "\n",
    "Hidden layers are the hidden units or nodes\n",
    "the weighrt is the number of the hidden units\n",
    "we know the input but we dont know what is inside\n",
    "Hypaparemeters are set by us before we start optimizing.\n",
    "parameters are derived through optimazation\n",
    "The weight is done with the same weigth\n",
    "\n",
    "Depth and weigth and learning rate \n",
    "are hyper parameters and they  are set by us before we start optimizing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f36125f-0e40-4d6f-9bce-c3a9163db286",
   "metadata": {},
   "source": [
    "An illustration of deep net\n",
    "\n",
    "input layers data  each circle reprens the data we feed to train the model we feed the model we have 8 e.g weather forecast e.g humidty , high and low temperature, ave temp, invusbibilty and distanceprecipitation, clouud cover\n",
    "\n",
    "To combine linearity we need weigth.\n",
    "weight are 8x9 matrix\n",
    "a vector of 8x9\n",
    "\n",
    "each error reps the mathematicaly expression \n",
    "erors represents weigths\n",
    "weigth is a part of the hidden layer\n",
    "non linearity does not change the shape of the experiession , it only changes its linearity.\n",
    "\n",
    "weigth has two index numbers\n",
    "\n",
    "units it refers to and ghidden units is referring to.\n",
    "\n",
    "hiden units and combine the non linearity\n",
    "\n",
    "we can add a 100 hidden layer\n",
    "\n",
    "we will reach the output layer. we decide the number of output we wan to reach ie humidty, temp, distance  etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13882873-3b23-44cf-b32d-317299d52792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
