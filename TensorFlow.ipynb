{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd2f2ef1-269a-45b8-b6f8-bb4a92febca4",
   "metadata": {},
   "source": [
    "### Week 13 Day 2: TensorFlow Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddebc42-2cfa-4caf-90ff-f05b3e4b05c6",
   "metadata": {},
   "source": [
    "#### Introduction to Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63c48af-149d-4233-b20e-1a47668524fa",
   "metadata": {},
   "source": [
    "There are python libraries tailored for machine learning.\n",
    "\n",
    "Two are Tensorflow and sklearn\n",
    "\n",
    "We are discussing on Tensorflow\n",
    "\n",
    "The mathematical concept of a Tensor could be broadly explaine din this way.\n",
    "\n",
    "If a scalar have the lowest dimensionality and is followed by a vector and then by a matrix, a tensor will be the next object in line\n",
    "\n",
    "Scalars, Vectors and Matrices are all tensors of rank 0 , 1 and 2 respectively.\n",
    "\n",
    "Tensors are simply a generalization of the concpt we have seen so far.\n",
    "\n",
    "+ Why is tensorflow a good choice?\n",
    "\n",
    "We will be comparing Tensorflow to sklearn,as they are two of the most popular libraries and most of the  machine learning courses are based on sklearn.\n",
    "\n",
    "Google is a leader in machine learning , it is also and it is also one of the great innovators in the field because of the google rating, as machine learning was developing , google needed better programmong methods to suit their needs.\n",
    "\n",
    "That is why they developed the tensorflow package for internal use.\n",
    "\n",
    "At the end of 2015, google realed Tensorflow to the public.\n",
    "\n",
    "Currently , it is probably yhre leading library for neural networks including deep neural network, convolution neural networks and recurring neural network>\n",
    "\n",
    "One of the biggest advantage of Tensorflow is that it uses not only the CPU of the computer but also its GPU.\n",
    "\n",
    "+ This is crucial for the speed of the algorithm as in this way Tensorflow utilizes much more computing power.\n",
    "The bset part is that this is done automatically.\n",
    "\n",
    "Recently, furthere its strength by introducing TPU or Tensor Proceesing  unit which imprves performance even further.\n",
    "\n",
    "Tensorflow is one of the cutting edge technology available rigth now and it is likely here to stay."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1836e8b4-d6d2-4913-b1fb-e4f8f06764e5",
   "metadata": {},
   "source": [
    "An alternative of tensorflow is sklearn,if you have done any machine learning and have not used Tensorflow , you are probably familiar with the scikit learn or sklearn library.It is very powerful and widely adopted .\n",
    "\n",
    "+ However, sklearn deos not offer theame functionality like Tensorflor regarding nueral networks.\n",
    "\n",
    "\n",
    "We cn now make the opposite pint for other fields of machine learning,\n",
    "\n",
    "In the presence of problems such as :\n",
    "\n",
    "+ K-Means\n",
    "\n",
    "+ Clutering \n",
    "+ Random forest \n",
    "\n",
    "Sklearn could be a better feet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44329f1-b2dd-4cdf-a1a6-f89aff6f5001",
   "metadata": {},
   "source": [
    "+ It is important to note that the theory is thesame for Tensor flow , sklearn or whatever package you are using .\n",
    "The only difference is the underlying code you write"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c46e65-f206-4fcc-a611-fe4a8be0ee71",
   "metadata": {},
   "source": [
    "#### TensorFlow 2 Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60ec8c7-88d1-44b9-a6ca-8f7237743f9b",
   "metadata": {},
   "source": [
    "\n",
    "#### Tensorflow 1 Vs Tensorflow 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbaebd3-b24b-4363-848c-c0c5313bf047",
   "metadata": {},
   "source": [
    "###### History of Development(2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92828b31-683a-4f9b-b42c-6b3941760aee",
   "metadata": {},
   "source": [
    "Tensorflow 1 is one of the most widely used deep learning packages.it is built with many varsatility which makes it a great choice of many Practitioners . Unfortunately , it has one major drawback, it is very hard to learn and use.\n",
    "That's why many people are dsheartened tha after seeing few lines of tensorflow code .\n",
    "Not only is the matter strange but a whole logic of coding is unlike most library out there. \n",
    "\n",
    "This lead to the development and popularization of higher level packages such as pytouch and keras in 2017.\n",
    "\n",
    "Keras is particularly interesting. In 2017 , it was integrated in the core tensorflow. Both tensorflow and keras are open source, So ti sholdnt be suprizing that such things happen in the programming world.\n",
    "\n",
    "Francois Chollet:  claims that keras is \"an interface for tensorflow rather than a different library\" making this integration easier to digest and implement.\n",
    "\n",
    "Even though Keras is a part of keras , Tensorflow was still loosing popularity bwtween 2017 - 2018.\n",
    "\n",
    "Tensorflow 2.0 came on the horizon and this was tensorflow effort to catch up with the current demand for higher level programming.\n",
    "\n",
    "+ Instead of developing their high level syntax, the Tf developers choose to borrow that of keras.( Higher level than TF 1)\n",
    "\n",
    "+ Thia decision made sense as keras was already widely adopted and \n",
    "\n",
    "+ people generally love it.\n",
    "\n",
    "And you can hear people saying that Tensorflow is basically keras,\n",
    "\n",
    "Tf 2 has the best of both words. Most of the varsatilty of Tf - 1 and the high level simplicity of keras.\n",
    "\n",
    "Other advantages of TF 2 over TF 1 are as follows:\n",
    "\n",
    "+ Simplified API\n",
    "\n",
    "+ Removed duplicate or deprecated functions\n",
    "\n",
    "+ Added new features in the core Tensorflow\n",
    "\n",
    "> Most importantly, TensorFlow 2 boost eager execution. In other word s allowing standard  python rule the physics to apply to it.\n",
    "Rather than complex computational graph you dont only want to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8c6956-ee71-4295-8127-e5eb0c364339",
   "metadata": {},
   "source": [
    "#### A note on coding in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876fe31d-bf60-4eac-aab7-04b924633fe6",
   "metadata": {},
   "source": [
    "##### Actual Tensorflow Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee9a2e8-02cc-489b-99d1-9821c434d8e0",
   "metadata": {},
   "source": [
    "Tensorflow is a deep learning library developed by google. It allows us to construct fairly complicated model with little coding.\n",
    "\n",
    "To give you a perspective, our practical example requires 20 lines of code.\n",
    "With tensowflow it will still be 20 lines of code.\n",
    "No differece whatsoever.\n",
    "\n",
    "However the last exercise will require a few 100 lines of code using numpy.\n",
    "\n",
    "With Tensor flow still around 20.\n",
    "Moreover, most of those will almost be thesame in our minimal example.\n",
    "\n",
    "Tensorflow was an amazing frame work and you will be convinced by that at the end of the course. The only issue is that it is yet another libary to learn.\n",
    "\n",
    "Once you start working with it ,it is going to be super easy but you must make an extra effort to understand it properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0191b9-15b3-4409-a8f6-e76ed9967d85",
   "metadata": {},
   "source": [
    "#### Types of file formats in Tensorflow and data handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9c7462-eaea-44bd-9df8-dda8f897f29a",
   "metadata": {},
   "source": [
    "#### Minimal example with TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a449728-5950-47fb-a6a4-684ea7d180db",
   "metadata": {},
   "source": [
    "##### import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9780d34c-a498-401c-b63a-e91a913cdc7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (3.7.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from matplotlib) (22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0987d4de-3c01-418f-b758-be32cb1311ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdd17da-2e35-4dda-a238-d58f0b43ab91",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Generate data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc9ef14-0bb6-482d-9ed0-9517e7943717",
   "metadata": {},
   "source": [
    "For each project you work on you have a dataset or a csv file, however Tensor flow does not work with all of them, it is tensor based so it likes tensors so we want  a format that can store the information in tensors \n",
    "\n",
    "One solution to this problem is .npz files, that is basically Numpy's file type, it allows you to save ND-Arrays or N-Dimensional arrays.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b07cc12-756b-464e-b16f-c60d606ed687",
   "metadata": {},
   "source": [
    "Thinking like computer scientist, we can say that tensors can be represented as multi-dimentional arrays.\n",
    "\n",
    "When we read an NPZ file , the data is already organized in the desired way.\n",
    "\n",
    "Often, this is an important part of deep learning pre-procesing.\n",
    "\n",
    "You are given data in a specific file format, then you open it, pre-process it and finally save it in an npz.\n",
    "\n",
    "Later you build your algorithm using the npz instead of the original file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c8e82e-d9e9-4c1e-853c-b9259ae745bc",
   "metadata": {},
   "source": [
    "Looking at the code, we have named the inputs and targets we generated( generated_inputs, targets) \n",
    "Next, we can easily save them into a  Tensor friendly file.\n",
    "\n",
    "The proper way to do that is to use the np.save method.\n",
    "\n",
    "It involves several arguement:\n",
    "\n",
    "+ The first one is the file name\n",
    "It is written in quatation marks, lets call it 'tf_intro'\n",
    "\n",
    "+ Then ,we must indicate the object we want to save into the file.\n",
    "The syntax is as follows\n",
    "The label we want to assign the nd-array = to the array we want to save under that label \n",
    "The label is input and it is equal to the generated input array\n",
    "\n",
    "Similarly, the targets are equal to the generated targets.\n",
    "\n",
    "Note,it is not required to call them input and targets.\n",
    "\n",
    "If we would like to we could call them with arbitrary names such as rad 1 and rad 2\n",
    "\n",
    "Executing the code will save the Tf-intro file in thesame directory as the jupiter notebook we are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74ce7971-afc6-4eab-a79a-c705fb4ba469",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = 1000\n",
    "\n",
    "xs = np.random.uniform(low=-10, high=10, size=(observations,1))\n",
    "zs = np.random.uniform(-10, 10, (observations,1))\n",
    "\n",
    "generated_inputs = np.column_stack((xs,zs))\n",
    "\n",
    "noise = np.random.uniform(-1, 1, (observations,1))\n",
    "\n",
    "generated_targets = 2*xs - 3*zs + 5 + noise \n",
    "\n",
    "#np.savez('TF_intro', Rad1=generated_inputs, Rad2= generated_targets)\n",
    "np.savez('TF_intro', inputs=generated_inputs, targets= generated_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6288a287-9544-4698-b210-27414673e693",
   "metadata": {},
   "source": [
    "#### Model layout – inputs, outputs, target, weights, bias, optimizer, and loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b9f8e8-f75f-4717-94bf-bdf977eeaedc",
   "metadata": {},
   "source": [
    "We will start by load the data from the .npz file Is good to get use to loading your data from npz as that is how you usually will be provided with it.\n",
    "\n",
    "We will create two variables that will measure the size of our input and output.The input size is two as there are two input variables. the xs and zs we saw earlier and the output size is 1 as there is only one output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6367ff-844d-4daa-a0e6-32ef73f89730",
   "metadata": {},
   "source": [
    "Unlike other packages ew have built in models , when we are employing tensorflow,we must actually build the model.\n",
    "\n",
    "S let's build the model,  i will store it in a variable called model.\n",
    "\n",
    "Model = tf.keras.sequential\n",
    "tf stands for tensorflow\n",
    "keras as we have already discussed tf2 is based on keras, so that is the model needed.\n",
    "\n",
    "Sequential is the function that indicates that we are laying down the model.it takes as an arguement the different layers we will like to include in  our algorithm\n",
    "\n",
    "tf.keras.sequential() function that specifies how the model will be laid down('Stacks layers')\n",
    "\n",
    "Why we have not spoken about layers just yet is because the algorithm we are building have a simple stucture.It takes inputs , applies a single linear transformation and provides output.\n",
    "\n",
    "This linear combination together with the output constitutes the so called output layer.\n",
    "\n",
    "With the minimal example with the numpy ,the outputs are equal to the dot product to be input and weight plus the bias.\n",
    "\n",
    "There is another useful method called Dense from tf.keras.layers\n",
    "\n",
    "tf.keras.layers.Dense(output size) takes the inputs provided to the model and calculates the dot product of the inputs and the weights and add the bias * also applies activation function(optional)\n",
    "\n",
    "\n",
    "The Dens method takes a provided input and calculates the dot product to the inputs and weights and adds the bias.\n",
    "It is precisely what we wanted to achieve, therefore in bracket we must simply specify the output size.\n",
    "\n",
    "We have already stored it in the variable, so we can primetarize our code by placing that variable as an arguement.\n",
    "\n",
    "This alone is completely enough for our model specification.\n",
    "\n",
    "Now according to our theological frame work,we need data, a model , an objective function and an optimization algorithm.\n",
    "\n",
    "We have taken care of the dat and the model, we are left witht the later two.\n",
    "\n",
    "The mothod which allows us to specify them is called compile.\n",
    "\n",
    "model.compile(optimizer, loss) cofigures the model for training.\n",
    "\n",
    "model.compile() we include several different arguement in the bracket, the optimizer or optimization algorithm.\n",
    "What we will use is abbreviated a sgd which stands for sochastic gradient descent . It is a generalization of the gradient descent concept we have already learnt.  we will learn the differences later.\n",
    "\n",
    "To ad as an arguement we write, optimizer equals and the string name of the optimizer we awnt to use.\n",
    "\n",
    "When using high level packages that require a string , if you want to check what you can actually include as a string. we go online and check (tf.keras.optimizer) we see a list of names of different optimizers .\n",
    "\n",
    "Under classes ; you can check the exact name of the optimizer e want to use.\n",
    "For this example , that will be sgd. we will explore other optimizers later in the course.\n",
    "\n",
    "The second arguement we will include is the loss function. We wantt o make this example as close as possible to the  numpy minimal example, so we have to us the L2-norm loss scaled by the number of observations.\n",
    "\n",
    "In such cases , Good theorogical prepration comes in handy.\n",
    "\n",
    "+ The L2-norm loss is also known as the least sum of squares.\n",
    "\n",
    "+ Moreover scaling by the number of observations  = average (mean)\n",
    "\n",
    "Looking to the posible lossess from the theoritical , we discovered mean squared error.\n",
    "\n",
    "Mean squared error is pricesily the L2-norm loss scaled by the the total number of observations.\n",
    "\n",
    "Let's include the arguement  having that in mind. los = mean_squared_error.\n",
    "\n",
    "we have lodwd the data , outlined the model amd configured the learning process by selecting an objective function and an optimization algorithm.\n",
    "\n",
    "What we have got left is o indicate to the model which data to fit.\n",
    "\n",
    "Similar to many other library, tensorflow 2.0 employs a fit method with two mandatory arguement: the inputs and the targets\n",
    "\n",
    "model.fit(inputs, targets)fits (trains) the model\n",
    "\n",
    "In the bracket we must specify the input variable containd in the training data and the target which are contained in the target tensor from training data.\n",
    "\n",
    "This same method is also the same place where we set the number of iteration.\n",
    "\n",
    "Each iteration over the full dataset in machine learning is called an epochs \n",
    "From now on we use this term to describe iterations and number of iterations .\n",
    "\n",
    "Now let's set the number of epochs to 100\n",
    "Finally, we set verbose=0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3ac637-b2d1-49e1-a4ba-fbadd8bdbea1",
   "metadata": {},
   "source": [
    "We have got all the code needed to train our first algorithm with Tensorflow 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b79ce97-b63e-478e-8c33-cc4963524f14",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Solving with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02b434e7-d859-480b-aece-9dd77990713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load('TF_intro.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a80ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ca46a49-e8ef-4e7c-b660-c0a4344baa0f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 - 1s - loss: 38.5454 - 668ms/epoch - 21ms/step\n",
      "Epoch 2/100\n",
      "32/32 - 0s - loss: 1.2207 - 41ms/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "32/32 - 0s - loss: 0.4250 - 34ms/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "32/32 - 0s - loss: 0.3941 - 48ms/epoch - 1ms/step\n",
      "Epoch 5/100\n",
      "32/32 - 0s - loss: 0.3752 - 52ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "32/32 - 0s - loss: 0.3594 - 54ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "32/32 - 0s - loss: 0.3683 - 60ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "32/32 - 0s - loss: 0.3972 - 57ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "32/32 - 0s - loss: 0.3587 - 51ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "32/32 - 0s - loss: 0.4004 - 61ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "32/32 - 0s - loss: 0.3901 - 51ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "32/32 - 0s - loss: 0.3708 - 48ms/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "32/32 - 0s - loss: 0.3747 - 50ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "32/32 - 0s - loss: 0.3631 - 49ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "32/32 - 0s - loss: 0.3600 - 57ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "32/32 - 0s - loss: 0.3853 - 46ms/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "32/32 - 0s - loss: 0.3614 - 48ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "32/32 - 0s - loss: 0.3905 - 54ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "32/32 - 0s - loss: 0.3502 - 51ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "32/32 - 0s - loss: 0.3582 - 40ms/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "32/32 - 0s - loss: 0.3580 - 61ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "32/32 - 0s - loss: 0.3682 - 48ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "32/32 - 0s - loss: 0.3984 - 54ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "32/32 - 0s - loss: 0.3575 - 47ms/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "32/32 - 0s - loss: 0.3735 - 46ms/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "32/32 - 0s - loss: 0.4344 - 32ms/epoch - 997us/step\n",
      "Epoch 27/100\n",
      "32/32 - 0s - loss: 0.3952 - 46ms/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "32/32 - 0s - loss: 0.3702 - 54ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "32/32 - 0s - loss: 0.3921 - 52ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "32/32 - 0s - loss: 0.4091 - 56ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "32/32 - 0s - loss: 0.3660 - 55ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "32/32 - 0s - loss: 0.3752 - 52ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "32/32 - 0s - loss: 0.3709 - 47ms/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "32/32 - 0s - loss: 0.4073 - 50ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "32/32 - 0s - loss: 0.3751 - 58ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "32/32 - 0s - loss: 0.3660 - 51ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "32/32 - 0s - loss: 0.3712 - 52ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "32/32 - 0s - loss: 0.3931 - 56ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "32/32 - 0s - loss: 0.3775 - 51ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "32/32 - 0s - loss: 0.3828 - 51ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "32/32 - 0s - loss: 0.3989 - 46ms/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "32/32 - 0s - loss: 0.3596 - 49ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "32/32 - 0s - loss: 0.3773 - 48ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "32/32 - 0s - loss: 0.3763 - 56ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "32/32 - 0s - loss: 0.3774 - 53ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "32/32 - 0s - loss: 0.3661 - 46ms/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "32/32 - 0s - loss: 0.3587 - 47ms/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "32/32 - 0s - loss: 0.3652 - 53ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "32/32 - 0s - loss: 0.3614 - 50ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "32/32 - 0s - loss: 0.3569 - 52ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "32/32 - 0s - loss: 0.3596 - 51ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "32/32 - 0s - loss: 0.3927 - 58ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "32/32 - 0s - loss: 0.3529 - 47ms/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "32/32 - 0s - loss: 0.3785 - 50ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "32/32 - 0s - loss: 0.4027 - 52ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "32/32 - 0s - loss: 0.4170 - 49ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "32/32 - 0s - loss: 0.4070 - 52ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "32/32 - 0s - loss: 0.4006 - 49ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "32/32 - 0s - loss: 0.3807 - 50ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "32/32 - 0s - loss: 0.3795 - 48ms/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "32/32 - 0s - loss: 0.3672 - 49ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "32/32 - 0s - loss: 0.3798 - 49ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "32/32 - 0s - loss: 0.3989 - 50ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "32/32 - 0s - loss: 0.4338 - 49ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "32/32 - 0s - loss: 0.3760 - 47ms/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "32/32 - 0s - loss: 0.3855 - 50ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "32/32 - 0s - loss: 0.3798 - 53ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "32/32 - 0s - loss: 0.3743 - 44ms/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "32/32 - 0s - loss: 0.3597 - 49ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "32/32 - 0s - loss: 0.3713 - 49ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "32/32 - 0s - loss: 0.3491 - 46ms/epoch - 1ms/step\n",
      "Epoch 72/100\n",
      "32/32 - 0s - loss: 0.3692 - 83ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "32/32 - 0s - loss: 0.3632 - 69ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "32/32 - 0s - loss: 0.3856 - 72ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "32/32 - 0s - loss: 0.3716 - 95ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "32/32 - 0s - loss: 0.3445 - 50ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "32/32 - 0s - loss: 0.3712 - 51ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "32/32 - 0s - loss: 0.4186 - 55ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "32/32 - 0s - loss: 0.3796 - 56ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "32/32 - 0s - loss: 0.3522 - 48ms/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "32/32 - 0s - loss: 0.3585 - 54ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "32/32 - 0s - loss: 0.3591 - 50ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "32/32 - 0s - loss: 0.3562 - 51ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "32/32 - 0s - loss: 0.3775 - 48ms/epoch - 1ms/step\n",
      "Epoch 85/100\n",
      "32/32 - 0s - loss: 0.3624 - 45ms/epoch - 1ms/step\n",
      "Epoch 86/100\n",
      "32/32 - 0s - loss: 0.3534 - 49ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "32/32 - 0s - loss: 0.3641 - 59ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "32/32 - 0s - loss: 0.3649 - 59ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "32/32 - 0s - loss: 0.3728 - 49ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "32/32 - 0s - loss: 0.3716 - 41ms/epoch - 1ms/step\n",
      "Epoch 91/100\n",
      "32/32 - 0s - loss: 0.3814 - 47ms/epoch - 1ms/step\n",
      "Epoch 92/100\n",
      "32/32 - 0s - loss: 0.3761 - 43ms/epoch - 1ms/step\n",
      "Epoch 93/100\n",
      "32/32 - 0s - loss: 0.3488 - 48ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "32/32 - 0s - loss: 0.3986 - 52ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "32/32 - 0s - loss: 0.3581 - 56ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "32/32 - 0s - loss: 0.3907 - 65ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "32/32 - 0s - loss: 0.3750 - 71ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "32/32 - 0s - loss: 0.3673 - 60ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "32/32 - 0s - loss: 0.3713 - 50ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "32/32 - 0s - loss: 0.3768 - 79ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1df177e79a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_size = 2\n",
    "output_size = 1\n",
    "# when we introduced kernel and bias iniializers the output is still same\n",
    "model = tf.keras.Sequential([\n",
    "                           tf.keras.layers.Dense(output_size,\n",
    "                                                 kernel_initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1),\n",
    "                                                 bias_initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1)\n",
    "                                                )\n",
    "                           ])\n",
    "\n",
    "# lets create a custom optimizer and set learning rate to 0.02 as we did in numpy e.g\n",
    "custom_optimizer = tf.keras.optimizers.SGD(learning_rate=0.02)\n",
    "#model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "# Replace sgd with new custom optimizer\n",
    "model.compile(optimizer=custom_optimizer, loss='mean_squared_error')\n",
    "# We will use built-in losses without customizing them.\n",
    "# in future you may get hooked without customizing them\n",
    "# The new result will still be the same , with the diff. being we need to set learning rate ourself\n",
    "# Verbose = 0 stands for silence or no output available when the training is displayed\n",
    "# If we set verbose to 1 ,we will get a progress bar\n",
    "# verbose = 2 stands for 1 line per epoch\n",
    "#model.fit(training_data['inputs'], training_data['targets'], epochs=100, verbose=0)\n",
    "model.fit(training_data['inputs'], training_data['targets'], epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cbb315-214c-4516-a015-f82ef4b4557e",
   "metadata": {},
   "source": [
    "#### Interpreting the result and extracting the weights and bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd873bb-fc00-4273-94d3-d8ebe2caaae7",
   "metadata": {},
   "source": [
    "We have got all the code needed to train our first algorithm with Tensorflow 2.\n",
    "\n",
    "So, it is time to run it.\n",
    "The result is a bit underwelming\n",
    "We get nothing more than an output signifying that the model have been trained in object with no information about the training with no information about the training,the reason we said verbose is 0, which stands for silence or no output about the training is displayed, if we set verbose to one , we should get a progress bar.  \n",
    "\n",
    "Unfortunately, for the current version on tensorflow and its integreation in jupiter we get the whole output in text form.\n",
    "We can still clearly see all the information needed. For other coding in other environment , it may be a more difficult experience . Because of this experience,this cleaner form of information can be found when verbose is two. This indicates we will get one line per epoch which will allow us to follow the development of the loss function over the training.\n",
    "\n",
    "The first piece is a timer tracking the time it took in seconds to complete each epoch.\n",
    "For all epoch in each example, it took 0 seconds per epoch.\n",
    "The second output is the current value of the loss function.\n",
    "\n",
    "As we scroll down. we comfirm that the loss is decreasing so our algorithm have worked as intended"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773327aa-ec70-4755-815a-f27472889850",
   "metadata": {
    "tags": []
   },
   "source": [
    "`inputs_size = 2\n",
    "output_size = 1\n",
    "\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(output_size)\n",
    "                            ])\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "\n",
    "model.fit(training_data['inputs'], training_data['targets'], epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f499b3-3dd7-48ec-a569-e23f02a49ccc",
   "metadata": {},
   "source": [
    "As we discussed already , we generated the function 2X - 3z + 5 + noise in other to be able t access how our model did. You should be aware that in a real life situation, you never know the exact relationship. So it wouldn't be possible to comfirm how well your model how faired."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c8f37c-d7c5-4979-9049-a1408f8f2a68",
   "metadata": {},
   "source": [
    "##### Extract the weights and bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01765ec-cae4-4ffb-bad8-47fbce639308",
   "metadata": {},
   "source": [
    "If we check the weight and biases . they shoild be 2 and -3.\n",
    "There is a convenient built-in method called get weight that could be applied  to each layer for this purpose.\n",
    "\n",
    "Model is the model that we created.we have to specify the layer we are interested in.\n",
    "\n",
    "In that case the only layer ie position o, finally ,we have to apply the method get weight, the output is a tensor with 2 rays. one for the weight and 1 for the biases.In this case ,bias.\n",
    "As anticipated , the weight are approximately 2 and -3 while the bias is 5. This is pricisely the information which comfirms that our algorithm has indeed learnt the underlying relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a8b6616-ad18-4684-91d6-3762e28abfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.0957038],\n",
       "        [-3.02566  ]], dtype=float32),\n",
       " array([4.9747496], dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9a75353-b4d7-487e-9f2c-f2fb4ad6aa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0957038],\n",
       "       [-3.02566  ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model.layers[0].get_weights()[0]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dacab660-355a-4200-9290-a5784a5ff9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.9747496], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = model.layers[0].get_weights()[1]\n",
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c8bc5d-1759-4e9d-9a84-750e4a962b91",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Extract the outputs (make predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7fbe9a-dc28-4255-9028-6743d15b7ece",
   "metadata": {},
   "source": [
    "+ what if we wanted to predict values using our model?\n",
    "\n",
    "To predict values with our model, we use the method, predict on batch. The batcg here is the data we are provided with\n",
    "\n",
    "model.predict_on_batch(data) calculates the outputs given inputs\n",
    "\n",
    "so the code is model.predict _no batch then you feed it with the training inputs.\n",
    "\n",
    "The results consists of an array with corresponding outputs for each of the inputs.\n",
    "\n",
    "Infact, these are the values that were compared to the target to evaluate the loss function.\n",
    "To be precise , these are the outputs based on the train model or in our case the outputs after 100 epochs of training.\n",
    "\n",
    "Since tthe outputs are compared to the targets at each epoch, it may be interesting to compare them manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5b26e95-c34e-42a9-bba7-38312163ff53",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-32. ],\n",
       "       [-17.5],\n",
       "       [ 35.3],\n",
       "       [ 10.7],\n",
       "       [-28.5],\n",
       "       [ 16.4],\n",
       "       [ 47.8],\n",
       "       [ 25.2],\n",
       "       [ 28.5],\n",
       "       [ 15.3],\n",
       "       [  9.2],\n",
       "       [-24.3],\n",
       "       [-12.5],\n",
       "       [ -0.5],\n",
       "       [ 12.9],\n",
       "       [ 22.8],\n",
       "       [ -9.1],\n",
       "       [ -0.5],\n",
       "       [ -0.3],\n",
       "       [ 11.3],\n",
       "       [-14.5],\n",
       "       [ -3.1],\n",
       "       [ -8.8],\n",
       "       [  2.5],\n",
       "       [-17.8],\n",
       "       [  8.7],\n",
       "       [ 16.2],\n",
       "       [ -8.6],\n",
       "       [ 32.2],\n",
       "       [  8.1],\n",
       "       [ -7.8],\n",
       "       [ -5.6],\n",
       "       [-28.5],\n",
       "       [ 30.1],\n",
       "       [ 41.6],\n",
       "       [ -3.4],\n",
       "       [-27.7],\n",
       "       [ 33.8],\n",
       "       [  1.3],\n",
       "       [ 28.2],\n",
       "       [ 30.9],\n",
       "       [ 27. ],\n",
       "       [ 22.9],\n",
       "       [-28.2],\n",
       "       [ 46.8],\n",
       "       [-13.6],\n",
       "       [ 44.3],\n",
       "       [ -9.3],\n",
       "       [ 48.3],\n",
       "       [-15.7],\n",
       "       [ 24.4],\n",
       "       [ 19.5],\n",
       "       [-32.6],\n",
       "       [  6.2],\n",
       "       [ 52. ],\n",
       "       [-33.9],\n",
       "       [-15.2],\n",
       "       [ 21.4],\n",
       "       [ 28.7],\n",
       "       [ 11.2],\n",
       "       [ -8.9],\n",
       "       [ 36.8],\n",
       "       [ -6.7],\n",
       "       [  5.7],\n",
       "       [-12.3],\n",
       "       [ 21.7],\n",
       "       [ 37.3],\n",
       "       [ 25.8],\n",
       "       [-40.4],\n",
       "       [ 13.3],\n",
       "       [  1.1],\n",
       "       [ 23.9],\n",
       "       [ 14. ],\n",
       "       [-21.8],\n",
       "       [-14.2],\n",
       "       [-25. ],\n",
       "       [ -1.3],\n",
       "       [ 12.4],\n",
       "       [-19.4],\n",
       "       [-29.2],\n",
       "       [ 17.7],\n",
       "       [  2.4],\n",
       "       [  9.2],\n",
       "       [ -1.1],\n",
       "       [ 34.2],\n",
       "       [-11.7],\n",
       "       [ 34.6],\n",
       "       [ -4.4],\n",
       "       [-21.1],\n",
       "       [ 22.9],\n",
       "       [ 17.9],\n",
       "       [ 10.6],\n",
       "       [ -3.8],\n",
       "       [ 15. ],\n",
       "       [ 19.6],\n",
       "       [ 11.8],\n",
       "       [-17.4],\n",
       "       [ 26. ],\n",
       "       [ 23.5],\n",
       "       [-11.9],\n",
       "       [ -5.7],\n",
       "       [ -7.6],\n",
       "       [ 31.2],\n",
       "       [ 27.7],\n",
       "       [ 17.6],\n",
       "       [ 23.5],\n",
       "       [ 52.3],\n",
       "       [  4.5],\n",
       "       [ 18.7],\n",
       "       [-15.9],\n",
       "       [ -3.4],\n",
       "       [  1.4],\n",
       "       [-18.8],\n",
       "       [ 10.4],\n",
       "       [-31.7],\n",
       "       [-29.5],\n",
       "       [-11.7],\n",
       "       [ -4.9],\n",
       "       [-37.1],\n",
       "       [-24.5],\n",
       "       [ 13. ],\n",
       "       [-33.7],\n",
       "       [-29.9],\n",
       "       [-14.8],\n",
       "       [ 36.8],\n",
       "       [  6.2],\n",
       "       [ 27.9],\n",
       "       [ -6.3],\n",
       "       [ 11.4],\n",
       "       [ -0.9],\n",
       "       [ 16.3],\n",
       "       [ 22. ],\n",
       "       [-34.3],\n",
       "       [  2.5],\n",
       "       [-14.8],\n",
       "       [ 20.6],\n",
       "       [-17.4],\n",
       "       [  4.5],\n",
       "       [ -2. ],\n",
       "       [  2.8],\n",
       "       [ 29.3],\n",
       "       [ -1.3],\n",
       "       [ 29.9],\n",
       "       [  0.4],\n",
       "       [  4.2],\n",
       "       [ -2.9],\n",
       "       [  7.4],\n",
       "       [ 21.9],\n",
       "       [ 13.7],\n",
       "       [ 33.7],\n",
       "       [ -1.4],\n",
       "       [-22.5],\n",
       "       [ -5.9],\n",
       "       [ -2. ],\n",
       "       [-13. ],\n",
       "       [ 29.5],\n",
       "       [ 12.1],\n",
       "       [ 23.4],\n",
       "       [ 25.3],\n",
       "       [ 23.1],\n",
       "       [ 13.1],\n",
       "       [-27.8],\n",
       "       [-24.2],\n",
       "       [  4.7],\n",
       "       [-10.9],\n",
       "       [-14.2],\n",
       "       [-36.6],\n",
       "       [  6.6],\n",
       "       [ 48.4],\n",
       "       [ 11.4],\n",
       "       [-23.2],\n",
       "       [ 24.7],\n",
       "       [ 20.5],\n",
       "       [ -8.1],\n",
       "       [ 25.8],\n",
       "       [ 10.1],\n",
       "       [ 34.7],\n",
       "       [ -3.1],\n",
       "       [-32.6],\n",
       "       [ -5.8],\n",
       "       [ -8.3],\n",
       "       [  3.6],\n",
       "       [-12.9],\n",
       "       [ 31.5],\n",
       "       [  2.7],\n",
       "       [ -3.4],\n",
       "       [  6.5],\n",
       "       [ 16.6],\n",
       "       [ 19.1],\n",
       "       [ -4.8],\n",
       "       [ 37.4],\n",
       "       [ 26.1],\n",
       "       [ -3.2],\n",
       "       [ 32.4],\n",
       "       [ -2.2],\n",
       "       [ -2.2],\n",
       "       [ -5.3],\n",
       "       [-25.4],\n",
       "       [ 41. ],\n",
       "       [ 21. ],\n",
       "       [  7.1],\n",
       "       [ 47.6],\n",
       "       [-39. ],\n",
       "       [-15.7],\n",
       "       [ 27.4],\n",
       "       [ 11.5],\n",
       "       [  2.3],\n",
       "       [ 21.8],\n",
       "       [ 34. ],\n",
       "       [ 26.3],\n",
       "       [ -5.7],\n",
       "       [ 21.4],\n",
       "       [ -5.4],\n",
       "       [ 14.7],\n",
       "       [ 21.8],\n",
       "       [  1.8],\n",
       "       [ 20.5],\n",
       "       [  2.7],\n",
       "       [ -7. ],\n",
       "       [ 29.6],\n",
       "       [  9.7],\n",
       "       [ -5.8],\n",
       "       [ 23. ],\n",
       "       [ 13.8],\n",
       "       [ 46.1],\n",
       "       [ 33.8],\n",
       "       [ 15.3],\n",
       "       [  9. ],\n",
       "       [-20.4],\n",
       "       [-13. ],\n",
       "       [ 30.3],\n",
       "       [ 14.9],\n",
       "       [-19.7],\n",
       "       [-11.5],\n",
       "       [ 29.8],\n",
       "       [-20. ],\n",
       "       [ 12.1],\n",
       "       [ 14.3],\n",
       "       [ 29.3],\n",
       "       [  5.9],\n",
       "       [ 22.2],\n",
       "       [-27.7],\n",
       "       [  5.3],\n",
       "       [-39.6],\n",
       "       [ 18. ],\n",
       "       [ 17.8],\n",
       "       [-13.5],\n",
       "       [ 12.8],\n",
       "       [  5.3],\n",
       "       [-10.5],\n",
       "       [ -9.7],\n",
       "       [ 16.7],\n",
       "       [-13.7],\n",
       "       [ -0.5],\n",
       "       [ 37.3],\n",
       "       [ -1.2],\n",
       "       [ 52.9],\n",
       "       [ 25.5],\n",
       "       [ 22.9],\n",
       "       [ 33.3],\n",
       "       [ 50.6],\n",
       "       [-21.9],\n",
       "       [ -1.9],\n",
       "       [  2.5],\n",
       "       [ 23.2],\n",
       "       [-19.6],\n",
       "       [ 26.8],\n",
       "       [  9.9],\n",
       "       [ 20.2],\n",
       "       [ 21.5],\n",
       "       [-21.7],\n",
       "       [ 33.8],\n",
       "       [ 21.9],\n",
       "       [  8.7],\n",
       "       [-10.3],\n",
       "       [ 18.1],\n",
       "       [ 44.2],\n",
       "       [ 12.2],\n",
       "       [ 21.6],\n",
       "       [  3.1],\n",
       "       [-20.4],\n",
       "       [ 26.3],\n",
       "       [-18.7],\n",
       "       [ 34.3],\n",
       "       [ 35.9],\n",
       "       [ -5. ],\n",
       "       [ 32.7],\n",
       "       [ -0.2],\n",
       "       [-14.2],\n",
       "       [-23.3],\n",
       "       [ -0.6],\n",
       "       [ 23.7],\n",
       "       [ -7.8],\n",
       "       [ 19.3],\n",
       "       [-19.4],\n",
       "       [-30.8],\n",
       "       [ 20.9],\n",
       "       [ 25.9],\n",
       "       [-14.2],\n",
       "       [ 17.2],\n",
       "       [ -6.3],\n",
       "       [ 17. ],\n",
       "       [ 21.6],\n",
       "       [ -4.9],\n",
       "       [  4.1],\n",
       "       [ 38.9],\n",
       "       [-26.3],\n",
       "       [ 10.4],\n",
       "       [-40.8],\n",
       "       [  6.9],\n",
       "       [ 33.4],\n",
       "       [-27.6],\n",
       "       [ 10.6],\n",
       "       [ 20.6],\n",
       "       [ 21.7],\n",
       "       [  2.7],\n",
       "       [ 29.3],\n",
       "       [ 18.3],\n",
       "       [ 11.1],\n",
       "       [  9.1],\n",
       "       [ -7.6],\n",
       "       [  8.5],\n",
       "       [-24.9],\n",
       "       [-17.1],\n",
       "       [ 32. ],\n",
       "       [ -3.4],\n",
       "       [ 21.1],\n",
       "       [ 25.4],\n",
       "       [ -9. ],\n",
       "       [  4.5],\n",
       "       [ 38.7],\n",
       "       [ -3.9],\n",
       "       [ -2.2],\n",
       "       [ 16. ],\n",
       "       [-18.1],\n",
       "       [ 28.3],\n",
       "       [ 12.3],\n",
       "       [  0.8],\n",
       "       [-12.9],\n",
       "       [-22.6],\n",
       "       [  8. ],\n",
       "       [ 49.5],\n",
       "       [ -0.9],\n",
       "       [-12.9],\n",
       "       [ 23.2],\n",
       "       [ 12.7],\n",
       "       [-34.7],\n",
       "       [ 42.9],\n",
       "       [ 27.6],\n",
       "       [-34.5],\n",
       "       [-25.1],\n",
       "       [ 31.3],\n",
       "       [ 35.3],\n",
       "       [ 33.8],\n",
       "       [ 12.3],\n",
       "       [ 15.9],\n",
       "       [-13.4],\n",
       "       [ 24.6],\n",
       "       [ 11.1],\n",
       "       [-22.7],\n",
       "       [ 18.3],\n",
       "       [ 45.7],\n",
       "       [ -5.7],\n",
       "       [-21.9],\n",
       "       [ 38.6],\n",
       "       [-26.9],\n",
       "       [ 51.9],\n",
       "       [ 15.9],\n",
       "       [ 44.6],\n",
       "       [-10.1],\n",
       "       [-17.4],\n",
       "       [-22.6],\n",
       "       [-16.7],\n",
       "       [  1.4],\n",
       "       [ -1. ],\n",
       "       [  9.5],\n",
       "       [ 12.2],\n",
       "       [  1.5],\n",
       "       [-26.8],\n",
       "       [ 31.2],\n",
       "       [  2.8],\n",
       "       [-19.7],\n",
       "       [ 14.4],\n",
       "       [ 27.8],\n",
       "       [ -3.1],\n",
       "       [ 13.8],\n",
       "       [ -4.1],\n",
       "       [  4.9],\n",
       "       [ 10.1],\n",
       "       [-20.4],\n",
       "       [-23.7],\n",
       "       [ 21.4],\n",
       "       [-10.6],\n",
       "       [-29.4],\n",
       "       [-26.9],\n",
       "       [  3.1],\n",
       "       [ 24.3],\n",
       "       [ 17.8],\n",
       "       [ 18.8],\n",
       "       [ -5. ],\n",
       "       [  1.6],\n",
       "       [-33.6],\n",
       "       [ 13.7],\n",
       "       [  7.8],\n",
       "       [ -6.1],\n",
       "       [ 39.7],\n",
       "       [  8.1],\n",
       "       [ 11. ],\n",
       "       [-28.1],\n",
       "       [-18.7],\n",
       "       [ 28.9],\n",
       "       [ 31.5],\n",
       "       [  5.4],\n",
       "       [ 16.7],\n",
       "       [-28.7],\n",
       "       [ -7.8],\n",
       "       [-10.4],\n",
       "       [ 24.1],\n",
       "       [ 50.1],\n",
       "       [ 44.3],\n",
       "       [-10.9],\n",
       "       [ 43. ],\n",
       "       [-12.5],\n",
       "       [  2.3],\n",
       "       [ 32.5],\n",
       "       [ 23.2],\n",
       "       [-29.8],\n",
       "       [  7.5],\n",
       "       [-19.9],\n",
       "       [  6.8],\n",
       "       [ -5.9],\n",
       "       [-18.5],\n",
       "       [ 20.4],\n",
       "       [ 11.8],\n",
       "       [ 23.2],\n",
       "       [ -2. ],\n",
       "       [  5. ],\n",
       "       [ 36.6],\n",
       "       [-21.8],\n",
       "       [ 16.5],\n",
       "       [ 27.3],\n",
       "       [ -8.8],\n",
       "       [  4.2],\n",
       "       [ 21.4],\n",
       "       [ -2.6],\n",
       "       [-11.8],\n",
       "       [ 31.3],\n",
       "       [  4.2],\n",
       "       [ 24. ],\n",
       "       [ 23.6],\n",
       "       [ 33. ],\n",
       "       [ 22.6],\n",
       "       [ 22.8],\n",
       "       [ -8.7],\n",
       "       [ 19. ],\n",
       "       [ 24.7],\n",
       "       [-19.7],\n",
       "       [-17.5],\n",
       "       [ 20.4],\n",
       "       [ 28.8],\n",
       "       [ 20.7],\n",
       "       [-34.3],\n",
       "       [ -1.7],\n",
       "       [ -3.5],\n",
       "       [  6.1],\n",
       "       [ 13.7],\n",
       "       [ 27.3],\n",
       "       [ -9. ],\n",
       "       [ -1.6],\n",
       "       [ 28.2],\n",
       "       [-44.1],\n",
       "       [ 23.6],\n",
       "       [-36.8],\n",
       "       [ 13. ],\n",
       "       [ -7.6],\n",
       "       [-25. ],\n",
       "       [-34.2],\n",
       "       [ 11.8],\n",
       "       [-12.4],\n",
       "       [ 31. ],\n",
       "       [ 16.9],\n",
       "       [  6.4],\n",
       "       [-21.4],\n",
       "       [ 31.1],\n",
       "       [ 23.4],\n",
       "       [ 36. ],\n",
       "       [-13.1],\n",
       "       [ -2.8],\n",
       "       [ -7.4],\n",
       "       [ 16.5],\n",
       "       [ 12.8],\n",
       "       [ 27.1],\n",
       "       [-13.5],\n",
       "       [  3.6],\n",
       "       [  7.2],\n",
       "       [-23.5],\n",
       "       [ 17.1],\n",
       "       [-10.1],\n",
       "       [-14.9],\n",
       "       [ 26.8],\n",
       "       [-19.3],\n",
       "       [-43.8],\n",
       "       [  1.3],\n",
       "       [-23. ],\n",
       "       [-29.3],\n",
       "       [ -8. ],\n",
       "       [ 19.4],\n",
       "       [ 35.2],\n",
       "       [-29.3],\n",
       "       [  0.6],\n",
       "       [ 41.1],\n",
       "       [ 25.9],\n",
       "       [ 22.6],\n",
       "       [ 18.9],\n",
       "       [-13.5],\n",
       "       [ -7.5],\n",
       "       [  1.2],\n",
       "       [ 17.9],\n",
       "       [ 15.9],\n",
       "       [-39. ],\n",
       "       [-16.7],\n",
       "       [ 13.7],\n",
       "       [ -6.8],\n",
       "       [ 31.7],\n",
       "       [-25.7],\n",
       "       [ -5.8],\n",
       "       [  1. ],\n",
       "       [ 41.6],\n",
       "       [ 30.2],\n",
       "       [-17.9],\n",
       "       [ -6.7],\n",
       "       [ -2.7],\n",
       "       [  0.2],\n",
       "       [-25.8],\n",
       "       [ 16.8],\n",
       "       [-32.3],\n",
       "       [ 16. ],\n",
       "       [ 28.9],\n",
       "       [  7.7],\n",
       "       [ 53.4],\n",
       "       [ -0. ],\n",
       "       [ 15.4],\n",
       "       [ -2.9],\n",
       "       [-18.8],\n",
       "       [ 13.3],\n",
       "       [  6.2],\n",
       "       [-21.5],\n",
       "       [-12.2],\n",
       "       [-18.6],\n",
       "       [-17.1],\n",
       "       [ -5.3],\n",
       "       [-18.4],\n",
       "       [ 37.7],\n",
       "       [ -7.4],\n",
       "       [ -1.4],\n",
       "       [ 50.1],\n",
       "       [ 40.7],\n",
       "       [ 30.7],\n",
       "       [-20.4],\n",
       "       [ 21.4],\n",
       "       [ -0.3],\n",
       "       [-21.8],\n",
       "       [ 14. ],\n",
       "       [  4.8],\n",
       "       [ -5.4],\n",
       "       [ 41.5],\n",
       "       [  9.2],\n",
       "       [  4.9],\n",
       "       [ -6.4],\n",
       "       [-33.4],\n",
       "       [-34.3],\n",
       "       [  7.1],\n",
       "       [  3.8],\n",
       "       [ 42.9],\n",
       "       [  1.3],\n",
       "       [-22.2],\n",
       "       [ 16.6],\n",
       "       [  1.5],\n",
       "       [ -4.9],\n",
       "       [ 31.8],\n",
       "       [-25. ],\n",
       "       [ -0.1],\n",
       "       [-17.2],\n",
       "       [ 29.7],\n",
       "       [  4.1],\n",
       "       [ 15.3],\n",
       "       [-24.4],\n",
       "       [  2.8],\n",
       "       [-22.3],\n",
       "       [ 18. ],\n",
       "       [-31.8],\n",
       "       [ 12.8],\n",
       "       [ 25.7],\n",
       "       [ -3.6],\n",
       "       [-13.3],\n",
       "       [ 11.6],\n",
       "       [ 22.5],\n",
       "       [ 17.6],\n",
       "       [ 17.1],\n",
       "       [ -8.6],\n",
       "       [ 21.8],\n",
       "       [  2.6],\n",
       "       [  2.2],\n",
       "       [-33.3],\n",
       "       [-18.1],\n",
       "       [ 23.9],\n",
       "       [-17.4],\n",
       "       [ 22.1],\n",
       "       [ 36.3],\n",
       "       [ 10.6],\n",
       "       [ -9.7],\n",
       "       [-12.1],\n",
       "       [ -6.7],\n",
       "       [-21.2],\n",
       "       [ -0.1],\n",
       "       [  7.4],\n",
       "       [ 19.9],\n",
       "       [ 22.3],\n",
       "       [  4.8],\n",
       "       [-27.9],\n",
       "       [-13.3],\n",
       "       [ 26.1],\n",
       "       [-13.8],\n",
       "       [ 38.6],\n",
       "       [ 16.8],\n",
       "       [  2.3],\n",
       "       [ 38. ],\n",
       "       [-27.6],\n",
       "       [ 20.7],\n",
       "       [ 32.2],\n",
       "       [ 11.1],\n",
       "       [-16.8],\n",
       "       [-20.2],\n",
       "       [ 22.3],\n",
       "       [  9.4],\n",
       "       [ 39.7],\n",
       "       [ -5. ],\n",
       "       [ 14.8],\n",
       "       [ 40. ],\n",
       "       [ 17.5],\n",
       "       [ 17.8],\n",
       "       [ -5.4],\n",
       "       [-21.9],\n",
       "       [ 35.6],\n",
       "       [ 36.8],\n",
       "       [ 46.6],\n",
       "       [ 17.2],\n",
       "       [  6.9],\n",
       "       [ -0.1],\n",
       "       [-12.5],\n",
       "       [ -5.5],\n",
       "       [ 15. ],\n",
       "       [ 14.6],\n",
       "       [-28.7],\n",
       "       [  0.3],\n",
       "       [-37.7],\n",
       "       [  8.8],\n",
       "       [ 10.6],\n",
       "       [-23.9],\n",
       "       [  4.1],\n",
       "       [ -5.7],\n",
       "       [ 33.2],\n",
       "       [ 23.9],\n",
       "       [ -1.3],\n",
       "       [ 23.2],\n",
       "       [ -4.5],\n",
       "       [-18.7],\n",
       "       [-18.3],\n",
       "       [ 30. ],\n",
       "       [-10.9],\n",
       "       [ 23.4],\n",
       "       [-10.8],\n",
       "       [ -1.9],\n",
       "       [-13.5],\n",
       "       [  8.6],\n",
       "       [-21.9],\n",
       "       [ 23. ],\n",
       "       [-26.7],\n",
       "       [-30. ],\n",
       "       [ -7.4],\n",
       "       [ -0.8],\n",
       "       [-16.5],\n",
       "       [ 16.5],\n",
       "       [-33.5],\n",
       "       [-15.9],\n",
       "       [ 14.1],\n",
       "       [ 11. ],\n",
       "       [-27.6],\n",
       "       [ 22.4],\n",
       "       [ 31.5],\n",
       "       [ 15.3],\n",
       "       [-23.7],\n",
       "       [-12. ],\n",
       "       [  2.4],\n",
       "       [ 21.6],\n",
       "       [ 49.3],\n",
       "       [  9.8],\n",
       "       [ 44.3],\n",
       "       [ 47. ],\n",
       "       [ -0.1],\n",
       "       [-11.5],\n",
       "       [ 13. ],\n",
       "       [ -1. ],\n",
       "       [  3.9],\n",
       "       [-13.5],\n",
       "       [-44.9],\n",
       "       [ 11.9],\n",
       "       [ 28.9],\n",
       "       [ 42.6],\n",
       "       [ 29.6],\n",
       "       [-14.4],\n",
       "       [ 15. ],\n",
       "       [ 42.4],\n",
       "       [-14.1],\n",
       "       [-12.2],\n",
       "       [ 16.9],\n",
       "       [ 10. ],\n",
       "       [ 18.9],\n",
       "       [ -7.7],\n",
       "       [  9.3],\n",
       "       [  2.6],\n",
       "       [ 16.5],\n",
       "       [ 26.8],\n",
       "       [-32.1],\n",
       "       [-13.2],\n",
       "       [-16. ],\n",
       "       [ -8. ],\n",
       "       [-21.5],\n",
       "       [ 17.5],\n",
       "       [-38.4],\n",
       "       [ 31.4],\n",
       "       [ -4.2],\n",
       "       [  9.9],\n",
       "       [ 12.9],\n",
       "       [ -4.9],\n",
       "       [  0.6],\n",
       "       [-15.7],\n",
       "       [ 11.9],\n",
       "       [-36.2],\n",
       "       [ 18.3],\n",
       "       [  0.4],\n",
       "       [-36.7],\n",
       "       [ 22.9],\n",
       "       [-21.9],\n",
       "       [  1.5],\n",
       "       [ -1.9],\n",
       "       [-19.6],\n",
       "       [ 18.9],\n",
       "       [ 34. ],\n",
       "       [ 10.5],\n",
       "       [ 47.1],\n",
       "       [ 19.1],\n",
       "       [ 28. ],\n",
       "       [  5. ],\n",
       "       [ -1. ],\n",
       "       [  2.1],\n",
       "       [ -2.5],\n",
       "       [-14.3],\n",
       "       [ 21.8],\n",
       "       [ 29.8],\n",
       "       [ 29.6],\n",
       "       [  6.4],\n",
       "       [-15. ],\n",
       "       [ 16. ],\n",
       "       [ 43.6],\n",
       "       [-18.3],\n",
       "       [ -3.4],\n",
       "       [ -1.9],\n",
       "       [ 12.1],\n",
       "       [-16.8],\n",
       "       [ 16.1],\n",
       "       [ 23.5],\n",
       "       [ -6.1],\n",
       "       [-17.7],\n",
       "       [ 12.2],\n",
       "       [ 24.7],\n",
       "       [ 38.8],\n",
       "       [  4.4],\n",
       "       [-33.8],\n",
       "       [ -4.6],\n",
       "       [ 37. ],\n",
       "       [ -8.7],\n",
       "       [ -7.1],\n",
       "       [ 13. ],\n",
       "       [  3.7],\n",
       "       [-13.8],\n",
       "       [ 11.5],\n",
       "       [ 10.6],\n",
       "       [ 32.3],\n",
       "       [  8.8],\n",
       "       [-42.4],\n",
       "       [ 12.5],\n",
       "       [ -4.3],\n",
       "       [ 29.2],\n",
       "       [ 27.3],\n",
       "       [-20.6],\n",
       "       [-40.3],\n",
       "       [ 25.9],\n",
       "       [ 40.6],\n",
       "       [ 35.6],\n",
       "       [-33.3],\n",
       "       [-27.7],\n",
       "       [  6. ],\n",
       "       [ -3.6],\n",
       "       [ 20.4],\n",
       "       [ 22.3],\n",
       "       [ 43.5],\n",
       "       [ 31. ],\n",
       "       [  7.8],\n",
       "       [ 15.2],\n",
       "       [ 38.2],\n",
       "       [  7.5],\n",
       "       [ 33.1],\n",
       "       [ 20.9],\n",
       "       [-20.7],\n",
       "       [ 25.1],\n",
       "       [ -6.5],\n",
       "       [ -9.7],\n",
       "       [ 34.9],\n",
       "       [ 33.2],\n",
       "       [ 21.4],\n",
       "       [ -7. ],\n",
       "       [ 35.6],\n",
       "       [  6. ],\n",
       "       [ -4.2],\n",
       "       [  1. ],\n",
       "       [ 23.5],\n",
       "       [ 20.2],\n",
       "       [ 37.3],\n",
       "       [ -0. ],\n",
       "       [ 54. ],\n",
       "       [ -1.6],\n",
       "       [ 27.1],\n",
       "       [ 16.1],\n",
       "       [-21.7],\n",
       "       [ 23.1],\n",
       "       [  1. ],\n",
       "       [ 31.5],\n",
       "       [-42.9],\n",
       "       [-12.6],\n",
       "       [  5.7],\n",
       "       [-42.6],\n",
       "       [ -4.9],\n",
       "       [-16.9],\n",
       "       [-21.9],\n",
       "       [  7.7],\n",
       "       [ 19.1],\n",
       "       [ 27.1],\n",
       "       [-38. ],\n",
       "       [ 12.8],\n",
       "       [-24. ],\n",
       "       [-29.3],\n",
       "       [-10.8],\n",
       "       [ 22.3],\n",
       "       [ 51.5],\n",
       "       [ 22.8],\n",
       "       [-21.8],\n",
       "       [ 18.1],\n",
       "       [-15.7],\n",
       "       [  3.2],\n",
       "       [ -9.4],\n",
       "       [-20.4],\n",
       "       [ 16.4],\n",
       "       [  8.9],\n",
       "       [  6.1],\n",
       "       [ 28.7],\n",
       "       [  1. ],\n",
       "       [-35.6],\n",
       "       [ 33.9],\n",
       "       [  1.9],\n",
       "       [  2.2],\n",
       "       [  4.4],\n",
       "       [  4.1],\n",
       "       [ -4.4],\n",
       "       [ 26.9],\n",
       "       [  7.2],\n",
       "       [ 18.6],\n",
       "       [ 25.5],\n",
       "       [ 33. ],\n",
       "       [ -0.5],\n",
       "       [-17.9],\n",
       "       [ -6.1],\n",
       "       [ 40.8],\n",
       "       [ 13.6],\n",
       "       [ -8.4],\n",
       "       [-31.1],\n",
       "       [-27.6],\n",
       "       [ 21.3],\n",
       "       [-32.6],\n",
       "       [  3. ],\n",
       "       [-25. ],\n",
       "       [ 43. ],\n",
       "       [-17.8],\n",
       "       [ -1.8],\n",
       "       [ 44.6],\n",
       "       [ 15.2],\n",
       "       [ 25.3],\n",
       "       [-11.4],\n",
       "       [-39.2],\n",
       "       [ 24.9],\n",
       "       [ 48.2],\n",
       "       [ 20.8],\n",
       "       [  8.8],\n",
       "       [ 35.6],\n",
       "       [ 37. ],\n",
       "       [ -4.3],\n",
       "       [ -1.8],\n",
       "       [ -3.3],\n",
       "       [ 40.9],\n",
       "       [ -8.7],\n",
       "       [ -8.6],\n",
       "       [ 10.8],\n",
       "       [ 36.3],\n",
       "       [ 11.7],\n",
       "       [-29. ],\n",
       "       [ 33.1],\n",
       "       [ 41.2],\n",
       "       [ 24.9],\n",
       "       [ -5.7],\n",
       "       [ 13.2],\n",
       "       [  3.2],\n",
       "       [ 14.2],\n",
       "       [ 12.3],\n",
       "       [ 32.5],\n",
       "       [ 22.2],\n",
       "       [ 34.6],\n",
       "       [ 10.7],\n",
       "       [ -8.2],\n",
       "       [ 31.2],\n",
       "       [-14.7],\n",
       "       [ 18.2],\n",
       "       [ 11.6],\n",
       "       [ 11.8],\n",
       "       [ 30.8],\n",
       "       [ 13.7],\n",
       "       [ 14.1],\n",
       "       [  9.5],\n",
       "       [ 44.1],\n",
       "       [ -3.1],\n",
       "       [-31.6],\n",
       "       [ 15.4],\n",
       "       [ 36.5],\n",
       "       [ 21.4],\n",
       "       [-15.7],\n",
       "       [ 44.3],\n",
       "       [ 11.8],\n",
       "       [  9.9],\n",
       "       [ 25.5],\n",
       "       [  0.8],\n",
       "       [-12.5],\n",
       "       [ 37.2],\n",
       "       [ 25.1],\n",
       "       [-14.2],\n",
       "       [-35.7],\n",
       "       [  3.6],\n",
       "       [ -4. ],\n",
       "       [ 22.6],\n",
       "       [  1.9],\n",
       "       [-39.4],\n",
       "       [ 41.9],\n",
       "       [ -3.6],\n",
       "       [ 24.3],\n",
       "       [-37.6],\n",
       "       [  0.9],\n",
       "       [ -2.7],\n",
       "       [-14.6],\n",
       "       [ -1.8],\n",
       "       [ 17.9],\n",
       "       [ -1.8],\n",
       "       [-39.6],\n",
       "       [-14. ],\n",
       "       [ 15.3],\n",
       "       [ 15.3],\n",
       "       [ -5.8],\n",
       "       [  1.8],\n",
       "       [ 47. ],\n",
       "       [ -8.7],\n",
       "       [ 14.2],\n",
       "       [  5.7],\n",
       "       [ 15.9],\n",
       "       [ -9.2],\n",
       "       [  3.8],\n",
       "       [  0.9],\n",
       "       [ -7.6],\n",
       "       [ 31.6],\n",
       "       [ -9.6],\n",
       "       [-18.2],\n",
       "       [ 10. ],\n",
       "       [ -5.4],\n",
       "       [ 14. ],\n",
       "       [ 25.9],\n",
       "       [  5.6],\n",
       "       [ 24.7],\n",
       "       [ 18.3],\n",
       "       [ 29.6],\n",
       "       [  4.9],\n",
       "       [ 35.9],\n",
       "       [ 19.7],\n",
       "       [-22.4],\n",
       "       [-14.1]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_on_batch(training_data['inputs']).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e56896e-1763-45c2-b39c-62bea750cca6",
   "metadata": {},
   "source": [
    "Since tthe outputs are compared to the targets at each epoch, it may be interesting to compare them manually. \n",
    "To achieve that explain the training target and round all digits to  one digit after the dot,so that they are easily readeable. What we see is that the output and the target are very close to each other but notexactily thesame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bdec364-73df-4639-8927-090bda8dbef9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-31.4],\n",
       "       [-17. ],\n",
       "       [ 34.9],\n",
       "       [  9.3],\n",
       "       [-27.4],\n",
       "       [ 15.5],\n",
       "       [ 47.3],\n",
       "       [ 25.5],\n",
       "       [ 26.9],\n",
       "       [ 14.3],\n",
       "       [  9.7],\n",
       "       [-23.6],\n",
       "       [-12.3],\n",
       "       [ -1.1],\n",
       "       [ 11.5],\n",
       "       [ 23.4],\n",
       "       [ -9.6],\n",
       "       [ -0.2],\n",
       "       [ -0.8],\n",
       "       [ 12.2],\n",
       "       [-13.5],\n",
       "       [ -2.5],\n",
       "       [ -9.9],\n",
       "       [  1.5],\n",
       "       [-17.7],\n",
       "       [  8.1],\n",
       "       [ 15.5],\n",
       "       [ -7.9],\n",
       "       [ 32.6],\n",
       "       [  9.4],\n",
       "       [ -7.2],\n",
       "       [ -6.2],\n",
       "       [-27.4],\n",
       "       [ 29.6],\n",
       "       [ 40.7],\n",
       "       [ -4.6],\n",
       "       [-27. ],\n",
       "       [ 33.2],\n",
       "       [  0.1],\n",
       "       [ 27. ],\n",
       "       [ 29.5],\n",
       "       [ 26.3],\n",
       "       [ 23.4],\n",
       "       [-26.6],\n",
       "       [ 45.1],\n",
       "       [-13.5],\n",
       "       [ 44.1],\n",
       "       [ -9.7],\n",
       "       [ 46.9],\n",
       "       [-16.1],\n",
       "       [ 22.7],\n",
       "       [ 19.2],\n",
       "       [-31. ],\n",
       "       [  4.8],\n",
       "       [ 50.9],\n",
       "       [-33.9],\n",
       "       [-14.5],\n",
       "       [ 20.7],\n",
       "       [ 29. ],\n",
       "       [ 12.3],\n",
       "       [ -8.5],\n",
       "       [ 36. ],\n",
       "       [ -7.3],\n",
       "       [  5.8],\n",
       "       [-12.3],\n",
       "       [ 20.8],\n",
       "       [ 36.7],\n",
       "       [ 26.6],\n",
       "       [-39.2],\n",
       "       [ 12.8],\n",
       "       [  2.1],\n",
       "       [ 23.3],\n",
       "       [ 14.5],\n",
       "       [-20.4],\n",
       "       [-14.8],\n",
       "       [-25.1],\n",
       "       [ -1.6],\n",
       "       [ 12.3],\n",
       "       [-18.1],\n",
       "       [-28.5],\n",
       "       [ 18.3],\n",
       "       [  1.6],\n",
       "       [  9.4],\n",
       "       [ -0.3],\n",
       "       [ 34.2],\n",
       "       [-10.9],\n",
       "       [ 34.1],\n",
       "       [ -4. ],\n",
       "       [-20.2],\n",
       "       [ 22.6],\n",
       "       [ 16.7],\n",
       "       [ 11.5],\n",
       "       [ -4.5],\n",
       "       [ 14.1],\n",
       "       [ 18.6],\n",
       "       [ 12. ],\n",
       "       [-18.2],\n",
       "       [ 24.3],\n",
       "       [ 23.2],\n",
       "       [-10.9],\n",
       "       [ -6.1],\n",
       "       [ -8.2],\n",
       "       [ 30.6],\n",
       "       [ 28.2],\n",
       "       [ 16.9],\n",
       "       [ 22.3],\n",
       "       [ 51.5],\n",
       "       [  4.8],\n",
       "       [ 18.8],\n",
       "       [-15.9],\n",
       "       [ -3.7],\n",
       "       [  2.1],\n",
       "       [-17.6],\n",
       "       [  9.7],\n",
       "       [-30.1],\n",
       "       [-28.9],\n",
       "       [-11.3],\n",
       "       [ -5.6],\n",
       "       [-36.7],\n",
       "       [-24.2],\n",
       "       [ 12.4],\n",
       "       [-32.7],\n",
       "       [-29.1],\n",
       "       [-14.2],\n",
       "       [ 35.9],\n",
       "       [  5.7],\n",
       "       [ 27.6],\n",
       "       [ -6.4],\n",
       "       [ 10.9],\n",
       "       [ -0.7],\n",
       "       [ 16.8],\n",
       "       [ 22.3],\n",
       "       [-32.9],\n",
       "       [  1.6],\n",
       "       [-15.3],\n",
       "       [ 21. ],\n",
       "       [-17.2],\n",
       "       [  4.2],\n",
       "       [ -2.1],\n",
       "       [  3.3],\n",
       "       [ 27.7],\n",
       "       [ -1.4],\n",
       "       [ 29.4],\n",
       "       [  0.3],\n",
       "       [  4.2],\n",
       "       [ -3.2],\n",
       "       [  5.9],\n",
       "       [ 21. ],\n",
       "       [ 14.5],\n",
       "       [ 32.6],\n",
       "       [ -1.8],\n",
       "       [-22.3],\n",
       "       [ -6.4],\n",
       "       [ -2.3],\n",
       "       [-12. ],\n",
       "       [ 28.9],\n",
       "       [ 11.5],\n",
       "       [ 22.7],\n",
       "       [ 24.2],\n",
       "       [ 22.1],\n",
       "       [ 11.8],\n",
       "       [-26.4],\n",
       "       [-24.5],\n",
       "       [  4.8],\n",
       "       [-10.8],\n",
       "       [-14.9],\n",
       "       [-36.3],\n",
       "       [  6.5],\n",
       "       [ 46.6],\n",
       "       [ 11.6],\n",
       "       [-22.6],\n",
       "       [ 24.1],\n",
       "       [ 21.5],\n",
       "       [ -8.2],\n",
       "       [ 24.7],\n",
       "       [ 10.2],\n",
       "       [ 35.1],\n",
       "       [ -3.2],\n",
       "       [-31.8],\n",
       "       [ -5.9],\n",
       "       [ -9. ],\n",
       "       [  3. ],\n",
       "       [-13.3],\n",
       "       [ 31.7],\n",
       "       [  2.1],\n",
       "       [ -2. ],\n",
       "       [  6.7],\n",
       "       [ 16.3],\n",
       "       [ 19.4],\n",
       "       [ -5.1],\n",
       "       [ 36.2],\n",
       "       [ 24.8],\n",
       "       [ -3.7],\n",
       "       [ 31.2],\n",
       "       [ -1.9],\n",
       "       [ -1.9],\n",
       "       [ -6. ],\n",
       "       [-25. ],\n",
       "       [ 40.3],\n",
       "       [ 21.1],\n",
       "       [  6. ],\n",
       "       [ 46.9],\n",
       "       [-38.8],\n",
       "       [-15.9],\n",
       "       [ 27.2],\n",
       "       [ 11.7],\n",
       "       [  2.4],\n",
       "       [ 21.2],\n",
       "       [ 33.5],\n",
       "       [ 25.5],\n",
       "       [ -5.1],\n",
       "       [ 20.5],\n",
       "       [ -5.2],\n",
       "       [ 13.9],\n",
       "       [ 22.6],\n",
       "       [  2.8],\n",
       "       [ 21.3],\n",
       "       [  2.4],\n",
       "       [ -6.6],\n",
       "       [ 29.8],\n",
       "       [ 10.1],\n",
       "       [ -6.2],\n",
       "       [ 21.2],\n",
       "       [ 13. ],\n",
       "       [ 44.9],\n",
       "       [ 33.2],\n",
       "       [ 15.5],\n",
       "       [  9.3],\n",
       "       [-19.2],\n",
       "       [-12.2],\n",
       "       [ 29.4],\n",
       "       [ 15.1],\n",
       "       [-19.3],\n",
       "       [-11.4],\n",
       "       [ 29.2],\n",
       "       [-20.2],\n",
       "       [ 11.6],\n",
       "       [ 12.7],\n",
       "       [ 28.4],\n",
       "       [  5. ],\n",
       "       [ 21.2],\n",
       "       [-27.7],\n",
       "       [  5.5],\n",
       "       [-39.4],\n",
       "       [ 18.1],\n",
       "       [ 17.7],\n",
       "       [-13.1],\n",
       "       [ 13.9],\n",
       "       [  4.6],\n",
       "       [ -9.4],\n",
       "       [ -9.1],\n",
       "       [ 15.2],\n",
       "       [-13.2],\n",
       "       [ -1.7],\n",
       "       [ 35.7],\n",
       "       [ -0.1],\n",
       "       [ 50.8],\n",
       "       [ 24.7],\n",
       "       [ 22.2],\n",
       "       [ 32.8],\n",
       "       [ 49.6],\n",
       "       [-21.3],\n",
       "       [ -2.6],\n",
       "       [  3.5],\n",
       "       [ 22.1],\n",
       "       [-19.4],\n",
       "       [ 27.2],\n",
       "       [ 10.5],\n",
       "       [ 20.9],\n",
       "       [ 21.1],\n",
       "       [-21.9],\n",
       "       [ 32.8],\n",
       "       [ 21.8],\n",
       "       [  8.6],\n",
       "       [ -9.2],\n",
       "       [ 17.3],\n",
       "       [ 43.6],\n",
       "       [ 13.8],\n",
       "       [ 21.8],\n",
       "       [  3.6],\n",
       "       [-20.1],\n",
       "       [ 25.9],\n",
       "       [-18.3],\n",
       "       [ 34.1],\n",
       "       [ 34.8],\n",
       "       [ -5.9],\n",
       "       [ 32.9],\n",
       "       [  0.7],\n",
       "       [-14.6],\n",
       "       [-22.1],\n",
       "       [  1.1],\n",
       "       [ 24.1],\n",
       "       [ -8.1],\n",
       "       [ 18.4],\n",
       "       [-18.9],\n",
       "       [-30.3],\n",
       "       [ 20.1],\n",
       "       [ 26.3],\n",
       "       [-13.1],\n",
       "       [ 17.4],\n",
       "       [ -5.7],\n",
       "       [ 16.2],\n",
       "       [ 21.5],\n",
       "       [ -4.8],\n",
       "       [  4.2],\n",
       "       [ 38.2],\n",
       "       [-25.7],\n",
       "       [  9.3],\n",
       "       [-38.9],\n",
       "       [  6.7],\n",
       "       [ 32.5],\n",
       "       [-27.4],\n",
       "       [ 10.2],\n",
       "       [ 20.2],\n",
       "       [ 21.5],\n",
       "       [  2.7],\n",
       "       [ 29.4],\n",
       "       [ 18.8],\n",
       "       [ 11.2],\n",
       "       [  9.3],\n",
       "       [ -7. ],\n",
       "       [  8.5],\n",
       "       [-24.3],\n",
       "       [-15.8],\n",
       "       [ 31.4],\n",
       "       [ -3.6],\n",
       "       [ 21.2],\n",
       "       [ 25.4],\n",
       "       [ -8.1],\n",
       "       [  4.3],\n",
       "       [ 39.1],\n",
       "       [ -4.8],\n",
       "       [ -1.8],\n",
       "       [ 15.4],\n",
       "       [-17.9],\n",
       "       [ 28.7],\n",
       "       [ 13. ],\n",
       "       [  0.8],\n",
       "       [-12.2],\n",
       "       [-22.4],\n",
       "       [  7.5],\n",
       "       [ 48.3],\n",
       "       [ -2. ],\n",
       "       [-11.9],\n",
       "       [ 22.5],\n",
       "       [ 12.4],\n",
       "       [-34.6],\n",
       "       [ 41.9],\n",
       "       [ 27. ],\n",
       "       [-34.6],\n",
       "       [-24.1],\n",
       "       [ 30.9],\n",
       "       [ 34.9],\n",
       "       [ 32. ],\n",
       "       [ 12.1],\n",
       "       [ 16.8],\n",
       "       [-13. ],\n",
       "       [ 23.9],\n",
       "       [ 11.3],\n",
       "       [-21.9],\n",
       "       [ 18.1],\n",
       "       [ 45.7],\n",
       "       [ -5.5],\n",
       "       [-21. ],\n",
       "       [ 38.5],\n",
       "       [-26.8],\n",
       "       [ 49.9],\n",
       "       [ 16.5],\n",
       "       [ 43.2],\n",
       "       [-10. ],\n",
       "       [-16.2],\n",
       "       [-22.6],\n",
       "       [-14.9],\n",
       "       [  1.5],\n",
       "       [ -1. ],\n",
       "       [ 10.3],\n",
       "       [ 13. ],\n",
       "       [  2.1],\n",
       "       [-27. ],\n",
       "       [ 30.3],\n",
       "       [  2.1],\n",
       "       [-20.3],\n",
       "       [ 13.9],\n",
       "       [ 26.5],\n",
       "       [ -3.8],\n",
       "       [ 14.4],\n",
       "       [ -4.5],\n",
       "       [  5.3],\n",
       "       [ 10.3],\n",
       "       [-20.2],\n",
       "       [-23.9],\n",
       "       [ 21.9],\n",
       "       [-11.9],\n",
       "       [-29. ],\n",
       "       [-25.1],\n",
       "       [  3. ],\n",
       "       [ 23.7],\n",
       "       [ 18.1],\n",
       "       [ 18.2],\n",
       "       [ -4.8],\n",
       "       [  1.6],\n",
       "       [-33.3],\n",
       "       [ 14.1],\n",
       "       [  8.7],\n",
       "       [ -5.9],\n",
       "       [ 38.8],\n",
       "       [  8.8],\n",
       "       [ 11.1],\n",
       "       [-27.1],\n",
       "       [-18.7],\n",
       "       [ 28.3],\n",
       "       [ 31.7],\n",
       "       [  6.4],\n",
       "       [ 16.8],\n",
       "       [-28.6],\n",
       "       [ -6.2],\n",
       "       [ -9.6],\n",
       "       [ 24.3],\n",
       "       [ 48.1],\n",
       "       [ 43.4],\n",
       "       [ -9.7],\n",
       "       [ 42.6],\n",
       "       [-11.2],\n",
       "       [  2. ],\n",
       "       [ 31.8],\n",
       "       [ 22.2],\n",
       "       [-28.5],\n",
       "       [  7.5],\n",
       "       [-19. ],\n",
       "       [  7.6],\n",
       "       [ -5.7],\n",
       "       [-17.6],\n",
       "       [ 21.3],\n",
       "       [ 10.8],\n",
       "       [ 22.2],\n",
       "       [ -2.1],\n",
       "       [  5.9],\n",
       "       [ 35.4],\n",
       "       [-20.2],\n",
       "       [ 15.9],\n",
       "       [ 27.2],\n",
       "       [ -7.7],\n",
       "       [  4.3],\n",
       "       [ 22.2],\n",
       "       [ -2.4],\n",
       "       [-10.9],\n",
       "       [ 30.4],\n",
       "       [  3.4],\n",
       "       [ 24.8],\n",
       "       [ 24.4],\n",
       "       [ 33. ],\n",
       "       [ 21.7],\n",
       "       [ 22.2],\n",
       "       [ -8.9],\n",
       "       [ 20.4],\n",
       "       [ 24. ],\n",
       "       [-20.6],\n",
       "       [-16.9],\n",
       "       [ 19.9],\n",
       "       [ 28.5],\n",
       "       [ 20.1],\n",
       "       [-33.7],\n",
       "       [ -2. ],\n",
       "       [ -3.6],\n",
       "       [  4.5],\n",
       "       [ 15.1],\n",
       "       [ 28.1],\n",
       "       [ -8.7],\n",
       "       [ -2.2],\n",
       "       [ 27.6],\n",
       "       [-42.9],\n",
       "       [ 23.3],\n",
       "       [-35.3],\n",
       "       [ 12.8],\n",
       "       [ -7.8],\n",
       "       [-24.9],\n",
       "       [-33.6],\n",
       "       [ 11.8],\n",
       "       [-12.5],\n",
       "       [ 31. ],\n",
       "       [ 16.6],\n",
       "       [  6. ],\n",
       "       [-20.6],\n",
       "       [ 30.8],\n",
       "       [ 23.1],\n",
       "       [ 35.4],\n",
       "       [-13.2],\n",
       "       [ -1.5],\n",
       "       [ -8. ],\n",
       "       [ 17.1],\n",
       "       [ 12.9],\n",
       "       [ 26.5],\n",
       "       [-13. ],\n",
       "       [  3.6],\n",
       "       [  7.9],\n",
       "       [-22.4],\n",
       "       [ 16.5],\n",
       "       [ -9.9],\n",
       "       [-13.4],\n",
       "       [ 26.7],\n",
       "       [-19. ],\n",
       "       [-42.5],\n",
       "       [  0.1],\n",
       "       [-21.7],\n",
       "       [-28.5],\n",
       "       [ -6.8],\n",
       "       [ 19.8],\n",
       "       [ 34.6],\n",
       "       [-29.3],\n",
       "       [  0.2],\n",
       "       [ 40.1],\n",
       "       [ 24.9],\n",
       "       [ 21.7],\n",
       "       [ 18. ],\n",
       "       [-13.7],\n",
       "       [ -7.8],\n",
       "       [  1.4],\n",
       "       [ 18.3],\n",
       "       [ 15.6],\n",
       "       [-37.6],\n",
       "       [-17.1],\n",
       "       [ 13.3],\n",
       "       [ -6.3],\n",
       "       [ 31.3],\n",
       "       [-25. ],\n",
       "       [ -5.4],\n",
       "       [  2.3],\n",
       "       [ 40.9],\n",
       "       [ 29.6],\n",
       "       [-16.4],\n",
       "       [ -7.8],\n",
       "       [ -1.7],\n",
       "       [  0.5],\n",
       "       [-24. ],\n",
       "       [ 17.1],\n",
       "       [-31.6],\n",
       "       [ 16.2],\n",
       "       [ 28.9],\n",
       "       [  8.1],\n",
       "       [ 51.5],\n",
       "       [  0.3],\n",
       "       [ 15.3],\n",
       "       [ -2.4],\n",
       "       [-18.6],\n",
       "       [ 13.8],\n",
       "       [  6.8],\n",
       "       [-21.3],\n",
       "       [-11.5],\n",
       "       [-17.6],\n",
       "       [-15.7],\n",
       "       [ -3.6],\n",
       "       [-18.7],\n",
       "       [ 36.6],\n",
       "       [ -7.8],\n",
       "       [ -1.1],\n",
       "       [ 48.4],\n",
       "       [ 38.7],\n",
       "       [ 31.4],\n",
       "       [-18.5],\n",
       "       [ 21.3],\n",
       "       [  0.5],\n",
       "       [-20.8],\n",
       "       [ 13.6],\n",
       "       [  4.9],\n",
       "       [ -5.6],\n",
       "       [ 41.1],\n",
       "       [  9.4],\n",
       "       [  3.4],\n",
       "       [ -6.9],\n",
       "       [-33. ],\n",
       "       [-33.9],\n",
       "       [  7.7],\n",
       "       [  3.2],\n",
       "       [ 41.9],\n",
       "       [  2.8],\n",
       "       [-22.1],\n",
       "       [ 15.9],\n",
       "       [  2. ],\n",
       "       [ -6. ],\n",
       "       [ 31.8],\n",
       "       [-24.3],\n",
       "       [ -0.1],\n",
       "       [-17.3],\n",
       "       [ 29.4],\n",
       "       [  3.8],\n",
       "       [ 14.5],\n",
       "       [-23.4],\n",
       "       [  1.9],\n",
       "       [-22.4],\n",
       "       [ 19.3],\n",
       "       [-30.1],\n",
       "       [ 12.1],\n",
       "       [ 25. ],\n",
       "       [ -4.2],\n",
       "       [-12.1],\n",
       "       [ 12.4],\n",
       "       [ 23. ],\n",
       "       [ 18.3],\n",
       "       [ 18.1],\n",
       "       [ -8.8],\n",
       "       [ 21.1],\n",
       "       [  4. ],\n",
       "       [  3.7],\n",
       "       [-32.6],\n",
       "       [-17.9],\n",
       "       [ 23.7],\n",
       "       [-17.7],\n",
       "       [ 21.6],\n",
       "       [ 35. ],\n",
       "       [ 10.1],\n",
       "       [ -9.7],\n",
       "       [-12.2],\n",
       "       [ -6.7],\n",
       "       [-21.2],\n",
       "       [ -0.4],\n",
       "       [  6.2],\n",
       "       [ 20.3],\n",
       "       [ 22.5],\n",
       "       [  4.4],\n",
       "       [-27.4],\n",
       "       [-13.8],\n",
       "       [ 25.2],\n",
       "       [-14.6],\n",
       "       [ 37.4],\n",
       "       [ 16.8],\n",
       "       [  2.3],\n",
       "       [ 37.2],\n",
       "       [-27. ],\n",
       "       [ 20.5],\n",
       "       [ 33. ],\n",
       "       [ 11.3],\n",
       "       [-15.4],\n",
       "       [-19.6],\n",
       "       [ 21.9],\n",
       "       [ 10.5],\n",
       "       [ 38.6],\n",
       "       [ -3.3],\n",
       "       [ 13.7],\n",
       "       [ 38.8],\n",
       "       [ 16.9],\n",
       "       [ 17.2],\n",
       "       [ -3.7],\n",
       "       [-21.1],\n",
       "       [ 34.3],\n",
       "       [ 36. ],\n",
       "       [ 45.2],\n",
       "       [ 18.1],\n",
       "       [  6.6],\n",
       "       [ -0.3],\n",
       "       [-11. ],\n",
       "       [ -5.9],\n",
       "       [ 14.1],\n",
       "       [ 14.3],\n",
       "       [-27.6],\n",
       "       [  0.2],\n",
       "       [-37.6],\n",
       "       [  7.2],\n",
       "       [  9.1],\n",
       "       [-24.1],\n",
       "       [  4. ],\n",
       "       [ -6.8],\n",
       "       [ 32. ],\n",
       "       [ 24.8],\n",
       "       [ -2.2],\n",
       "       [ 24. ],\n",
       "       [ -3. ],\n",
       "       [-18.2],\n",
       "       [-16.9],\n",
       "       [ 30.1],\n",
       "       [-10.1],\n",
       "       [ 22.9],\n",
       "       [-10. ],\n",
       "       [ -1.6],\n",
       "       [-13.8],\n",
       "       [  7. ],\n",
       "       [-20.9],\n",
       "       [ 21.6],\n",
       "       [-25.7],\n",
       "       [-28.8],\n",
       "       [ -6.5],\n",
       "       [ -1.2],\n",
       "       [-16.5],\n",
       "       [ 16.2],\n",
       "       [-33.3],\n",
       "       [-16. ],\n",
       "       [ 14.3],\n",
       "       [ 12. ],\n",
       "       [-26.5],\n",
       "       [ 21.6],\n",
       "       [ 30.8],\n",
       "       [ 14.9],\n",
       "       [-22.9],\n",
       "       [-10.7],\n",
       "       [  3.3],\n",
       "       [ 21.1],\n",
       "       [ 48.1],\n",
       "       [  8.8],\n",
       "       [ 43.3],\n",
       "       [ 46.8],\n",
       "       [  0.9],\n",
       "       [-11.8],\n",
       "       [ 11.8],\n",
       "       [ -0.2],\n",
       "       [  4.7],\n",
       "       [-14. ],\n",
       "       [-44.2],\n",
       "       [ 11.1],\n",
       "       [ 29.8],\n",
       "       [ 42.3],\n",
       "       [ 29.1],\n",
       "       [-15. ],\n",
       "       [ 14.6],\n",
       "       [ 42.4],\n",
       "       [-14. ],\n",
       "       [-11.2],\n",
       "       [ 17.4],\n",
       "       [  9.2],\n",
       "       [ 19.3],\n",
       "       [ -8.7],\n",
       "       [  9.8],\n",
       "       [  2.4],\n",
       "       [ 16.6],\n",
       "       [ 27.1],\n",
       "       [-31.6],\n",
       "       [-12.8],\n",
       "       [-15.6],\n",
       "       [ -7.4],\n",
       "       [-20.6],\n",
       "       [ 17.2],\n",
       "       [-37.2],\n",
       "       [ 31.4],\n",
       "       [ -3.4],\n",
       "       [ 10.4],\n",
       "       [ 13.1],\n",
       "       [ -5.1],\n",
       "       [  1.1],\n",
       "       [-16.4],\n",
       "       [ 12.1],\n",
       "       [-35.9],\n",
       "       [ 18.4],\n",
       "       [  0.3],\n",
       "       [-36.5],\n",
       "       [ 21.7],\n",
       "       [-20.5],\n",
       "       [  1.9],\n",
       "       [ -1.2],\n",
       "       [-19.3],\n",
       "       [ 19.3],\n",
       "       [ 33.6],\n",
       "       [ 10.2],\n",
       "       [ 46.9],\n",
       "       [ 19.1],\n",
       "       [ 26.7],\n",
       "       [  4.6],\n",
       "       [  0.5],\n",
       "       [  1.4],\n",
       "       [ -2.5],\n",
       "       [-14.2],\n",
       "       [ 20.3],\n",
       "       [ 30.4],\n",
       "       [ 29.4],\n",
       "       [  6. ],\n",
       "       [-14.3],\n",
       "       [ 15.4],\n",
       "       [ 43. ],\n",
       "       [-16.9],\n",
       "       [ -2.7],\n",
       "       [ -0.9],\n",
       "       [ 13.1],\n",
       "       [-15.8],\n",
       "       [ 17.1],\n",
       "       [ 23.1],\n",
       "       [ -5.4],\n",
       "       [-18.4],\n",
       "       [ 12.9],\n",
       "       [ 23.4],\n",
       "       [ 37.7],\n",
       "       [  4.7],\n",
       "       [-32. ],\n",
       "       [ -4.5],\n",
       "       [ 37. ],\n",
       "       [ -9.8],\n",
       "       [ -6.8],\n",
       "       [ 13.3],\n",
       "       [  4.4],\n",
       "       [-13.5],\n",
       "       [ 12.1],\n",
       "       [  9.9],\n",
       "       [ 32.1],\n",
       "       [  9.2],\n",
       "       [-41.9],\n",
       "       [ 12.7],\n",
       "       [ -4.5],\n",
       "       [ 28.4],\n",
       "       [ 27.4],\n",
       "       [-19.5],\n",
       "       [-38.3],\n",
       "       [ 24.7],\n",
       "       [ 40.6],\n",
       "       [ 34.5],\n",
       "       [-33.2],\n",
       "       [-27.4],\n",
       "       [  7.3],\n",
       "       [ -3.4],\n",
       "       [ 20.2],\n",
       "       [ 21.9],\n",
       "       [ 41.6],\n",
       "       [ 29.8],\n",
       "       [  8.1],\n",
       "       [ 13.9],\n",
       "       [ 38.4],\n",
       "       [  7.2],\n",
       "       [ 32.3],\n",
       "       [ 21.5],\n",
       "       [-19.3],\n",
       "       [ 24.2],\n",
       "       [ -6.8],\n",
       "       [ -9.9],\n",
       "       [ 34.1],\n",
       "       [ 31.7],\n",
       "       [ 20.7],\n",
       "       [ -6.7],\n",
       "       [ 34.4],\n",
       "       [  6. ],\n",
       "       [ -4.8],\n",
       "       [  0.6],\n",
       "       [ 24.5],\n",
       "       [ 18.7],\n",
       "       [ 37.5],\n",
       "       [ -0.6],\n",
       "       [ 53.6],\n",
       "       [ -0.9],\n",
       "       [ 27.7],\n",
       "       [ 15.2],\n",
       "       [-21.3],\n",
       "       [ 22.7],\n",
       "       [  2.2],\n",
       "       [ 31. ],\n",
       "       [-41.5],\n",
       "       [-11.5],\n",
       "       [  5. ],\n",
       "       [-42.1],\n",
       "       [ -4.9],\n",
       "       [-15.8],\n",
       "       [-20.8],\n",
       "       [  7.6],\n",
       "       [ 19.8],\n",
       "       [ 27.4],\n",
       "       [-36.8],\n",
       "       [ 13.1],\n",
       "       [-23.2],\n",
       "       [-29.1],\n",
       "       [-10. ],\n",
       "       [ 22. ],\n",
       "       [ 50.9],\n",
       "       [ 23.6],\n",
       "       [-21.1],\n",
       "       [ 17.8],\n",
       "       [-15.3],\n",
       "       [  3.1],\n",
       "       [ -9.5],\n",
       "       [-20.7],\n",
       "       [ 14.9],\n",
       "       [  8.8],\n",
       "       [  6.5],\n",
       "       [ 27.8],\n",
       "       [  1.5],\n",
       "       [-34.8],\n",
       "       [ 34. ],\n",
       "       [  2.7],\n",
       "       [  1.5],\n",
       "       [  4.3],\n",
       "       [  4.3],\n",
       "       [ -4.4],\n",
       "       [ 27.1],\n",
       "       [  6.9],\n",
       "       [ 18.5],\n",
       "       [ 25.9],\n",
       "       [ 31.7],\n",
       "       [  0.4],\n",
       "       [-17.1],\n",
       "       [ -6.2],\n",
       "       [ 39.8],\n",
       "       [ 14.9],\n",
       "       [ -8.6],\n",
       "       [-30.3],\n",
       "       [-28.2],\n",
       "       [ 22. ],\n",
       "       [-31.9],\n",
       "       [  3.2],\n",
       "       [-23.6],\n",
       "       [ 43.2],\n",
       "       [-18.6],\n",
       "       [ -1.5],\n",
       "       [ 44. ],\n",
       "       [ 14.5],\n",
       "       [ 25.6],\n",
       "       [-12. ],\n",
       "       [-38.4],\n",
       "       [ 24.5],\n",
       "       [ 46.5],\n",
       "       [ 19.9],\n",
       "       [  9.4],\n",
       "       [ 34.7],\n",
       "       [ 35.5],\n",
       "       [ -4.4],\n",
       "       [ -0.6],\n",
       "       [ -2.8],\n",
       "       [ 40.5],\n",
       "       [ -7.5],\n",
       "       [ -9.1],\n",
       "       [ 11.8],\n",
       "       [ 35.2],\n",
       "       [ 11.3],\n",
       "       [-28. ],\n",
       "       [ 31.3],\n",
       "       [ 40.5],\n",
       "       [ 24.1],\n",
       "       [ -4.7],\n",
       "       [ 12.7],\n",
       "       [  3.5],\n",
       "       [ 13.3],\n",
       "       [ 13.1],\n",
       "       [ 31.4],\n",
       "       [ 22.3],\n",
       "       [ 33.3],\n",
       "       [ 10.8],\n",
       "       [ -7.7],\n",
       "       [ 31.5],\n",
       "       [-14.4],\n",
       "       [ 16.8],\n",
       "       [ 12.6],\n",
       "       [ 11.6],\n",
       "       [ 29.6],\n",
       "       [ 13. ],\n",
       "       [ 13.9],\n",
       "       [  9.5],\n",
       "       [ 42.5],\n",
       "       [ -2.8],\n",
       "       [-31.6],\n",
       "       [ 15.6],\n",
       "       [ 35.6],\n",
       "       [ 20.4],\n",
       "       [-15.5],\n",
       "       [ 42.5],\n",
       "       [ 12.1],\n",
       "       [ 10.1],\n",
       "       [ 24.8],\n",
       "       [  1.7],\n",
       "       [-12.3],\n",
       "       [ 36.1],\n",
       "       [ 25.4],\n",
       "       [-14.3],\n",
       "       [-34.1],\n",
       "       [  2.5],\n",
       "       [ -4.3],\n",
       "       [ 21.3],\n",
       "       [  2.4],\n",
       "       [-38.2],\n",
       "       [ 40.4],\n",
       "       [ -2.3],\n",
       "       [ 23.9],\n",
       "       [-35.8],\n",
       "       [  1.9],\n",
       "       [ -3.5],\n",
       "       [-13.3],\n",
       "       [ -1.6],\n",
       "       [ 17.6],\n",
       "       [ -1.6],\n",
       "       [-39.2],\n",
       "       [-13. ],\n",
       "       [ 16.5],\n",
       "       [ 16. ],\n",
       "       [ -5.4],\n",
       "       [  2.2],\n",
       "       [ 45.2],\n",
       "       [ -8. ],\n",
       "       [ 14.2],\n",
       "       [  6. ],\n",
       "       [ 15.7],\n",
       "       [ -9.9],\n",
       "       [  3.9],\n",
       "       [  2. ],\n",
       "       [ -6.8],\n",
       "       [ 31.3],\n",
       "       [ -9.1],\n",
       "       [-18.7],\n",
       "       [ 10.7],\n",
       "       [ -5.5],\n",
       "       [ 13.7],\n",
       "       [ 24.3],\n",
       "       [  5.6],\n",
       "       [ 25.2],\n",
       "       [ 18.3],\n",
       "       [ 28.7],\n",
       "       [  6. ],\n",
       "       [ 34.4],\n",
       "       [ 18.6],\n",
       "       [-21.5],\n",
       "       [-14.8]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['targets'].round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc707407-341c-450d-aa54-9e3f7e53efc9",
   "metadata": {},
   "source": [
    "##### Plotting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcf89c7-2690-473a-b2d4-b77775c1dfe5",
   "metadata": {},
   "source": [
    "Finally , we can us the same techniques as in our previous minimal example. We can plot the output against the target. Since, we expect them to be very close to each other, the lines should be as close to 45 deegree  as possible. and that is precisely, what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3914000d-2115-4764-94b4-3d7e7df0544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.squeeze(model.predict_on_batch(training_data['inputs'])), np.squeeze(training_data['targets']))\n",
    "plt.xlabel('outputs')\n",
    "plt.ylabel('targets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48181a9f-39d7-4b3e-8d23-810afc13af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "### THis is not running, it tells me to restart kernnel !!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eafe06-1fa6-4835-98fb-cdd4588569d5",
   "metadata": {},
   "source": [
    "#### Customizing your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bdcdb2-e1a2-4142-8435-c6189b691c40",
   "metadata": {},
   "source": [
    "##### Numpy Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30b1419-4686-44f8-bcfe-946f0778d3fc",
   "metadata": {},
   "source": [
    "In our numpy neural network, we had several decision to make, First ,we had to select the bset way to initialize the weight.\n",
    "\n",
    "Back then, we choose the starting point of the weight and biases to be random numbers between -0.1 to 0.1. Here, we left the default tensorflow settings to do the magic.\n",
    "Infact, if we want o make this example as close to the original as possible , we can set the random  uniform initializer where we definre the layer.\n",
    "\n",
    "Instead of having a single arguement, output size , we can also have a kernel initializer and a bias initializer.\n",
    "\n",
    "kernel here is a broader term for weight\n",
    "\n",
    "tf.keras.layers.Dense(output)_size,kernel_initializer,bias_initializer)\n",
    "function that is laying dowm the model(used to 'stack layers') and initialize weights \n",
    "\n",
    "Let kernel  -initialer = tf.random_uniform _initializer from -0.1 to 0.1, imilarly , bias initializer will be equal to the same expression.\n",
    "\n",
    "Naturally, you can specify other ways you want your weights  and bias to be initialized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a3f3f5-9d65-4346-b8ac-3b2141c6cc5b",
   "metadata": {},
   "source": [
    "##### Set a learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3560763-1e53-480e-8b62-8a88838c7511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_rate = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224bb503-03e1-4504-bf3f-eefff3fba506",
   "metadata": {},
   "source": [
    "The learning rate is an integral part of the optimizer. Here,we took the default Stochastic gradient descent or sgd . we can create a variable called custom optimizer = tf.keras.optimizer.SGD and specify several arguement. The only one we know is the learning rate\n",
    "o let's set it to 0.02 as we did in the numpy example\n",
    "tf.keras.optimizers.SGD(leaning_rate)Stochastic gradient descent optimizers including support for learning rate momentum, decay, etc.\n",
    "Next we should replace the string as agda model and compile it with a new custom optimizer.\n",
    "\n",
    "The new result will be pracically thesame but the small difference is that we have to set the learning rate ourselves.\n",
    "\n",
    "Is a good idea for you to know that you can always refer to the tensor flow documentation and figure out how to customize your model\n",
    "\n",
    "Now the only thing we have left is the loss.\n",
    "\n",
    "We will use the built in losses without customizing them since matters are much more complicated\n",
    "\n",
    "In the future , you may want to try out new loss function.\n",
    "Let's train our model with this tweet , surprisngly , the results are not different, our weight and biases are still the same as well as the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c0cd7b-81f5-4fa1-b26e-3b25c2e9600d",
   "metadata": {},
   "source": [
    "### Week 13: Day 3 – Deep Nets Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3744450c-c4db-41f6-b044-933ac5126ac5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a01d890-c947-49df-ab5e-c5eed65f3011",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers are the linear combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f61de1-d1e1-4c61-9968-9620a6935bbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### What is a deep net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb41683-f25d-4550-9e1d-0ab9f14ecacb",
   "metadata": {},
   "source": [
    "#### Really understand deep nets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435e7583-440f-48bf-aa1a-bd794893b230",
   "metadata": {},
   "source": [
    "#### Why do we need non-linearities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab05e54-b685-490e-9ffe-a26b0d6ecadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "escape m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e051d2de-0001-4310-b6cc-318e47fbedb7",
   "metadata": {},
   "source": [
    "In other to have deep nets and find complete relationships through arbitrary function we need non linearity.\n",
    "\n",
    "It is used to represent complicated relationship.\n",
    "we cant stack layer if we have just linear relationship.\n",
    "\n",
    "h = x *W1\n",
    "\n",
    "y = x * W1 * W2 =\n",
    "\n",
    "X *W*\n",
    "\n",
    "we can train the simple linear model and get same result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcc911c-a183-4453-97ad-39759dc6d09c",
   "metadata": {},
   "source": [
    "you can combine lineear and non linear function\n",
    "\n",
    "non linearity is sigmoid function\n",
    "\n",
    "Input layer : is our first layer\n",
    "\n",
    "output layer is the last layer is what we compare our output to.\n",
    "\n",
    "Hidden layers are the hidden units or nodes the weighrt is the number of the hidden units we know the input but we dont know what is inside Hypaparemeters are set by us before we start optimizing. parameters are derived through optimazation The weight is done with the same weigth\n",
    "\n",
    "Depth and weigth and learning rate are hyper parameters and they are set by us before we start optimizing.\n",
    "\n",
    "Input layer : is our first layer\n",
    "\n",
    "output layer is the last layer is what we compare our output to.\n",
    "\n",
    "Hidden layers are the hidden units or nodes the weighrt is the number of the hidden units we know the input but we dont know what is inside Hypaparemeters are set by us before we start optimizing. parameters are derived through optimazation The weight is done with the same weigth\n",
    "\n",
    "Depth and weigth and learning rate are hyper parameters and they are set by us before we start optimizing.\n",
    "\n",
    "An illustration of deep net\n",
    "\n",
    "input layers data each circle reprens the data we feed to train the model we feed the model we have 8 e.g weather forecast e.g humidty , high and low temperature, ave temp, invusbibilty and distanceprecipitation, clouud cover\n",
    "\n",
    "To combine linearity we need weigth. weight are 8x9 matrix a vector of 8x9\n",
    "\n",
    "each error reps the mathematicaly expression erors represents weigths weigth is a part of the hidden layer non linearity does not change the shape of the experiession , it only changes its linearity.\n",
    "\n",
    "weigth has two index numbers\n",
    "\n",
    "units it refers to and hidden units is referring to.\n",
    "\n",
    "hiden units and combine the non linearity\n",
    "\n",
    "we can add a 100 hidden layer\n",
    "\n",
    "we will reach the output layer. we decide the number of output we want to reach ie humidty, temp, distance etc\n",
    "\n",
    "​\n",
    "\n",
    "Simple\n",
    "0\n",
    "12\n",
    "Python 3 (ipykernel) | Idle\n",
    "Time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16722b2c-30a8-411b-be5c-8f890a55e177",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaf6311-05e2-4e2b-8d29-6cca5d5f65d9",
   "metadata": {},
   "source": [
    "Activation function is another name for non-linearity in ml context\n",
    "\n",
    "Non linearity transform input into output of different types.\n",
    "\n",
    "They are also called transfer functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40658b1-8dbf-4873-a7ec-b01a14245bc2",
   "metadata": {},
   "source": [
    "#### Softmax activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e46fe9-1250-4170-91f6-632d9992d744",
   "metadata": {},
   "source": [
    "It has no definite graph\n",
    "a = xw + b\n",
    "y = softmax(a)\n",
    "\n",
    "it considers information about the whole set of numbers we have\n",
    "It is used as final output layer in classification problems.\n",
    "\n",
    "soft max is special\n",
    "you calcucate the denominaor\n",
    "\n",
    "probabilities\n",
    "it combines arbitrary numbers and convert them into probabilities.\n",
    "\n",
    "The final output of the outlayer is a probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5241294e-4423-473d-8edf-b6ee8c55fc7a",
   "metadata": {},
   "source": [
    "#### Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a599b-fe67-46ee-aed6-27902f2cd829",
   "metadata": {},
   "source": [
    "Backpropagation layers\n",
    "\n",
    "deltas or hidden layer are to difine\n",
    "\n",
    "Forward propagation is a way of pushing input into the net.\n",
    "We must compare he output to the weight\n",
    "\n",
    "We can trace the contribution of each unit to the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d080ce9-2800-4528-b688-12c692edf05e",
   "metadata": {},
   "source": [
    "Backpropagation layers\n",
    "\n",
    "deltas or hidden layer are to difine\n",
    "\n",
    "Forward propagation is a way of pushing input into the net.\n",
    "We must compare he output to the weight\n",
    "\n",
    "We can trace the contribution of each unit to the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09423f7-360b-48a4-980f-42cca2401eda",
   "metadata": {},
   "source": [
    "Backpropagation layers\n",
    "\n",
    "deltas or hidden layer are to difine\n",
    "\n",
    "Forward propagation is a way of pushing input into the net.\n",
    "We must compare he output to the weight\n",
    "\n",
    "We can trace the contribution of each unit to the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b208b6-f4b6-438e-aacd-f6aa69ba1f24",
   "metadata": {},
   "source": [
    "Backpropagation layers\n",
    "\n",
    "deltas or hidden layer are to difine\n",
    "\n",
    "Forward propagation is a way of pushing input into the net.\n",
    "We must compare he output to the weight\n",
    "\n",
    "We can trace the contribution of each unit to the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90151b31-872c-4875-ab9a-7a2fe12ff1c9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Backpropagation of input layers\n",
    "\n",
    "deltas or hidden layer are tricky to difine\n",
    "Procedure to defining them is called Backpropagation.\n",
    "\n",
    "Forward propagation is a way of pushing input into the net.\n",
    "\n",
    "We must compare the output to the weight.\n",
    "\n",
    "We can trace the contribution of each unit to the input hidden or not to the   way of the output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc173a2-627f-402f-a1dc-93031bf098da",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Backpropagation – intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e668235a-9818-4376-bea0-52b4b603326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6247e3-0063-43fa-ba41-f96c182136f8",
   "metadata": {},
   "source": [
    "### Week 13: Day 3 – Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ec0e4-823e-46cf-bc2d-d626d502e422",
   "metadata": {},
   "source": [
    "#### Underfitting and overfitting. A regression example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1504c5-fb2e-4182-aefb-4669f8f13bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e9867d8-08ca-44e8-901d-1b00c63528d6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Overfitting our model focusing on a particular point and missing the point. They capture the random noise.\n",
    "noise are irelevant data.\n",
    "\n",
    "Underfitting :the model did not capture the underlying logic of the data\n",
    "\n",
    "They are clumsy, accuracy is low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a78cdd1-4fbe-4cf3-b4e9-5b831e72274b",
   "metadata": {},
   "source": [
    "#### Underfitting and overfitting. A classification example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd034c0a-7b1e-4772-972e-d8d9c9b0174a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "classification \n",
    "Regression\n",
    "\n",
    "A good model is a quadractic function with few errors.\n",
    "\n",
    "A balance Between an underfitting  and overfitting mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78c22c5-de1b-4d14-8f3b-421300441252",
   "metadata": {},
   "source": [
    "You camt talk about overfitting without talking  about Bias and variance . Bias is a prediction error.\n",
    "\n",
    "The difference btw predicted and actual value.\n",
    "\n",
    "Variance , if the trainin g model performs well with training but not with testing data set, then variance has occured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889632cc-abaf-4da0-8408-3a95f43b9636",
   "metadata": {},
   "source": [
    "\n",
    "Overrfitting  : it causes low performance. it leads to poor performance.when the variance is high , your model is over fitted.durring training the error is low. but you get high error during testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a432159-4c1f-4069-9f89-0e268554bf92",
   "metadata": {},
   "source": [
    "Under fitting  : ypor bias is high, test error is also high.\n",
    "use training , bias , variance to explain it\n",
    "\n",
    "\n",
    "the optimum is training and testing error is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55489ff-90d1-41cf-9939-59d58094bda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "How to stop ovrfitting\n",
    "\n",
    "Train with plenty data\n",
    "feature selection\n",
    "stratified k-fold\n",
    "\n",
    "regularizatin\n",
    "data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2f3ff9-1120-4093-9a5c-4b5ec21bec94",
   "metadata": {},
   "source": [
    "#### Train vs validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4c1c96-4ccc-4998-a9bb-e92961cab68c",
   "metadata": {},
   "source": [
    "\n",
    "To solve over fiting problem You need to identify it first .\n",
    "Overfittinhg is the real enemy in ml\n",
    "\n",
    "training the training set happens\n",
    "\n",
    "validation to detect and prevent over fitting. you take it to the vadidating set.\n",
    "we perform it \n",
    "train loss and validation loss (if the validation set start increasing we need to stop,it means we are pverfitting , so we need to stop\n",
    "\n",
    "and test. It need to be done with out over;apping each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2ee747-4916-4175-a3c1-ebf90ba324d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3135b969-f8ae-4cc6-9b36-bb2b5eb80ff1",
   "metadata": {},
   "source": [
    "#### Train vs validation vs test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bb19f1-b7b8-4613-918a-a2fbf716be7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b3abf4-e614-4d64-be7f-37946bf1c68c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a389ee7-f025-47d7-9ad8-61aed3702fa1",
   "metadata": {},
   "source": [
    "#### N-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f183cb-a18d-4b63-8ed8-0d2659efcf3f",
   "metadata": {},
   "source": [
    "N-fold is used in small data, you merge training and validation.but dont touch the test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b6a7fc-8725-4940-b544-f59b99023172",
   "metadata": {},
   "source": [
    "Cross validation is checking your  data to know how well your model performs after traioning\n",
    "\n",
    "checking thhe efficiency of ypur model after training by giving your model a data it has not seen before to see if it has learnt\n",
    "\n",
    "K-fold  and stratified cross validation a ere commonly used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd97ef-1348-41e0-a76d-60c3407018ef",
   "metadata": {},
   "source": [
    "#### Early stopping – motivation and types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a43274-85f6-4a33-aa85-5fd1c8b631a4",
   "metadata": {},
   "source": [
    "we train the model until the loss function is minimized.\n",
    "\n",
    "Early stopping is introduced to prevent overfitting.\n",
    "\n",
    "stop when update becomes too small\n",
    "\n",
    "validation set stragegy is the early stopping  technique that is  used to stop over fitting.\n",
    "\n",
    "stop when the validation loss starts increasing or when the training loss is minimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c9beff-f7a4-49d1-8a00-7e04727e6854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6913b748-5f70-4db6-83c7-0e926c1405b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd6eb74b-6524-40bd-a596-4c97b84483db",
   "metadata": {},
   "source": [
    "### Week 13: Day 3 – Initializing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f261a91-0bc4-4f6a-84a6-5593e3abe7c2",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0781b7f-ed62-442e-87f7-953489d40b2c",
   "metadata": {},
   "source": [
    "IT is the process where we set the initial values of weight.\n",
    "\n",
    "we can initialize our weigtht until is equal to a constant.\n",
    "\n",
    "The three hidden unit are symetrical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328d7b8f-b068-4e00-9561-34177ee9c0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec5a9a37-2a98-46d6-9c61-20ecb927eb01",
   "metadata": {},
   "source": [
    "\n",
    "#### Types of simple initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc782a38-91e5-4f62-b2d4-3ad70437de81",
   "metadata": {},
   "source": [
    "1.initialize using a small range in a uniform manner\n",
    "2.normal initializer : thesame idea but picked from 0 mean normal distribution mean 0, std - 0.1\n",
    "3. sigmoid activation : it is peculiar around its mean and combination\n",
    "\n",
    "Non linearity are essential for deep net.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a038c983-7d2c-490a-9af2-8a1e59d82d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a6f542f-d74b-41cd-b1b5-e7a07fe4eb36",
   "metadata": {},
   "source": [
    "#### Xavier’s initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1499f26-db50-4340-be6f-4a428dd1a169",
   "metadata": {},
   "outputs": [],
   "source": [
    " video is not opening "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aea8ded-b998-4a7a-b011-68ea1c99297a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4946b8b-2198-450a-af9b-ec90042cdefa",
   "metadata": {},
   "source": [
    "#### Week 13: Day 4 – Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8a4a59-2e54-4371-9d22-c026fbaf1eb9",
   "metadata": {},
   "source": [
    "#### SGD&Batching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb4150d-0cca-4778-bfb3-a671be17e6e1",
   "metadata": {},
   "source": [
    " GD short for gradient descent is very clumsy\n",
    "SGD  sochastic is related to batching\n",
    "It updates in real time\n",
    "\n",
    "You split data in N-batches\n",
    "\n",
    "It is widely used \n",
    "\n",
    "splitting to batches helps the cpu to train in batches\n",
    "\n",
    "mini batches Gd is SGD\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9008ce02-27be-418b-8432-6a11f6b44d32",
   "metadata": {},
   "source": [
    "### Local minima pitfalls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ebbd25-72df-4fb6-8344-170c7c13f518",
   "metadata": {},
   "source": [
    "\n",
    "In real life ,losss fuction is not regular\n",
    "\n",
    "GD depens on the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba87f25b-cc7a-44e3-b9b0-6d8fb9bf503b",
   "metadata": {},
   "source": [
    "### Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10bc2c0-0013-407d-9216-7749e9e15ab0",
   "metadata": {},
   "source": [
    "Momentum is like rolling  a ball form a top of  a mountain.\n",
    "small deep = local minimum\n",
    "\n",
    "big valley is the global minimum\n",
    "    w <- w (t)- eta l /aw (t) - alpha eta al /aw(t-1)\n",
    "    \n",
    "alpha = 0.9 is a conventional rule of thumb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33415d04-f3d2-437c-bd21-c2ac3a4f2e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422a627f-702b-4c24-8916-30d004424af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3be71f1e-d987-4a23-9f50-71c102bee195",
   "metadata": {},
   "source": [
    "### Learning rate schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5991d42f-2c0e-4770-a79f-6aab45f5e5e6",
   "metadata": {},
   "source": [
    "Hyper parameters  are the number of learning rate like \n",
    "width and depth of the algorithm\n",
    "\n",
    "the number of hidden units\n",
    "small enough \n",
    "big enough\n",
    "\n",
    "implementation\n",
    "\n",
    "predetemined learning rate\n",
    "\n",
    "Exponential schedules : it smoothly reduces or decays the learning rate.\n",
    "\n",
    "\n",
    "the presence of the learning scedule is what matters.\n",
    "\n",
    "\n",
    "learning rate eta, \n",
    "Adopt the learning rate schedule\n",
    "\n",
    "start from a higher initial learning rate the 1st , 5 epoch \n",
    "at some point we lower the rate to avoid oscilliation.\n",
    "\n",
    "you get accurate solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d13dbba-cf2c-4b38-9ed8-c69f849cc727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade14b43-7427-43b7-90bf-cd494233de50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8686d33-26b2-45ca-93c4-6f481b90838d",
   "metadata": {},
   "source": [
    "#### Learning rate schedules. A picture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f199dd9f-21e8-4929-a442-7ac990f9163e",
   "metadata": {},
   "source": [
    "\n",
    "small learning rate will reach the goal slowly\n",
    "A well selected learning rate will minimize the loss much faster and more acuurately than a low learning rate\n",
    "\n",
    "high learning rate may not  minimize the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf964ae-8544-416d-bfd2-314940972fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222354db-efd7-4f01-8a42-f13634ddb066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04e80ac1-57a5-47b3-bbc4-545b949d561f",
   "metadata": {},
   "source": [
    "#### Adaptive learning schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bf2c91-6dbb-4f1a-a726-012a3565758b",
   "metadata": {},
   "source": [
    "Adagrad \n",
    "\n",
    "Adaptive gradint  algorithm , 2011\n",
    "\n",
    "G is the adaptative magic\n",
    "\n",
    "\n",
    "Absolom is a small number we need to put there.\n",
    "The adaptation is per weight.\n",
    "\n",
    "\n",
    "RMSPROP\n",
    "\n",
    "root mean square propagation\n",
    "\n",
    "they are very logical and smart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beea55c-41e0-4aca-86f3-4d1923c42228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae62572-ba2b-4cf5-a3c4-d4e01e828a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfafc86d-c238-46d5-a697-1fde44473da1",
   "metadata": {},
   "source": [
    "#### Adaptive moment estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94001ed2-f5b5-49d0-88c5-186f7bd27df7",
   "metadata": {},
   "source": [
    "\n",
    "This is more superior than Adagrad and RMSprop.\n",
    "\n",
    "22/12/2014  it was proposed\n",
    "ml preparation does not stop after a course you take , you need to keep upgrading\n",
    "\n",
    "Is a combination of the above two.\n",
    "\n",
    "Adam is short for adaptive moment estimation\n",
    "\n",
    "delta wi(t) = eta // squareroot G1(t)\n",
    "\n",
    "m is the mometum we discussed earlier but a bit transfored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcd0827-7b42-4cc0-a3d9-7caa7defa20e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dad660a-3476-4416-b19e-017f5e89b0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf12ac2-4952-44c0-aa53-1651437eb4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Week 13: Day 4 – Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8e327f-34d1-4043-bb96-e3f446d383e6",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf90407a-c114-4429-904d-943b8ee83066",
   "metadata": {},
   "source": [
    "any manipulation applied to the dataset before loading it.\n",
    "\n",
    "motivation'\n",
    "\n",
    "compatibility with the dat we use \n",
    "\n",
    "make it compatiblew \n",
    "\n",
    "orders of magnitude\n",
    "\n",
    "a value of 1 is negligible to a value of 1000\n",
    "\n",
    "+ Generalization \n",
    "different probles with similar model you have used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab03c044-dd91-4811-8f91-4dbc66c409bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f88890b-fa42-4aef-a5a6-f4754c0da7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc7b57fa-1c6d-4884-ac0f-3de7bca6471c",
   "metadata": {},
   "source": [
    "### Basic preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175bd747-26f5-4070-972e-cb9b2bfcf92c",
   "metadata": {},
   "source": [
    "Relative matrx is important when we have time serie problem. Ml prepocessing \n",
    "\n",
    "we are not interested in relative value. apple have green and red.\n",
    "\n",
    "log transfored finacuial data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07247cd-04fa-4f1e-91b2-35b81df66c31",
   "metadata": {},
   "source": [
    "#### Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcbf42e-4037-46f8-a6fd-d53728dcb844",
   "metadata": {},
   "source": [
    "\n",
    "Standardizatio  (feature scaling)\n",
    "Transformaing data to a stardard scale\n",
    "  We  have forced the features to appear similar\n",
    "  \n",
    "  Normalization = use L1 or L2 -norm\n",
    "  \n",
    "  PCA -principal component analysis\n",
    "  \n",
    "  whitening  comes after PCA\n",
    "  \n",
    "  Standardization\n",
    "  \n",
    "  Normalization\n",
    "  \n",
    "  PCA\n",
    "  \n",
    "  Whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dfd063-1241-4d2a-966f-504cabf7c241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff67dc75-4ab8-446c-ad2f-058f19199f89",
   "metadata": {},
   "source": [
    "#### Dealing with categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416fd1e3-609b-461b-b388-e252ad3dc8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b9d3d8-1696-4b51-b82a-c01041d9938b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79539337-09fd-4a06-a69c-64e3d0a72f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3601840-b821-4e6a-8fdc-cb94f8d70e9b",
   "metadata": {},
   "source": [
    "#### One hot vs binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d953219-2071-40fb-ba80-75712401c179",
   "metadata": {},
   "source": [
    "We use binary when dealing with many variable. Binary encoding means turning the values into two variables.\n",
    "It proves problematic, but we need to introduce some other ways of solving the problem\n",
    "\n",
    "One hot encoding have one challenge,It requires alot of new variables. \n",
    "Few categories we useone hand and many categories we use binary\n",
    "Uncorrelated and unequvacal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dcc387-8903-45f2-8903-d9256d31e9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5312ef84-b251-44db-8905-e420801d22c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e41bd29e-360a-4212-ae73-7f87cd613a0d",
   "metadata": {},
   "source": [
    "#### Week 13: Day 4 – Deeper Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3486c36-32d9-4601-81f0-8af26eccc4c0",
   "metadata": {},
   "source": [
    "#### MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536baa8f-fcc0-4d92-b365-c5a377eb9f8d",
   "metadata": {},
   "source": [
    "\n",
    "It contains of 70,000 handwritten digits.\n",
    "Hello world of ml\n",
    "Mnest classification\n",
    "10 cloasses \n",
    "0-9\n",
    "\n",
    "Reasons why we use it:\n",
    "    \n",
    "+ very visual problems.\n",
    "+ extremely common\n",
    "+ easy to build up to CNN\n",
    "+very big and preprocessd\n",
    "\n",
    "\n",
    "yann.lecun,com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8114ba59-0c67-4c2f-b8ff-3cd63c14a0dd",
   "metadata": {},
   "source": [
    "#### MNIST – Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945931f0-eca1-4fcb-8b2b-6cee7733f125",
   "metadata": {},
   "source": [
    "Assignment\n",
    "\n",
    "*** You will find this text in the 'TensorFlow_MNIST_Exercises_All.ipynb' file that is attached ***\n",
    "\n",
    "There are several main adjustments you may try.\n",
    "Please pay attention to the time it takes for each epoch to conclude.\n",
    "Using the code from the lecture as the basis, fiddle with the hyperparameters of the algorithm.\n",
    "\n",
    "1. The *width* (the hidden layer size) of the algorithm. Try a hidden layer size of 200. How does the validation accuracy of the model change? What about the time it took the algorithm to train? Can you find a hidden layer size that does better?\n",
    "2. The *depth* of the algorithm. Add another hidden layer to the algorithm. This is an extremely important exercise! How does the validation accuracy change? What about the time it took the algorithm to train? Hint: Be careful with the shapes of the weights and the biases.\n",
    "3. The *width and depth* of the algorithm. Add as many additional layers as you need to reach 5 hidden layers. Moreover, adjust the width of the algorithm as you find suitable. How does the validation accuracy change? What about the time it took the algorithm to train?\n",
    "4. Fiddle with the activation functions. Try applying sigmoid transformation to both layers. The sigmoid activation is given by the string 'sigmoid'.\n",
    "5. Fiddle with the activation functions. Try applying a ReLu to the first hidden layer and tanh to the second one. The tanh activation is given by the string 'tanh'.\n",
    "6. Adjust the batch size. Try a batch size of 10000. How does the required time change? What about the accuracy?\n",
    "7. Adjust the batch size. Try a batch size of 1. That's the SGD. How do the time and accuracy change? Is the result coherent with the theory?\n",
    "8. Adjust the learning rate. Try a value of 0.0001. Does it make a difference?\n",
    "9. Adjust the learning rate. Try a value of 0.02. Does it make a difference?\n",
    "10. Combine all the methods above and try to reach a validation accuracy of 98.5+ percent.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f16912-981e-4cbd-ab0a-322e0224d70a",
   "metadata": {},
   "source": [
    "#### How to tackle the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755adc7e-1940-4312-b0a3-f0908bbbdd06",
   "metadata": {},
   "source": [
    "\n",
    "Each image is 28 by 28\n",
    "\n",
    "0 - 255\n",
    "0 = black\n",
    "255\n",
    "white\n",
    "\n",
    "teo transform or flanten each to 784 inputs units in our input layer\n",
    "2 hidden layers and 10 classes will give you a a good model with good accuracy.\n",
    "\n",
    "soft mat acivation\n",
    "\n",
    "Action plan\n",
    "\n",
    "+ prepare data and preprocess it a bit. crate training ,validation and test datasets\n",
    "\n",
    "+ outline the model and choose the activation functions\n",
    "\n",
    "+ Set the appropriateadvanced optimizers and the loss function\n",
    "\n",
    "+ make it learn \n",
    "\n",
    "+ Test the  accuracy of the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4597be56-5af4-46cf-9d20-30e0cc82bf8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### How to tackle the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d51d8d3-8375-4da4-a77f-e47590466463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21d0c246-7a06-4862-a512-532d1fad08ed",
   "metadata": {},
   "source": [
    "#### MNIST – Importing libraries and data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d1bc9b-4685-4efc-9d76-4d2dffd6eed5",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "##### Import the relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b741c8-6c28-4333-96cf-9ad5771d2794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b36c0d02-f187-4a0b-922e-5717bfd3a3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21343f61-3182-471d-8f6b-28fb57d3ee4e",
   "metadata": {},
   "source": [
    "#### Preprocess the data – create a validation dataset and scale the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab7c273-920e-4385-a947-6376edefd655",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62652576-a307-4f39-b0b5-b5ddae44cbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "mnist_dataset = tfds.load(name='mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da34d3-644a-4317-a0d3-c80c72dc1635",
   "metadata": {},
   "source": [
    "There are two twist we can make, we can set the arguement from supervised to true and this will load the dataset  in a two trupple structure\n",
    "input and target . in addition, then we will include one final arguement with infor = true and store it in the variable mnist info , this provids a tuple containing info about version,features,\n",
    "#number of samples of the dataset\n",
    "tdfs.loads(name,as_supervised)loads a dataset from Tensorflow datasets-> as_supervised = True, loads the data in a 2-tuple structure['input, target]\n",
    "\n",
    "We can either load the dataset or continue our preprocessing in the same cell.\n",
    "\n",
    "Note , that the first time ,it will take a bit longer to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "470699e3-4fd3-4599-82e5-efbd6761de46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (2.10.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from datasets) (0.13.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from datasets) (2023.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d080ecd7-c4d9-4b41-97ae-11f2f90adb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b37bb76c-aa6d-4e6e-9d46-89690919262f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 86\u001b[0m\n\u001b[0;32m     83\u001b[0m validation_data \u001b[38;5;241m=\u001b[39m validation_data\u001b[38;5;241m.\u001b[39mbatch(num_validation_samples)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# To handle our test data we dont need to batch it either, we use same approach used in the validation data\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m#test_dataset = test_dataset.batch(num_test_samples)\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtest_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mbatch(num_test_samples)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Our validation data must have same shape and object property as the train and test data, the mnist data is iterable and in in 2- turple performace as we set the arguement as supervised to true, we must extractand convert the validation input and target well\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# lets store them in validatin input and target,we store then in iter, whcich is the pythonic syntax for making the element an iterator by defauilt, it makes the dataset iterable but not lowr than the datam then load the next batch, but since we have just one batch , it will load the input and the target\u001b[39;00m\n\u001b[0;32m     89\u001b[0m validation_inputs, validation_targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(validation_data))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#tfds.loads(name) - loads a data from tensorflow dataset\n",
    "# tfds.loads(name,with_info,as_supervized) :- \n",
    "# as_supervised=True will load the dataset in a 2-tuple structure (input, target) \n",
    "# alternatively, as_supervised=False, would return a dictionary\n",
    "# obviously we prefer to have our inputs and targets separated \n",
    "# (1) as supervised - True,loads the data in a 2-tuple structure(inputs,targets)\n",
    "# (2) with_info - True,provides a tuple containing information about version,features, #samples of the d\n",
    "\n",
    "#tfds.loads(name) - loads a data from tensorflow dataset\n",
    "# tfds.loads(name,with_info,as_supervized) :- \n",
    "# as_supervised=True will load the dataset in a 2-tuple structure (input, target) \n",
    "# alternatively, as_supervised=False, would return a dictionary\n",
    "# obviously we prefer to have our inputs and targets separated \n",
    "# (1) as supervised - True,loads the data in a 2-tuple structure(inputs,targets)\n",
    "# (2) with_info - True,provides a tuple containing information about version,features, #samples of the data\n",
    "#inputs between 0 and 1 helps our result to be more numerical stable\n",
    "mnist_dataset,mnist_info = tfds.load('mnist',with_info = True, as_supervised = True)\n",
    "\n",
    "mnist_train,mnist_test = mnist_dataset['train'],mnist_dataset['test']\n",
    "\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "# let's cast this number to an integer, as a float may cause an error along the way\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
    "\n",
    "num_test_samples = mnist_info.splits['train'].num_examples\n",
    "# once more, we'd prefer an integer (rather than the default float)\n",
    "num_test_samples = tf.cast(num_validation_samples, tf.int64)\n",
    "\n",
    "\n",
    "\n",
    "def scale(image, label):\n",
    "    # we make sure the value is a float\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # since the possible values for the inputs are 0 to 255 (256 different shades of grey)\n",
    "    # if we divide each element by 255, we would get the desired result -> all elements will be between 0 and 1 \n",
    "    image /= 255. \n",
    "    #the dot signifies we want the result to be a float\n",
    "    # return image and original label\n",
    "    return image, label\n",
    "\n",
    "#dataset.map(*function*) allows us to apply custom transformation to a given set,it can only take an input and a label and return an input and a label\n",
    "# you can scale your data in other ways if you see fit but it must take image and label and return same\n",
    "#hence, you are simply transforming he values\n",
    "scaled_train_and_validation_data = mnist_train.map(scale)\n",
    "\n",
    "test_data = mnist_test.map(scale)\n",
    "\n",
    "# Preprocess the data- shuffle and batch\n",
    "# shuffle means to keep thesame information in a different order, is possible the data is shuffled in ascending order resulting in x batches of 0 targets in one batch and the next batch having only 1 as a target.\n",
    "# Hence , we shuffle to get a random spread of dat \n",
    "# We shuffle in batches e.g 10,000 per batch, if we set at 20,000 it will take 20,000 at once but if bufer size = 1 no shuffle will happen, Note , if buffer size >= number_samples,shuffling will happen at once uniformly\n",
    "# If buffer size of btw 1 and total sample size we will be optimizing the computational power of our computer.\n",
    "# we use the already available shuffle method and specify buffer size\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "#After scaling and shuffling data we proceed to extract the train and validation dataset\n",
    "# we use 10% ot train data ,to validate, and we have already stored it in non validation samples\n",
    "# use the method take to extract the many samples\n",
    "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
    "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)\n",
    "# We will use mini -batch as the trade off between accuracy and speed is optimal\n",
    "# we must set a batch size. batch size = 1 = stochastic gradient descent(SGD)\n",
    "#batch size = # samples =  (single batch)CD ie gradient descent we have seen up till now\n",
    "# We want the number to be small to the dataset but reasonably high so as to allow us to preserve the underlying dependencies\n",
    "# lets set the batch size - 100, a hyper parameter to play with when you fine tune the algorithm\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "# baching helps to reduce noise in our dataset\n",
    "# There is  a method batch, dataset.batch(batch_size) a method that allows us to combine the elements of a dataset into batches\n",
    "# we can also take advantage of the occasion to batch the train data\n",
    "# this would be very helpful when we train, as we would be able to iterate over the different batches\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "# When we validate or test we forward propagate once but when batching we find the average loss and avg.accuracy, \n",
    "#During validation we want the exact values, so we take all the dats at once , when we forward propagate we dont use much computation power , so is not expensive to calculate, but the model expects our validation set in batch form too.\n",
    "\n",
    "#validation_data = validation_data.batch(num_validation_samples) \n",
    "\n",
    "#Single batch, having size equal to number of validation samples\n",
    "# We overrite validation data with the code below because of the reason above\n",
    "# WE will have a single batch with the batch size = to the total no of validation samples or num validation samples\n",
    "# it shows that our model will take the whole value at once when it utilizes it\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "# To handle our test data we dont need to batch it either, we use same approach used in the validation data\n",
    "#test_dataset = test_dataset.batch(num_test_samples)\n",
    "test_dataset = test_dataset.batch(num_test_samples)\n",
    "# Our validation data must have same shape and object property as the train and test data, the mnist data is iterable and in in 2- turple performace as we set the arguement as supervised to true, we must extractand convert the validation input and target well\n",
    "# lets store them in validatin input and target,we store then in iter, whcich is the pythonic syntax for making the element an iterator by defauilt, it makes the dataset iterable but not lowr than the datam then load the next batch, but since we have just one batch , it will load the input and the target\n",
    "validation_inputs, validation_targets = next(iter(validation_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532a835-4616-4e53-8cee-3c79d918e6e8",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5e6ef5-4d05-4520-b27e-2d7f7dc28eb3",
   "metadata": {},
   "source": [
    "####  Outline the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e895ee23-d6f8-43ec-9559-61da98c2c031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 784 inputs , and this will be our input layer\n",
    "# We have 10 output nodes one for each digit\n",
    "# We will work with 2 hidden layers consisting of 50 nodes each\n",
    "# Note, with and depth are hyperparameters\n",
    "# We dont know the optimal width and dept but we know what we choose is sub optimal\n",
    "# Assignment ,fine tune the hyperparameters of our model and obtain an improved result\n",
    "# We declare 3 variables for inputs, outputs and hidden layers\n",
    "# Underlying assumption is thal all hidden layers are same size, we can also create hidden layers\n",
    "# with diff. width and see if it works better for you.\n",
    "\n",
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layer_size = 50\n",
    "\n",
    "# We define the actual model and store it in a variable called model\n",
    "# The first layer is he input layer,our data is such that each observation is 28 X 28 X 1 or a tensor of rank 3\n",
    "# Since we dont know CNNs , we need to flaten the images into a vector\n",
    "# This  a common operation in deep learning, we us e a method called 'flatten' which is  apart of the layers model\n",
    "# it takes it arguement into the object we want to flatten\n",
    "#tf.keras.layers.Flatten(original shape) transforms(flattens) a tensor into a vector\n",
    "# indicate the input shape we want to flaten (28,28,1)\n",
    "# next step build neural network in a very similar way to our tensor flow intro model , using Dense\n",
    "# Dense is used to find the dot product of input and weight,adding the bias\n",
    "# tf.keras.layers.Dense(output size) takes the inputs, provided to the model and calculates the dot product of the \n",
    "# inputs and the weights and adds the bias. This is also where we can apply an activation function.\n",
    "# tf.dense takes the mathematical operation of the first hidden layer and we can include activation function as a second arguement\n",
    "# We will use Relu cos it works very well for this problem, In practice, each neural network have a differnt combination of activation function\n",
    "# Find out if it matters for Mnist ?\n",
    "# We can create the 2nd hidden layer in thesame way\n",
    "#outlining the model is easy and you can stack as many layers as possible using this structure\n",
    "# Finaly , we use the denss function to cretae the output layer but this time we specify the output layer size and not the hidden layer size\n",
    "# For the activation bcos we are creating a classifier, the activation function of the output layer must transform the values in the probabilities\n",
    "# Therefore, we must sort for the softmax\n",
    "# Our model has been built\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation ='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation ='relu'),\n",
    "                            tf.keras.layers.Dense(output_size, activation ='softmax')   \n",
    "                            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d0e5ab-b827-43b8-a125-e759c5940f6e",
   "metadata": {},
   "source": [
    "#### Select the loss and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c5ed06-8854-489d-92a4-cbb53dabcc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76d6ca13-d53c-454e-bf3e-2a3e79f9bf49",
   "metadata": {},
   "source": [
    "Iter() creates an object which can be iterated one element at a time (e.g, m a for loop or while loop)\n",
    "\n",
    "Next() loads the next element of an iterable object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8960a1-ca70-42e8-818c-4d6ce3418146",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Preprocess the data – create a validation dataset and scale the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f6bf4c-e1de-492a-8fce-9f38277a86ad",
   "metadata": {},
   "source": [
    "Is time to extract the trained data and test data but luckily we have \n",
    "built in refernces that will help us achieve it.\n",
    "\n",
    "But where is the validation dataset, by default tensorflow have training and test datset but no validation dataset, but it gives us the opportunity to practice splitting dataset on our own\n",
    "As we can see the trained datset is bigger than the test one so we take our validation data from the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667d0745-a336-417b-bcce-44f21accebbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b518bc-bfd0-4e02-ad93-f90b14d01fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Preprocess the data – shuffle and batch\n",
    "When batching we usually use the average loss and average accuracy.\n",
    "\n",
    "During validation and testing we want the exact values.\n",
    "\n",
    "iter is the pytonic syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb223c60-630e-48b1-88e6-0bd1f2523b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f318e-7ee7-4dba-9d96-fbae06f24f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09b640d-7e4b-4136-8125-8db158e06b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348ee906-a317-4a4a-8880-388686c79132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf017d8-602c-47ba-8181-85ef22642b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9105d87-4dad-4db3-8b80-e5e9e0a97783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c64fd3-17af-4c59-985e-1d0d686e3c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8758b67f-a461-4601-961f-82a4ccc4179e",
   "metadata": {},
   "source": [
    "#### Preprocess the data – shuffle and batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d17eb91-e21b-48d9-a02a-5fa39b9193ad",
   "metadata": {},
   "source": [
    "When batching we usually ind the average loss and average accuracy.\n",
    "\n",
    "During validation ant testing we want the exact values.\n",
    "\n",
    "iter is the pytonic syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996133db-3c32-4c3e-a3b4-31ddc02751fb",
   "metadata": {},
   "source": [
    "#### Outline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6db1629-1ba0-400b-902f-95399c6f6269",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431c3348-6ea7-4e6b-ba33-d7fdd3e4f139",
   "metadata": {},
   "source": [
    "Our input layer is 784\n",
    "Since we dont know the can we need to flaten the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f94d8121-392f-4d4f-9b37-babb112e1ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layer_size = 50\n",
    "# hidden_layer_size = 100\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation ='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation ='relu'),\n",
    "                            tf.keras.layers.Dense(output_size, activation ='softmax')   \n",
    "                            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99e983-3184-4d09-80e0-d0548ff0c437",
   "metadata": {},
   "source": [
    "#### Select the loss and the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f22fe8-2c12-4dc5-8ce8-cb3498731b32",
   "metadata": {},
   "source": [
    "We have taken care of the data and the model , the next step is to choose the optimizer and the loss through the compile method we call on the model object.\n",
    "\n",
    "model.compile(optimizer, loss) configures the model for training\n",
    "\n",
    "We start by specifying the optimizer and one of the best choices we have is the adaptive moment estimation or ADAMS .\n",
    "\n",
    "Tensorflow allows us to use a string to find the optimizer,\n",
    "To select the ADAMS optimizer we silply write adam\n",
    "Note , the stings are not case sensitive so you can capitalize the first letter or all letters if you wish.\n",
    "\n",
    "for the loss fuction, we will apply a loss used for classifiers.\n",
    "Cross entropy will be our first choice normally, but there are different types of cross entropy.\n",
    "\n",
    "In terms of float 2 ,thre a re three built-in variation of the cross entropy loss, \n",
    "The are \n",
    "+ Binary_crossentropy(...)\n",
    "+ Categorical _crossentropy(...)\n",
    "+ sparse_categorical_crossentropy(...)(...)\n",
    "\n",
    "+ Binary_crossentropy refers to the case where we have binary encoding.\n",
    "\n",
    "The two below are equilaent \n",
    "+ Categorical _crossentropy(...) =>  expects tht you have one-hot encoded the targets\n",
    "\n",
    "+ sparse_categorical_crossentropy(...)(...)   are equivalent => applies one -hot encoding\n",
    "\n",
    "but the difference is that  sparse_categorical_crossentropy applies one hot encoding to the data.\n",
    "\n",
    "Is our data one-hot encoded?\n",
    "\n",
    "That was not the pre-processing step we went through , however the output and the target layers should have matching forms.\n",
    "\n",
    "Our model and optimizer expects the output shape to match the target shape in a one -hot endoded format.\n",
    "\n",
    "This means we will opt for the sparse_categorical_crossentropy.\n",
    "\n",
    "Finally we can add a third arguement to compile.\n",
    "We can include matrix that we wish to calculate to have the training and testing processes.\n",
    "Typically, that is the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4821e980-b749-45e1-9f21-a74f3efb2cf7",
   "metadata": {},
   "source": [
    "##### Choose the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "192037b1-81b3-469d-aa57-6ee80db7a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ad25b1-9d88-4028-bf0b-1a3dfec92494",
   "metadata": {},
   "source": [
    "#### Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357cc68e-8fff-4de6-9387-ddc9da4f9fde",
   "metadata": {},
   "source": [
    "#### Training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd993d8-5540-4c33-9a44-67972f1784d4",
   "metadata": {},
   "source": [
    "This is the most important part of this ml process. This is where we fit the model we built and see if it actually worked perfectly.\n",
    "\n",
    "+ Create a number of epochs you want to train ,we wil set it to 5\n",
    "\n",
    "+ fit the modelusing the fit method , we then specify the dat, in this case , train data, then set the number of epochs as epochs=num_epochs.\n",
    "\n",
    "You need to parameterize it in a neat way so that you can clearly inspect the number of epochs.\n",
    "Whenever we have hyperparameters such as the buffer size,batch size, input size,output size and so on we prefer to create dedicated variables that can be easily spotted when we fine tune our deburg or code. This alone will be enough to train the model.\n",
    "\n",
    "However, we also need to validate.\n",
    "\n",
    "Since we have already prepared our validation dat, what we shoulld next is to include it as an argement with the same method equal to the validation input and validation target we created earlier.\n",
    "\n",
    "Finally , i will set verbose to 2 to make sure we will receive only the most important information for each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e7943b-e79a-45a9-b8a9-5fbc070cd5d8",
   "metadata": {},
   "source": [
    "What  happens inside an Epoch\n",
    "\n",
    "+ At the beginning of each epoch, the training loss will be set to zero.\n",
    "\n",
    "+ The algorithm will iterate over a preset number of batches, all from train_data.\n",
    "Essentially the whole training set will be utilized but in batches.\n",
    "\n",
    "+ Therefore the weights and biases will be updated as many times as there are batches\n",
    "\n",
    "+ At the end of each epoch we gat a value for the loss function,indicating how the training is going.\n",
    "\n",
    "+ Moreover, we will also see a training accuracy thanks to the last arguement we added.\n",
    "\n",
    "+ At the end of the epoch, the algorithm will forward propagate the whole validation set in a single batch through the optimized model and calculate the validation accuracy.\n",
    "\n",
    "When we reach the maximum number of epoch, the training will be over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "841d6e22-1f6a-4260-aba7-2b610bc2f15f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validation_inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m NUM_EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m----> 3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_data, epochs \u001b[38;5;241m=\u001b[39m NUM_EPOCHS, validation_data\u001b[38;5;241m=\u001b[39m(\u001b[43mvalidation_inputs\u001b[49m, validation_targets), verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'validation_inputs' is not defined"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "\n",
    "model.fit(train_data, epochs = NUM_EPOCHS, validation_data=(validation_inputs, validation_targets), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b921f157-b3b9-417d-80b0-5e433b83fb75",
   "metadata": {},
   "source": [
    "Explanation of the output\n",
    "\n",
    "We have several lines of output\n",
    "+ information about the number of epoch 1/5\n",
    "\n",
    "+ we have the number of batches which is 540/540 because if we have a progress bar that will fill out gradually\n",
    "\n",
    "+ The third information is the time it took the epoch to conclude which is around 5 to 6seconds per epoch.\n",
    "\n",
    "+ Next, we have the training loss, is good to consider the training loss acrosss epochs ann not to investigate it seperately. We observe that it was decreasing but it didnt change too much.\n",
    "\n",
    "Even after the first epoch, we still have 540 different weights and bias updates one for each batch.\n",
    "\n",
    "What follows is the accuracy, the accuracy shows in what % of the cases our output is equal to th target.\n",
    "Logically , it follows the trend of the loss afterall they both represent how well the output match the targets.\n",
    "\n",
    "Finally, we have the loss and the accuracy for the validation set. They are our check.\n",
    "We usually keep an eye on the validation loss(or set early stopping) to determine whether the model is overfitting.\n",
    "\n",
    "The validation accuracy on the other hand is the true accuracy of the model for the epoch.\n",
    "\n",
    "This is because the training accuracy is the average acuracy accoss batches while the validation accuracy is the whole validation set.\n",
    "\n",
    "To access the overall accuracy of our model we will look at the validation accuracy of the last epoch. It is at 97%.\n",
    "\n",
    "This is a remarkable result already.\n",
    "\n",
    "But can we do better? \n",
    "Let's try fitting a bit with the model.\n",
    "We can change many of the hyper parametersLets start from the hidden later side.\n",
    "\n",
    "Instead of 50 nodes lets use 100\n",
    "\n",
    "With this we drastically increased the accuracy of our model to 98% \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5701dea6-f5e6-465c-8806-eafa42d2e4b6",
   "metadata": {},
   "source": [
    "#### Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e931c6-b187-41fc-9848-afe187d0e218",
   "metadata": {},
   "source": [
    "With this we drastically increased the accuracy of our model to 98% \n",
    "Note , this is the validation accuracy and we still need the test the model on the test accuracy because the final accuracy of the nodel comes from simply forward propagating the test dataset and not the validation .\n",
    "The reason is that we may have overfit.\n",
    "The accuracy we obtain at this stage is the accuracy of the algorithm.\n",
    "\n",
    "We may think we have already dealt with over fitting , but is important to note the diffence between validation and test data set.\n",
    "\n",
    "+ We rain on the training data\n",
    "\n",
    "+ We validate on the validation data\n",
    "This is how we make sure our parameters , the weight and biases - dont overfit.\n",
    "\n",
    "Once we train our first model, we fifddle with the hyperparameters.\n",
    "\n",
    "Normally , we will not change only the weight of the hidden layers ,we can also adjust the depth, the learning rate , the batch size, the activation function for each layer and so on.\n",
    "\n",
    "Each time we make a change , we run the model once more and check if the validaton accuracy improved.\n",
    "\n",
    "After 10 to 20 different combinations we may reach a model with outstanding validation accuracy. In essence, we are trying to find the best hyperparameters but what we found are not the best hyper parameters in general .\n",
    "These are the hyperparameters that fit our validation dataset best. Basically, by fine tunning them, we are overfitting the validation dataset.\n",
    "\n",
    "During the training stage , we can overfit the parameters or the weights and biases.\n",
    "\n",
    "The validation dataset is our reality check that prevents us from overfitting the parameters.\n",
    "\n",
    "After fiddling with the hyperparameters, we can overfit the validation dataset as we are considering the validation accuracy as a bench mark for how good the model is.\n",
    "\n",
    "The test dataset then is our reality check that prevents us from from overfitting the hyperparameters( width, depth, batch size, epochs etc)\n",
    "\n",
    "It is a dataset the model have never seen before.\n",
    "\n",
    "We can access the test accuracy using the method evaluate() \n",
    "\n",
    "model.evaluate () returs the loss value and metrics values for the model in 'test mode'\n",
    "\n",
    "\n",
    "We will be propagating the test data to the next, with our current model structure ,there will be two output , the loss function and te accuracy. the same ones we had in the training stage.\n",
    "\n",
    "To make it clear , let's store them in test loss and test accuracy.\n",
    "\n",
    "If we run the code nothing comes out as we still have not displayed them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1ef406d-d7d5-4821-b4f8-8b6c7ea07872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_1_input'), name='flatten_1_input', description=\"created by layer 'flatten_1_input'\"), but it was called on an input with incompatible shape (28, 28, 1, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_1_input'), name='flatten_1_input', description=\"created by layer 'flatten_1_input'\"), but it was called on an input with incompatible shape (28, 28, 1, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1665, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_1\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_3\" is incompatible with the layer: expected axis -1 of input shape to have value 784, but received input with shape (28, 28)\n    \n    Call arguments received by layer \"sequential_1\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(28, 28, 1), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileiqrx6wll.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1665, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_1\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_3\" is incompatible with the layer: expected axis -1 of input shape to have value 784, but received input with shape (28, 28)\n    \n    Call arguments received by layer \"sequential_1\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(28, 28, 1), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "# if we run the code nothing will come out bcos we are yet to display them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e758cb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_1_input'), name='flatten_1_input', description=\"created by layer 'flatten_1_input'\"), but it was called on an input with incompatible shape (28, 28, 1, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_1_input'), name='flatten_1_input', description=\"created by layer 'flatten_1_input'\"), but it was called on an input with incompatible shape (28, 28, 1, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1665, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_1\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_3\" is incompatible with the layer: expected axis -1 of input shape to have value 784, but received input with shape (28, 28)\n    \n    Call arguments received by layer \"sequential_1\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(28, 28, 1), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileiqrx6wll.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1665, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_1\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_3\" is incompatible with the layer: expected axis -1 of input shape to have value 784, but received input with shape (28, 28)\n    \n    Call arguments received by layer \"sequential_1\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(28, 28, 1), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "# if we run the code nothing will come out bcos we are yet to display them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89edad81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_1_input'), name='flatten_1_input', description=\"created by layer 'flatten_1_input'\"), but it was called on an input with incompatible shape (28, 28, 1, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_1_input'), name='flatten_1_input', description=\"created by layer 'flatten_1_input'\"), but it was called on an input with incompatible shape (28, 28, 1, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1665, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_1\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_3\" is incompatible with the layer: expected axis -1 of input shape to have value 784, but received input with shape (28, 28)\n    \n    Call arguments received by layer \"sequential_1\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(28, 28, 1), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileiqrx6wll.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\training.py\", line 1665, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\user\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_1\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_3\" is incompatible with the layer: expected axis -1 of input shape to have value 784, but received input with shape (28, 28)\n    \n    Call arguments received by layer \"sequential_1\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(28, 28, 1), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "# if we run the code nothing will come out bcos we are yet to display them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "927b30eb-deec-4067-aa1e-d7fc61ddd77b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Lets print the result using some nice formating\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_loss: \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m0:..2f},Test_accuracy: \u001b[39m\u001b[38;5;132;01m{1:.2f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mtest_loss\u001b[49m, test_accuracy\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100.\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_loss' is not defined"
     ]
    }
   ],
   "source": [
    "# Lets print the result using some nice formating\n",
    "print('test_loss: {0:..2f},Test_accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bf6e53-c37a-4520-81b4-560de54228f0",
   "metadata": {},
   "source": [
    "\n",
    "Our model have a final test accuracy around 97.5%.\n",
    "\n",
    "This is also the final stage of the machine learning process.\n",
    "\n",
    "After we test the model conceptually, we are no longer allowed to change it.\n",
    "\n",
    "If you start changing the datset after this point, the test data will no longer be  adatset the model have never seen .\n",
    "\n",
    "You have feed back of 97.5% accuracy with this particular configuration.\n",
    "\n",
    "The main point of the test dataset is to insunerate model deployment.\n",
    "\n",
    "If we get 50% or 60% model accuracy, we will know for sure that our model have overfit and we will fail miserably in real life.\n",
    "However, getting the value very close to the validation accuracy shows we have not overfit.\n",
    "\n",
    "Finally, the test accuracy is the accuracy we expect to observe if we deploy the model in the real world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795264cc-0240-4fa1-9e3d-6876b0d58cf3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Week 14: Day 1 – Business Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80e946b-f062-464e-acbb-531c3b39c517",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Exploring the dataset and identifying predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443161ac-959c-40e3-9be9-a6798bddda4d",
   "metadata": {},
   "source": [
    "\n",
    "Thi is the application of everything learnt\n",
    "so far.\n",
    "\n",
    "+ Problem Statement\n",
    "\n",
    "You are given data from an audio book app. Logically,it relates to the audio version of books only. each customer on the data base has made a purchase atleast once.\n",
    "That is the condition to be included. We want to create a machine learning algorithm based on our data that can predict if a customer will buy again from the audio book company. The main idea is that the company should extend its advertising budget targeting individuals who are unlikely to come back.\n",
    "\n",
    "If we focus our efforts on customers likely to convert again, we can obtain an improved sales and profitability figures.\n",
    "\n",
    "So our model will take several matics and will try to predict human behaviour. a side effect of the model is that the model which of the most important metrics for a customer to come back (conversion). \n",
    "Having the data and the technology to identify prospective customers creates alot of values and growth opportunities.It is one of the better application of data science.\n",
    "\n",
    "Here is our data. the csv file is included in the lecture resources. when you download it the column headers will not be included as we want no test of the data when trianing the model.\n",
    "Each row represents a person. lwt's go through the model and see why each one of them could be abused. \n",
    "First, we have customer id, id is like a name. Whether the id is 1, 2, 3 , or john1 ,john2,john3, it makes no difference. As no information is contained in the id we will skip it in our algorithm.\n",
    "\n",
    "Next,we have  book_length, the overall book_length is the sum of the length of all purchases, we also have the average book length which is basically the sum divided by the number of purchases. So if someone have bougth single audio book ,the average length and the overall length for this person will be equal.\n",
    "\n",
    "There is no need to include the number of purchases as it is contained in the two variables we just described.\n",
    "\n",
    "We then have the overall price paid and he average price paid. These variables were constructed in the same way as those of book length.  The price is in dollars , althogth it makes no difference to the algorithm.\n",
    "\n",
    "The price variable is almost always a good predictor of the earlier.\n",
    "\n",
    "The next variable is review. Review is a boolean. It hows if  acustomer left a review. This is a matrix that shows enagement on the platform.\n",
    "Our assumption is that people who leave reviews are more likely to come back again.\n",
    "\n",
    "We have  reviews_out_of_10, This is a different variable.It measures the reviews of a customer on a scale of 1 to 10( Reviews 10/10). Pay attention here as we will show you the first pre-processing trick.\n",
    "\n",
    "Logically, we will only have a value for people that left a review.By examing the table , we quickly see that that most people dont leave review as in most market places. This is bad for our dataset and bad in general. We have decided to leave the reviews posted in the platform and substitute all missing values with the average review. the average is 8.91 .\n",
    "\n",
    "for our machine learning algorithm, 8.91 = status quo, a review bigger than 8.91 will indicate above average feelings while a review lesser than 8.91 will indicate below average feelings.\n",
    "We use the word feelings because review is another variable that is an average. A customr may have bougth 2 or 3 books from the platform, the average reviews she left indicates her feelings towards the content on the median more better. The median as a whole.\n",
    "An average of 2 out of 10 indicates a person did not have a pleasant experiance on the audio books especially when the average is 8.91. It is logical, that such a customer is not likely to buy again.\n",
    "\n",
    "Next we have toal minutes listenened. This is a measure of engagement.\n",
    "\n",
    "Next, we have completion, this is the total minutes listened divided by the total length of book a person have purchased.\n",
    "Assuming people dont eally listen to books . both variables are self explanatory.\n",
    "\n",
    "The next variable is support requests, it is numerical and shows the total number of support requests a person have opened. Support is anything from forgoten password to insistance on using the platform. Once more, this is a measure of enagement.\n",
    "\n",
    "It may turn out that the more support a person is needed the more he/she gets fed up with the platform and abandons it or he/she likes it so much that by using it he stumbles on different issues unlike someone who never opens the app.\n",
    "\n",
    "Finally,we have a variable measuring the difference between the last time a person interacted with the platform and th first purcahse day. This is anothe measure of engagement. The bigger the difference the better. If a person enagaes regularly with the platform. His difference will be bigger, thus the customer is likely to convert again. If the value of this variable is zero,It shows customer has never accessed what he has bought or perhaps , he did it on the first day only and it is unlikely here she will convert again.\n",
    "These are our inputs.\n",
    "\n",
    "It is always necessary to ask how the data was gathered. This piece of information is valuable for any analysis.\n",
    "\n",
    "The day it was gathered from the audio book app as we said. It represents two years work of engagement.\n",
    "\n",
    "Now we are doing supervised learning. So we need Targets. The targets will be a boolean.\n",
    "\n",
    "1 if a person converted and 0 if he /she didnt.\n",
    "What does it mean to convert?\n",
    "We have taken an extra 6 months of data after 2 years to check if a user converted. So we took 2 years and 6 months. We have 2 years and 6 months of data .\n",
    "\n",
    "The first 2 years are contained in the datset (inputs) we already explained.\n",
    "\n",
    "The next 6 monts will show us if a person converted , in other words if he or she bought another book and if it happened , we can count that as conversion, the target will be 1 , otherwise 0.\n",
    "\n",
    "This is how we created the Targets column. 6 months sounds reasonable for us. If one buys no new books , it means they might have gone to outr competitor or dont ike the audio book way of digesting information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cc5220-a03b-4fe4-a722-ae1512d10414",
   "metadata": {},
   "source": [
    "+ Task \" Create a Machine leaning algorithm that can predict if a customer will buy again. This is a cassification problem wih 2 classess. \n",
    " Wont buy\n",
    " Will buy\n",
    " \n",
    " represented by 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8ffa98-caa1-40af-9953-6c22f935e337",
   "metadata": {},
   "outputs": [],
   "source": [
    "Week 13 day 3 video not playing  !!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f827f83-0c03-4ad6-bd5e-b6fdf00309cd",
   "metadata": {},
   "source": [
    "#### Outlining the business case solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b197459-f62b-4eb0-b306-2f581325be7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Business case Action Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb876e4-962d-405c-9e08-c4fe780fea6a",
   "metadata": {},
   "source": [
    "Since we are working with real life data we must pre-process it. \n",
    "\n",
    "+ 1. Pre- Processing is important for machine learning. \n",
    "In a data science team, there may be a person whose job is to prepare dataset for analysis.\n",
    "\n",
    "+ Common techniques associated with pre-processing\n",
    "\n",
    "To create a ml algorithm from scatch we need 3 important steps\n",
    "> 1.1 balance the dataset\n",
    "> 1.2 Divide the dataset into 3 parts: Training, validation and test. The essence is to prevent overfitting\n",
    "\n",
    "> 1.3 Save the data in a tensor friendly format using the .npz\n",
    "\n",
    "+ 2. Create the machine learning algorithm\n",
    "\n",
    "The code is 90% thesame as the one in the mnist example. Here is the true power of Tensorflow. We will use the same structure to create a different model which will be equally powerful. By the end you can take any dataset to repeat this operation using the code to create deep neural network \n",
    "for countless problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567a8fa1-b20c-4740-aeac-f0bf59c9e869",
   "metadata": {},
   "source": [
    "#### Balancing a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48df2ded-b1b7-411b-a5f0-3e2c07db8f60",
   "metadata": {},
   "source": [
    "Before pre-procesing , it is important to balance your dataset. Let's think about a photo classification problem with two classes.\n",
    "Cats and Dogs\n",
    "What accuracy do you expect from a good model?\n",
    "\n",
    "If we correctly classify 70% of the photos, it is not too bad. 80% accuracy is good and 90% is very good for beginners.\n",
    "\n",
    "We are not talking about google or facebook which may have 99.99% accuracy.\n",
    "90% accuracy for most problems is an impressive accomplishment.\n",
    "\n",
    "Imagine a model that takes animal photos and outputs only cats . No matter what you feed to the algorithm, it will always output cat as the answer, this is a bad model.\n",
    "\n",
    "Is this machine learning you may ask?\n",
    "It is definitely not the result we want from an algorithm, but is common result.\n",
    "\n",
    "Imagine that in our algorithm,90% of the photos are cats and 10% dogs. The model will classify all photos as cats since 90% of the dtaset are cats.\n",
    "\n",
    "What is the accuracy of the algorithm?\n",
    "It is 90%\n",
    "Why do this problem arise?\n",
    "\n",
    "Since , the machine learning algorithm try to optimmize the loss,it quickly realises that if so  \n",
    "many targets are cats, the outputs shold most likely be cat to achieve a great result . Hence,it comes up with the most prediction at all times. Cats!\n",
    "\n",
    "If the distribution photos are 90% cats and 10% dogs,a model with an 80% accuracy is a bad model.\n",
    "\n",
    "This is because the Dumb model with outputs only cats will do better than it (90%)\n",
    "\n",
    "Therfore ,only a result above 90% will be the most favourable one.\n",
    "\n",
    "We referred the initial probablity of picking a photo of some class as a prior.\n",
    "\n",
    "The priors are 0.9 for cats and 0.1 for dogs.\n",
    "\n",
    "The priors are balanced when 50% of the photos are cats and 50% dogs or 0.5 and 0.5.\n",
    "\n",
    "Examples of unbalanced priors are \n",
    "0.1 and 0.9\n",
    "0.7 and 0.3\n",
    "0.6 and 0.4 and so on and each pair is prone to the issue discussed above.\n",
    "\n",
    "A ml algorithm may quickly learn that one class is much more common than the other and decide always to output the value with the gigher prior.\n",
    "\n",
    "If we have 3 classes\n",
    ", \n",
    "Cats   33%\n",
    "\n",
    "Dog    33%\n",
    "\n",
    "Horses 33%.\n",
    "\n",
    "Balancing the dataset would imply picking the dataset. Each class amount to approximately 1/3 of the dataset. If we have 4 clasess, 25% each.\n",
    "\n",
    "In our business case, by exploring the target, we quickly realised that most customers did not convert in the given time spent. We must surely balance the dataset to proceed. This is done by counting the total number of target ones and matching the same number of zeros to them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5031caa2-10f4-48cc-8a04-42e21bcc2616",
   "metadata": {},
   "source": [
    "#### Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9043b3da-a1a3-4689-b254-0cc6238083c7",
   "metadata": {},
   "source": [
    "#### Practical example. Audiobooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a685faa3-0e5e-452e-a736-88bedb896f91",
   "metadata": {
    "tags": []
   },
   "source": [
    "+ Preprocessing the data, Balance the dataset,Create 3 datasets: training,validation and test. Save the newly created sets in a tensor friendly format(e.g.* .npz)\n",
    "\n",
    "Since we are with the real data we will need to preprocess it a bit . This is the relevant code which is not that hard but refers to data engineering more than machine learning.\n",
    "\n",
    "If you want to know how to do that, go through the code and the comments. In any case, this should do the trick for all datasets organized in the way. Many inputs and then 1 cell containing the targets(all supervized learning datasets)\n",
    "\n",
    "Note that we have removed the header row, which contains the names of the categories. We simply want the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c5d25a2-2347-45df-8888-0a58f13cabf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\user\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (0.0.post1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92318192-5043-4d6c-844d-d2ab82e38930",
   "metadata": {},
   "source": [
    "##### Extract the data from the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e776d8cf-4f1c-4cc0-ab9c-6cb941838224",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import the necessary libraries\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# we will use the sklearn capabilities for standardizing the e inputs\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# we reach 10% less accuracy of the model.0.5% improvement can give\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# a great success to our model\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocessing\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "\n",
    "# we will use the sklearn capabilities for standardizing the e inputs\n",
    "# it is one line of code which drastically inproves the accuracy of the\n",
    "# model. Almost always we standardize all input as the quality of the \n",
    "# algorithm improves significantly , without standardizing the input \n",
    "# we reach 10% less accuracy of the model.0.5% improvement can give\n",
    "# a great success to our model\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93b4298-da89-4bcc-a4c6-e67dc759e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_csv_data = np.loadtxt (\"C:\\\\Users\\\\user\\\\tensorflow_datasets\\\\downloads\\\\Audiobooks_data.csv\")\n",
    "\n",
    "unscaled_inputs_all = raw_csv_data[:,1:-1]\n",
    "targets_all = raw_csv_data[:,-1]\n",
    "#targets is the last column of the csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee45279-e807-4c02-a091-7ead6b9ab46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Balancing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3295ac17-9d39-4c80-8226-bb814090355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will count the number of targets that are 1s\n",
    "# We will keep as many 0s as there 1s, though the n0 of 0s are more\n",
    "# if we sum all targets that can take only 0 and 1 as values\n",
    "# We will get the no of targets that are 1s\n",
    "\n",
    "num_one_targets = int(np.sum(targets_all))\n",
    "# We will declare it as an integer as targets all may be a boolean\n",
    "# depending on the programming language.\n",
    "# Then keep as many 0s as 1s.\n",
    "#lets set a counter for the 0 target = 0\n",
    "zero_targets_counter = 0\n",
    "# we need a variable that records the indices to be removed\n",
    "# for now it will be empty , we want it to be a list or turple\n",
    "# so we put empty bracket\n",
    "indices_to_remove = []\n",
    "# lets iterate over the dataset and balance it\n",
    "# Targets all contains all targets,its hape on the zero axis is the length of the vector\n",
    "# It will show us the no of all targets\n",
    "# In the loop we want to increase the counter by 1 if the target at position i is 0\n",
    "# In the same if we put another if which will add an index to the variable indices to remove\n",
    "# if the 0 conter is over the number of 1s\n",
    "# We will use the append method which simply adds the element to a list\n",
    "# After the counter of 0s matches the number of 1s, we note all indices to be removed\n",
    "# After we run the code ,the variable indices to remove will contain the indices of all targets we will not need\n",
    "# Deleting these entries will balance the dataset\n",
    "\n",
    "\n",
    "for i range(targets_all.shape[0]):\n",
    "    if targets_all[i] ==0\n",
    "       zero_targets_counter > num_one_targets:\n",
    "        indices_to_remove.append(i)\n",
    "        \n",
    "# lets create a new variable unscaled inputs= np.delete nscaled inputs all\n",
    "# np.delete(array,obj to delete,axis) is a method that delete an object on axis 0 of the vector\n",
    "# targets-equal-priors = np.delete (targets all indices to remove on axis 0\n",
    "# we have a balanced dataset\n",
    "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis =  0)\n",
    "targets_equal-priors = np.delete (targets_all, indices_to_remove, axis=0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53167468-7eea-43a1-aad3-130765f78df1",
   "metadata": {},
   "source": [
    "##### Standardize the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0460d4-450c-41c5-a86f-efd55b103445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To standardize means ti scale the inputs so as to improve the algorithm\n",
    "# A single line of code will do the work\n",
    "# The scale method standardize the dataset along each variable\n",
    "# Thats the preprocessing library we imported from sklearn\n",
    "# preprocessing.scale(X) is a method that standardizes an array along each variable\n",
    "# Basically all inputs will be standardized\n",
    "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ccf5b9-f1cd-468c-aa88-026015695986",
   "metadata": {},
   "source": [
    "##### Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc3149c-1666-4e1b-bc33-2725eb3f86c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will suffle the inputs and targets\n",
    "# we keep thesame information in a different order.\n",
    "# Is possible the original datset was collected in the order of \n",
    "# date,since we will be batching we must shuffle the data.\n",
    "# It should be as randomly spread as possible so batching works fine\n",
    "# Image the data is ordered so that each batch reps a diff. day of purchase\n",
    "# inside the batch, the data is homogenuos, while between batches ,it is very heterogenuos\n",
    "# due to promotions , day of the week effect and so on.this will confuse the sochastic\n",
    "# gradient descent when we average the loss across batches,overall we want them shuffled\n",
    "# First, we take the indices of the axis 0 of the scaled input shape and place them in a variable\n",
    "# np.arrange([start],stop) is a method that returns a evenly spaced values within a given interval.\n",
    "# Then we use the np.shuffle method to shuffle them\n",
    "#np.random.shuffle(X) is a method that shuffles the numbers in a given sequence.\n",
    "# Finally, we create shuffle inputs and shuffle targets variable equal to the scaled inputs and the targets\n",
    "# Where the indices are the shuffled indices\n",
    "\n",
    "shuffled_indices = np.arrange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = targets_equal_priors[shffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4e96e5-4f7d-422c-a266-bf5fa51d6558",
   "metadata": {},
   "source": [
    "##### Split the dataset into train, validation, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c48f368-bbe7-4d86-910e-c75cb2911066",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_count = shuffled_inputs.shape[0]\n",
    "\n",
    "# Determine the size of the 3 dataset using the 80 /10/10 split\n",
    "# We want to make sure the no is integer.\n",
    "train_samples_count = int(0.8*samples_count)\n",
    "validation_samples_count = int(0.1*samples_count)\n",
    "test_samples_count = samples_count - train_samples_count - validation_samples_count\n",
    "\n",
    "# let's extract them from the big dataset, the train input is given by\n",
    "# the first train count of the preprocessed input\n",
    "# The train target are the first train sample count of the targets\n",
    "# Analogically,the validation inputs are the inputs in the interval form\n",
    "# train sample count totrain sample count + validation sample count\n",
    "# The validation targets in the same interval\n",
    "# finally the test is everything that is left\n",
    "train_inputs = shuffled_inputs[:train_samples_count]\n",
    "train_targets = shuffled_targets[:train_samples_count]\n",
    "\n",
    "validation_inputs = shuffled_inputs[train_samples_count:train_samples_count+validation_samples_count]\n",
    "validation_targets = shuffled_targets[train_samples_count:train_samples_count+validation_samples_count]n_samples_count:]\n",
    "\n",
    "test_inputs = shuffled_inputs[train_samples_count+validation_samples_count:] \n",
    "test_targets = shuffled_targets[train_samples_count+validation_samples_count:]\n",
    "\n",
    "# it is useful to check if we have balanced the dataset\n",
    "# we may have balanced the whole dataset but not the training ,validation and test dataset\n",
    "# lets print the no of 1s for each dataset\n",
    "# The total number of samples and the proportion of 1s as a part od the total\n",
    "# They should all be around 50%\n",
    "\n",
    "print(np.sum(train_targets), train_samples_count, np.sum(train_targets) / train_sample_count)\n",
    "print(np.sum(validation_targets), validation_samples_count, np.sum(validation_targets) / validation_sample_count)\n",
    "print(np.sum(test_targets), test_samples_count, np.sum(test_targets) / test_sample_count)\n",
    "\n",
    "# from the output the training set is considerably larger than the validation and test and this is how we want it to be.\n",
    "# The total number of observation is around 45 hundred(3579 + 447 + 448 =4474 ) which is relatively good amount of data\n",
    "# data. Although we started with around 15000 samples in the csv\n",
    "# All three sets are balanced.The proportions or priors are ok as they are almost 50%. note , that 52 or 55% are still ok.\n",
    "# Howevr, we want to be as close to 50% as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1aca70-2f11-4655-8278-960ca0f054a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Save the three datasets in *.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9761561-6c9a-4e0f-b0bf-6227aca07f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will save the data so that we can use them later\n",
    "np.savez('Audiobooks_data_train', inputs=train_inputs, targets=train_targets)\n",
    "np.savez('Audiobooks_data_validation', inputs=validation_inputs, targets= validation _targets )\n",
    "np.savez('Audiobooks_data_test',inputs=test_inputs, targets=test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47209772-2630-46d0-befb-9eb49194e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each  time we run the codes , we will get different proportions as we\n",
    "# We suffle the indices randomly.So training, validation and test dataset \n",
    "# will contain different samples.\n",
    "# You can use this same code to preprocess any dataset where you have two classes\n",
    "# The code will skip the first column of the dta, as here we skip the id and the\n",
    "# last column wili be treated as target. \n",
    "# If you want to customize the code for problems with more classes, you must \n",
    "# balance the dataset classes instead of 2, everything else should be the same.\n",
    "# The preprocessing is over, henceforth,we will only work with the .npz files\n",
    "# We will save this in jupiter notebook and continue with machine learning in a seperate one.\n",
    "# Make sure you hhave the raw csv when you run the code on your computer, in this way you will \n",
    "#create the npz files which we wil use in our machine learning.\n",
    "# There are some additional adjustments you can make on the code to improve the preprocessing\n",
    "# Check out the exercises below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba65f42-c58e-45d1-9a1e-ba296e63896b",
   "metadata": {},
   "source": [
    "#### Preprocessing Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1059c33-54d4-4cb6-81a6-246884b52608",
   "metadata": {},
   "source": [
    "Assignment\n",
    "\n",
    "It makes sense to shuffle the indices prior to balancing the dataset. \n",
    "Using the code from the lesson, shuffle the indices and then balance the dataset.\n",
    "\n",
    "Note: This is more of a programming exercise rather than a machine learning one. Being able to complete it successfully will ensure you understand the preprocessing. \n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8f510b-7f06-475b-ba46-662572cc28e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load the preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435d07f5-f4b4-45bb-bf84-ff14c597a0fd",
   "metadata": {},
   "source": [
    "Here,we have an input layer consisiting of 10 units, those are the inputs from our csv. Thre are only two output nodes as there are only 2 possibilities, 0 and 1.We will build the net with two hidden layers. The number of each hidden layers will be 50 but as we know very well, this is extremely easy to change, therefor for product type of aan algorithm, 50 is a good value.\n",
    "\n",
    "50 hidden units in the hidden layers provide enough complex\n",
    "ity, so we expect the algorithm to be much more sophisticated than a linear or logistic regression. \n",
    "At the same time, we dont want to put too many units initially, as we want to complete the learning as fast as possible and see if anything is been learned at all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26113c4d-3ff4-4bcc-8677-81c9cd064900",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### create the machine learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aef5a82-30f7-4412-ae32-5c4d092c2bb5",
   "metadata": {},
   "source": [
    "##### Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c5d6120-a453-47a7-bc10-7f9708e1972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9421f630-d38b-4863-aa5d-d538876a9f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next logical step is to load the data\n",
    "# Lets declare a temporary dataset called npz that will store each of the 3 dataset as we load \n",
    "# them. To load the trained data, we use np.load and the name of the trained dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6729e606-7822-40e1-889c-07975eb6ebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18adc1d-4752-4cc7-954a-7d8a405bfc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "npz = np.load(\"C:\\\\Users\\\\user\\\\tensorflow_datasets\\\\downloads\\\\Audiobooks_data.npz\")\n",
    "            \n",
    "# We expect all nputs to be float\n",
    "train_inputs = npz['inputs'].astype(np.float)\n",
    "# extract the trained target from npz using the keyword targets\n",
    "# Our targets are 0s and 1s but we are not completely dertain it \n",
    "# will be extracted as integers or booleans, is good practice to \n",
    "# use the same method as type and make sure that the data type will be np.int\n",
    "# Even if we know inwhat format we saved them\n",
    "train_targets = npz['targets'].astype(np.int)\n",
    "\n",
    "# For validation and test we start loading the next npz, audiobook data in \n",
    "# a temporary variable npz, then we proceed in a similar way to extract the\n",
    "# validation input and targets making sure of there data type.\n",
    "npz = np.load(\"C:\\\\Users\\\\user\\\\tensorflow_datasets\\\\downloads\\\\Audiobooks_data.npz\")\n",
    "validation_inputs, validation_targets =  npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
    "\n",
    "\n",
    "npz = np.load(\"C:\\\\Users\\\\user\\\\tensorflow_datasets\\\\downloads\\\\Audiobooks_data.npz\")\n",
    "# npz = np.load('Audiobooks_data_test.npz')\n",
    "test_inputs, test_targets = npz['inputs'].astype(np.float), npz['targats'].astype(np.int)\n",
    "# Note that our train,validation and test data is simply an array formm instead \n",
    "# of the interators we used for the mnist. In this business example, we will \n",
    "# train our model with every day arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51810fbf-404b-4ca5-a34b-b7ab3e8e7215",
   "metadata": {},
   "source": [
    "#### Learning and interpreting the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08739796-ebf1-4dc1-8776-1f5cc1e8b8d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1bc8ce-dbe1-4598-94ee-18db65666b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### OUtline, optimizers, loss, early stopping and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2da97ac-c0cf-4bac-a137-0929ada038dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We claim that tensorflow codes is extremely re-useable, we will now prove \n",
    "# it as infact true . We will copy the mnist model outline , then adjust it,\n",
    "# First the imput size of our model must be 10 as there are 10 predictors \n",
    "# The output size must be 2 as we have 1s and 0s\n",
    "# We can leave the hidden layers the way it is cos we are not sure of the optimal \n",
    "# value is . \n",
    "# In the mnist code we used the method flatten to flatten the image to a vector\n",
    "# Here we have already preprocessed our data, so we can delete the flatten line the \n",
    "# rest remains unchanged. We have 2 hidden layers each activated by a redo activation \n",
    "# function. We know that the model is a classifier, therefore our output layer should be activated with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c0ee57-d073-462d-89d3-e9a9a1cfee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "output_size = 2\n",
    "hidden_layer_size = 50\n",
    "# hidden_layer_size = 100\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                            #tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation ='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation ='relu'),\n",
    "                            tf.keras.layers.Dense(output_size, activation ='softmax')   \n",
    "                            ])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "max_epochs = 100\n",
    "\n",
    "model.fit(train_inputs,\n",
    "          train_targets,\n",
    "          batch_size = batch_size,\n",
    "          epochs = max_epochs,\n",
    "          validation_data=(validation_inputs, validation_targets),\n",
    "          verbose=2)\n",
    "# Next we choose the optimizer and the loss function, we copy and paste from the mnist e.g\n",
    "# The choosen optimizer is adam , while the loss is cross categorical crossentropy, we use use\n",
    "# use thisloss so as to ensure that our integer targets are one hot encoded appriopriately when \n",
    "# calculating the loss. We are happy at obtaining the accuacy for each epoch, we will now set 2 \n",
    "# of our hyperparameters the batch size and number of epoch. For batch size we will not take\n",
    "# advantage of iterable objects that contains the data instead we will enploy simple arrays, but\n",
    "# the batching itself will be indicated when we fit the model in the module 2\n",
    "# max number of epoch = 100, max epochs = 100, next we fit the model()\n",
    "# Then lets start with the trained input and the trained target, we can fit the 2 turple object \n",
    "# containing both of them as we did with the mnist or we can feed them seperately.\n",
    "# To show both approaches we already extracted the input and targets into seperate variables\n",
    "# inside the fit method we place the input 1st and then the targetm our firstarguement will be train \n",
    "# inputs, train targets and then the batch size.if you are dealing with arrays, indicating the batch size\n",
    "# will automatically batch the data during the training process, batchsize= batch size\n",
    "# next is the maximum no of epochs\n",
    "# validation data ,we have 2 arrays of interest(validation input and target)\n",
    "# We now set vebose to 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676fe828-7b67-4706-a39f-f34d7dfcda5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The result we got is outstanding,after 100 epochs of training we have \n",
    "# reached we have reached a validation accuracy of around 91 to 92%\n",
    "# Why did our model train for all 100 epochs?\n",
    "# Isn't there a danger of overfitting afetr training for so long?\n",
    "# yes pricisely,if we check the training process overtime , we will\n",
    "#notice that while the training was consistably decreasing our validation\n",
    "# loss was sometimes increasing, hence, is obvious we have overfitted the model\n",
    "# When we trained the mnist we didnt set an early stopping procedure\n",
    "# and we missed the step here as well, for the mnist it was not really crucial\n",
    "# bcos the dataset was so well prepared that it will barely make a difference, \n",
    "# this time though it does.\n",
    "# we will ned an early stopping mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd039f8-df8a-48c1-8bb1-6e3edd63dab1",
   "metadata": {},
   "source": [
    "#### Setting an early stopping mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c10b55b-5549-4008-9cdf-e986907684d2",
   "metadata": {},
   "source": [
    "We will explore how to set up an early stopping mechanism with tensorflow.\n",
    "The fit method contains an arguement called callbacks. Callbacks are functions  called at certain points during model \n",
    "training. There are many different readily available \n",
    "callbacks. You can try your training process in tensor\n",
    "board( class Tensorboard), you can strem the result in a csv file or server(class CSVLogger), class modelcheckpoint, \n",
    "classRemoteMonitor, save the model after each epoch, adjust the learning rate (class learningRateScheduler), You can also define any custom call back you may want to use.\n",
    "\n",
    "We will be focusing on early stopping\n",
    "class Earlystoping: Stop training when a monitored quantity has stopped improving.\n",
    "This is a definition of a utility called at certain point during training . Each time the validation loss is calculated\n",
    "it compares to the validation loss one epoch at a go. if it starts increasing, the model is overfitting and we should stop training. Since the early stopping mechanism is a hyperparameter in a way we decalre a new varaible called early stopping which will as follows early stopping = tf.keras.callback.Earlystopping, there is a readily available structure we can use, Hence, we need to take care of other particulas of this early stopping mechanism.\n",
    "By default, this object will monitor the validation loss and stop the training process the first time the validation \n",
    "loss process starts increasing.\n",
    "\n",
    "Is time to implement it in our training process, as suggeste, lets add a callback arguement to our fit method equal  to a list of callbacks. In our case , it will have a single element our early stopping variable.\n",
    "Lets retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cb4c20-3d1f-491c-84f9-38c315cd2ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "output_size = 2\n",
    "hidden_layer_size = 50\n",
    "# hidden_layer_size = 100\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                            #tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation ='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation ='relu'),\n",
    "                            tf.keras.layers.Dense(output_size, activation ='softmax')   \n",
    "                            ])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "max_epochs = 100\n",
    "\n",
    "#early_stopping = tf.keras.callbacks.EarlyStopping()\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "\n",
    "model.fit(train_inputs,\n",
    "          train_targets,\n",
    "          batch_size = batch_size,\n",
    "          epochs = max_epochs,\n",
    "          callbacks=[early_stopping],\n",
    "          validation_data=(validation_inputs, validation_targets),\n",
    "          verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb23b58-543a-4239-b408-e1b102587b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After retraining the model, we can see that the new \n",
    "# training lasts for less than 20 epochs and the final\n",
    "# accuracy of the model is around 90%. Obviosly the\n",
    "# first time we trained we had overfit and the result\n",
    "# was about 2% higher and we can attribute this solely \n",
    "# to over training it.Now if we value the validation \n",
    "# loss, we will notice that the first time it increased\n",
    "# was during the last epoch, moreover ,it increase only \n",
    "# slightly, Some times , if we notice that the validation \n",
    "# loss has increased by insignificant amount , we may prefer\n",
    "# to let one or two validation increase slide.\n",
    "# To allow for this tolerance, we can adjust the early\n",
    "# stopping object. There is an arguement called patience, \n",
    "# which by default ,is set to 0, we can specify the no \n",
    "# of epochs with no improvements after which the training will stop\n",
    "# tf.keras.callbacks.EarlyStopping(patience) configures \n",
    "# the eraly stopping mechanism of the algorithm.\n",
    "# it is a bit too strict to have no tolerance for a random \n",
    "# increase in the validation loss , thus let's set the patience to 2,\n",
    "# This way we will be completely sure if the model have started to overfit\n",
    "# With the adjustment we can re run the code.\n",
    "# Depending on your problem in dataset, the difference may not be crucial\n",
    "# However , this is yet anothe deburging tool you have at your disposal\n",
    "# This time the accuracy is between 90 to 91%, definitely worse than the overfitted\n",
    "# modelbut slightly butter than the one with no patience.\n",
    "# intepretation: the final validation accuracy of the model is around 90%, the priors \n",
    "# is around 50% , this means our ml algorithm has learnt alot. It managed to classify \n",
    "# around 90% of the customers correctly.\n",
    "# In other words , if we are given 10 customers and their audiobook activity we will \n",
    "# be ablle to correctly identify future customer behaviour of 9 of them.\n",
    "# How does this help us in practice ?\n",
    "# We can focus our marketing efforts only on those customers who are likely to convert again\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d4154d-d7f9-45de-8741-c79f71880c34",
   "metadata": {},
   "source": [
    "In summary, it is extremely hard to predict human behaviour , however with the machine learning algorithm what we create here is a new tool in your aesenal that has given you an incredible edge!\n",
    "Moreover, using the algorithm is a skill you can easily apply in any business out there.\n",
    "What we did was leverage the power of artificial intelligence (AI)to reach a business insight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4b09d4-1a33-41f8-b958-7fec6f0425e8",
   "metadata": {},
   "source": [
    "#### Testing the business model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc2a442-9fb6-4bdd-82db-e239121e7cea",
   "metadata": {},
   "source": [
    "To test the model we use the model evaluate\n",
    "model.evaluate() returns the loss value and metrics values for the model in test mode.\n",
    "\n",
    "Let's declare two variables, test loss and test accuracy = model evaluate of the test input and test target.\n",
    "Recall evaluate the returns the loss and any other mettics we have requested in our model outline. This was the accuracy, to make the result pritty ,we can print them with some nice \n",
    "fomatic.\n",
    "This is the final acuracy of the model.(91%)\n",
    "Natrally, it is close to the validation accuracy as we did not fiddle too much with hyperparameters.\n",
    "\n",
    "Note ,that sometimes , you can get a  test accuracy\n",
    " higher than the validation one.That is nothing but pure luck. theoritically, \" \n",
    " + The test accuracy should be equal or lower than the validation one\n",
    "+ from yhis point on, you are no longer allowed to change the model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800afdbe-95b7-48a8-a618-dd403b8dbbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_inputs,test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba07c5ae-aab2-4850-a486-8ee4e8f96010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eef7a92a-2f28-4d7e-aa49-fd8c6a70d54d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Week 14: Day 1 – Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fa6e71-4c17-495b-a48a-1a78ccc1ff88",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098f19d0-8403-4e76-97bd-c4864108264a",
   "metadata": {},
   "source": [
    "###  What’s more out there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48630118-4fad-4018-814e-113c43ea07bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "video not playing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4579550-9082-4650-ace4-326b302233b4",
   "metadata": {},
   "source": [
    "#### An overview of CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a298a197-c5bb-414c-8473-078da2497786",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CNNs are  used in image recognition\n",
    "\n",
    "spatial proximity\n",
    "are preserved\n",
    "\n",
    "google assistant by deepmind\n",
    "\n",
    "google \n",
    "apple use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d252a3-4b8b-4bf9-8585-14d5067fa3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fc5972-4835-476e-b948-bbdc783d9a06",
   "metadata": {},
   "source": [
    "#### How DeepMind uses deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78105d50-d9de-4762-bfee-bce10877298e",
   "metadata": {},
   "source": [
    "In the lesson on CNNs we briefly mention the great success with which DeepMind employs deep learning. \n",
    "\n",
    "\n",
    "DeepMind (https://deepmind.com/) is extremely productive and successful not only in the machine learning field (where they are supposedly the best in the world) but also in their efforts to communicate their findings to the world. In their blog, you can find all publicly available information about their research. \n",
    "\n",
    "\n",
    "After taking this course, you can easily read and understand their blog. Please follow the links below to read their accomplishments on their project WaveNet, which produced the most humanlike computer generated voice so far (integrated in Google Assistant).\n",
    "\n",
    "\n",
    "The deep learning involved in WaveNet: https://deepmind.com/blog/high-fidelity-speech-synthesis-wavenet/\n",
    "\n",
    "\n",
    "Alternatively, you can just listen and compare the speech synthesis (listen to the results) here: https://deepmind.com/blog/wavenet-launches-google-assistant/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b94343-30ac-4e8d-9ae2-2eafb65ce5ad",
   "metadata": {},
   "source": [
    "#### An overview of RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29f70a4-21d4-4dac-878d-87fe4908760c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "783e8efa-04a4-4d52-a927-17b6482a3da9",
   "metadata": {},
   "source": [
    "####  Non-NN approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa9c0e8-9f0b-4ab0-aee2-1ec3e1290df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn sequential data\n",
    "\n",
    "music trading \n",
    "\n",
    "\n",
    "cnn has memory\n",
    "\n",
    "hidden layer\n",
    "output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aa05a0-6565-4034-8607-38e4720bf5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "random forest are used for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48101073-e6eb-485b-98a4-e97d4ee49dba",
   "metadata": {},
   "source": [
    "#### Week 14: Day 2 – BIG DATA, MACHINE LEARNING AND NATURAL LANGUAGE PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac37171a-467a-438b-8c93-a07d83df2883",
   "metadata": {},
   "source": [
    "#### Big data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86d0a09-86e9-4dea-bd6b-e474c810d9c6",
   "metadata": {},
   "source": [
    "big data\n",
    "\n",
    "velocity - it is fast eg now we send mesage or call in minutes, \n",
    "\n",
    "veracity :comformity and origin of data\n",
    "unstictured about 80%\n",
    "\n",
    "variety : unstructured line format, variety of data, data comes from machine, people and processs\n",
    "\n",
    "devces\n",
    "\n",
    "value - tto turn data into asset\n",
    "\n",
    "volume \" the growth of data, scale of the data\n",
    "\n",
    "\n",
    "impact : speaking of impact. eg nestlist the streaming company. analyze customers watchinh habit and use it to produce their on model,\n",
    "\n",
    "it impprove the whole experience of data collection before streaming.\n",
    "\n",
    "it brings improvement to companies\n",
    "\n",
    "personalization of offerings e.g amazon\n",
    "use it to know thre customers\n",
    "fraud reduction eg pfizeer use big data to anayze unusual patterns\n",
    "\n",
    "predictive maintainance. : performance issues before it happens e.g ol and gas\n",
    "\n",
    "\n",
    "It is used in many compamies\n",
    "\n",
    "Overlooked challehge:\n",
    "\n",
    "How companies learn your secrets\n",
    "loose customers trust\n",
    "\n",
    "key take aways\n",
    "\n",
    "+ stored data increasing exponentially , shifting\n",
    "from analog to digital\n",
    "\n",
    "+ large. unstructured and fast moving data\n",
    "value generation through tracing , connecting  and analyzing \n",
    "\n",
    "+ trust of customers is a competitive advantage\n",
    "\n",
    "\n",
    "Digital tranformation is the way to the future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d310a17-c710-4e98-a0b9-bb2e5ce6c792",
   "metadata": {},
   "source": [
    "+ Big data refers to the dynamic, large and disparate volumes o data being created by people, tools, and machines. it requires new innovative and scalaeble technology to collect,host and analytically process the vast amount of data gathered in other to derive real time business insights that relates to consumers, risk, profit, performance, productivity ,management and enhanced shareholder value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ff0b1e-7375-43f9-9905-6e09bed31d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05544452-50ef-4721-a9b1-fa1b98a65d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a705f19-cfe0-468f-8633-ea9ca6fd8266",
   "metadata": {},
   "source": [
    "#### OUIZ on big data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b691c114-008a-424c-9c0c-8042e2c8928b",
   "metadata": {},
   "source": [
    "\n",
    "1. Which of the following typically create large sets of data?\n",
    "\n",
    "Search Engines\n",
    "Social Media Sites\n",
    "Hospitals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00636946-e10e-47f4-bbf7-fbe27dc93de2",
   "metadata": {},
   "source": [
    " 2. Why are computers used to process digital data? (Choose all that apply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30641ceb-e524-4a68-9a1f-c671fb346f31",
   "metadata": {},
   "source": [
    "Computer are much faster and more efficient than humans when searching large data sets\n",
    "Computer can more quickly scan and sort through giant sets of data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeedd4e-0a04-4beb-8c66-1f41d3e1594f",
   "metadata": {},
   "source": [
    "3. Which of the following operations can computers perform on large data sets to help make sense of the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b12cfa-9457-4a5f-8bd3-750aa8452ba6",
   "metadata": {},
   "source": [
    "computers can remove useless stuff from the data way faster than humans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dfc9db-695a-4170-9e07-743519cf901a",
   "metadata": {},
   "source": [
    "4. Which of the following is possible when computers and programs are used to manipulate large data sets? (Choose all that apply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb60e48-b5de-4f62-ba06-a9b7f2685377",
   "metadata": {},
   "source": [
    "groups or patterns may emerge that need to be examined\n",
    "\n",
    "useless stuff can be removed to make the data easier to examine\n",
    "\n",
    "ways to use the data can be discovered once junk is removed from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf67f5f-1415-433f-b2e8-60bbfa15bdfa",
   "metadata": {},
   "source": [
    "5. Scanning large data sets can help companies and individuals locate which of the following in the large data sets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cbcc2b-8b10-4fe1-ada7-ad892aef0a4c",
   "metadata": {},
   "source": [
    "repeating groups or patterns in the data\n",
    "\n",
    "how the data relates to the business and how the business operates\n",
    "\n",
    "groups or patterns that could be important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de726be5-6671-4a3f-8726-cfc01c9c426b",
   "metadata": {},
   "source": [
    "6. Which of the following are valid risks when working with large data sets? (Choose all that apply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48439e8-9fd6-4103-9de0-37c5ea7f68e6",
   "metadata": {},
   "source": [
    "the data could be accessed by those without permission\n",
    "it takes time and resources to sort through large data sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b2ce8a-75fb-4715-8810-3497523ea720",
   "metadata": {},
   "source": [
    "7. Which of the following can help make sense of large sets of data? (Choose all that apply)\n",
    "\n",
    "Software programs to sort through the data and display it in ways that help us better understand the data\n",
    "Algorithms that quickly sort through the data looking for groups or patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3835f3a7-b2c4-4781-98ba-dd2e53291b28",
   "metadata": {},
   "source": [
    "8. Which of the following would be a valid reason to analyze a large set of data?\n",
    "\n",
    "To determine if groups and patterns are present\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ca527f-d584-4e95-a64e-73867b9c5554",
   "metadata": {},
   "source": [
    "9. When stored, which of the following could create a large data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15ba6be-0475-42c1-a1b5-cf3c23914a65",
   "metadata": {},
   "source": [
    "List of songs\n",
    "\n",
    "Group of Images\n",
    "\n",
    "Data from search results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85829ee-8ef2-4077-9d10-01a6631e8442",
   "metadata": {},
   "source": [
    "0. If writing a program for use on a large data set, which of the following would be important considerations for the programming language selected?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97db4d59-c003-4ffb-bb29-ce3955e2ace5",
   "metadata": {},
   "source": [
    "Does the programming language contain the features needed.\n",
    "\n",
    "Will the programming language create code that is logical and easy to understand.\n",
    "\n",
    "Will the programming language create code that will run efficiently for the problem being solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4a8ce2-9671-48ab-80f3-62565caa54cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5391bda8-a1a5-4377-9709-24ba1bd98b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cd1262e-8fb5-489a-b45e-a476e0e88418",
   "metadata": {},
   "source": [
    "### Week 14: Day 2 continuation – Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7b4331-3d50-4b34-9fe5-3c1d912932b4",
   "metadata": {},
   "source": [
    "#### Introduction to NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837ae4b5-d526-4805-a6e9-bf221eeaa7ef",
   "metadata": {},
   "source": [
    "word embedding is vector representation of words in orther to have a clearer understanding about it \n",
    "\n",
    "used as a thesaurus\n",
    "topic identification\n",
    "\n",
    "\n",
    "summary\n",
    "\n",
    "1. syntax and semantics of english language\n",
    " +  Structure and meaning of written text\n",
    " \n",
    " language models\n",
    " Converting text into  a series of probabilities\n",
    " \n",
    " Word enbeddings\n",
    " \n",
    " learning sematics of text as mathematical vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f71e15-b092-4c39-9a8b-edc7f856d431",
   "metadata": {},
   "source": [
    "thesaurus\n",
    "\n",
    "a book or electronic resource that lists words in groups of synonyms and related concepts.\n",
    "\"I'm going to need a thesaurus to come up with synonyms for ‘stupid’\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4808dd1-99f8-4740-8b56-defdb92da9ae",
   "metadata": {},
   "source": [
    "Natural language processing is an automated way to understand and analyze natural human languages\n",
    "and extract information from such data by applying machine algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32debf19-ae36-452a-86ad-d25caf615587",
   "metadata": {},
   "source": [
    "Text data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c979c4-f762-4917-9a97-c05dfd281747",
   "metadata": {},
   "source": [
    "#### Natural Language Processing: Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ccbbf2-f1dc-4b8a-9a39-aae098a9fe3f",
   "metadata": {},
   "source": [
    "1. Natural Language Processing (NLP) is the field of __________\n",
    "\n",
    "Computer Science\n",
    "Artificial Intelligence\n",
    "Linguistics\n",
    "\n",
    "All of the above (corect answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13400a2-46b1-49c2-b156-48d8a8e074b3",
   "metadata": {},
   "source": [
    "2. NLP is concerned with the interactions between computers and human (natural) language\n",
    "true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58efff5a-f3b3-440d-8127-3ba676de4b33",
   "metadata": {},
   "source": [
    "3. One of the main challenge/s of NLP Is _____________\n",
    "\n",
    "Handling Ambiguity of Sentences\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4670a9-5e3f-4189-bffd-63fff825a520",
   "metadata": {},
   "source": [
    "4. Modern NLP algorithms are based on machine learning, especially statistical machine learning.true\n",
    "\n",
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6e04f4-cb77-4532-8ba5-1cc5c63ab9ca",
   "metadata": {},
   "source": [
    "5. Choose form the following areas where NLP can be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164c074d-530d-45fb-9c32-bf612aeb8a8b",
   "metadata": {},
   "source": [
    "Automatic Text Summarization\n",
    "Automatic Question-Answering Systems\n",
    "Information Retrieval\n",
    "All of the above correct "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9744de77-f254-45cd-9e13-cee5b01d5d6f",
   "metadata": {},
   "source": [
    "6. The major tasks of NLP includes\n",
    "\n",
    "all of the above  Answer\n",
    "\n",
    "\n",
    "Automatic Summarization\n",
    "Semantic Analysis\n",
    "Incorrect Machine Translation\n",
    "All of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acc4894-545c-4b20-a2bf-a3efe7e0d211",
   "metadata": {},
   "source": [
    "7. Machine Translation _______________\n",
    "convert human language to another"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82cf042-4b63-4242-a2bb-838da41daf9f",
   "metadata": {},
   "source": [
    "8. Morphological Segmentation ___ ____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a7cfdc-9fe0-4baa-b144-c0151fe4840f",
   "metadata": {},
   "source": [
    "Separate words into individual morphemes and identify the class of the morphemes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26270724-0f4f-4294-8a7c-0e563d62a534",
   "metadata": {},
   "source": [
    "9. . The more general task of coreference resolution also includes identifying so-called “bridging relationships” involving referring expressions.\n",
    "\n",
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e375f8-b8bb-4a73-8a90-88c02dcc6012",
   "metadata": {},
   "source": [
    "10. Google Translate is one of the ________________ application.\n",
    "\n",
    " machine translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fd369f-5baf-4df6-aed7-01056d76e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk ; natural language tool kit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0400fdb9-8b3f-402d-953c-5eaddda21bac",
   "metadata": {},
   "source": [
    "#### Week 14: Day 3 – Text Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad249366-3450-4da0-817e-8cf67c5f95dd",
   "metadata": {},
   "source": [
    "#### Text Vectorization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0975d238-b066-43b2-aa38-4d34442253a9",
   "metadata": {},
   "source": [
    "Text Vectorization is the process of converting text into numerical representation.\n",
    "\n",
    "Here is some popular methods to accomplish text vectorization:\n",
    "\n",
    "Binary Term Frequency.\n",
    "\n",
    "Bag of Words (BoW) \n",
    "\n",
    "Term Frequency. (L1)\n",
    "\n",
    "Normalized Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd5e80c-8480-46cf-bc77-d580dcc074a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenization is splitting words into smaller lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f6551d-3ce3-4b64-a71b-49c3d4ebd8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Inverse downscales words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853f349b-1eba-4df7-937e-111456ace6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Text Vectorization: Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dca5dd-834e-4092-a5ab-52e5d9831787",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.  ___________________ is the process of converting text into numerical representation\n",
    "\n",
    "Text Vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f011b27-2635-4e4a-9d22-431b443b0a98",
   "metadata": {},
   "outputs": [],
   "source": [
    ". One of these is NOT a method of accomplishing text vectorization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf26037-a216-4222-b6ab-525d580af83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Binary Term Frequency\n",
    "(L1) Normalized Term Frequency\n",
    "Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a124944b-acfb-4ea1-b364-ee660e3a9230",
   "metadata": {},
   "outputs": [],
   "source": [
    "Combinatorics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af155e60-2f4b-4655-b7db-c608fbd633f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Binary Term Frequency captures ___________ or _____________ of term document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462ae3f3-fdd6-480b-ab87-d965e1b812b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "present 1 absent zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3971bd80-6e45-4bbe-86bd-c86e70a1d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. BoW is short for _bag of words_________?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f840c39-5d8e-4571-ba57-2d3309c25c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. TFIDF stands for ___Term Frequency – Inverse Document Frequency____________?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959c962b-2572-4f26-af98-b364bc06acdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. In the (L2) Normalized TFIDF formula, N stands for _____________?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2de0b25-3718-4052-9242-a3cb2f47fb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number of documents in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ab4026-7a21-4346-b2b3-69baa53e406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. ______________ provides embedded representation of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f86182d-6588-496a-b17e-1bfa7d8d74de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82daa263-2b23-4427-8627-c48d1a4871ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. A collection of texts without non-alpha-numeric characters is called __corpus___________?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8293d656-50b0-468c-b299-31c9dc64abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. Word2Vec requires training NN on a very large corpus of data. Two methods for training the NN are __________?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f11bcf-a676-4626-a1f5-f994bf88220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Continuous Bag of Words (CBOW) and Skip-Gram (SG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d600244f-b8a6-4931-b81e-7ad7e471bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. Which of these is a method to accomplish text vectorization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89ec1fb-3332-40d0-83f0-1a45be6918c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(L1) Normalized Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cea18f-b845-4dac-9b24-d8c3f3c79774",
   "metadata": {},
   "outputs": [],
   "source": [
    "Week 14: Day 3 – Natural Language Processing Toolkit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923189b3-fb06-4921-b683-1eb45d99e1d9",
   "metadata": {},
   "source": [
    "Week 14: Day 3 – Natural Language Processing Toolkit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6ea3c6-b8c2-4b15-a69d-2558b3ee3bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a620954-ea96-4793-8a0d-851706fcb3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af758567-937e-4274-aa6c-882cf8cb024d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
