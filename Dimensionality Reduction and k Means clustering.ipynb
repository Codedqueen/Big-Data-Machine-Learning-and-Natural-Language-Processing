{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b0d5e7d-11a2-4c93-b887-8e44238cf013",
   "metadata": {
    "tags": []
   },
   "source": [
    "### MODULE 4: BIG DATA, MACHINE LEARNING AND NATURAL LANGUAGE PROCESSING\n",
    "\n",
    "#### Week 12: Day 1 – Dimensionality Reduction \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67847461-21f7-40eb-a22a-1918af35d1df",
   "metadata": {},
   "source": [
    "##### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc58417-e8d8-459b-a179-f2a09aa0b5df",
   "metadata": {},
   "source": [
    "##### learning Goals\n",
    "\n",
    "In this section, we are moving away from clustering and moving on to a different typpe of supervised learning,namely,Or finding ways of representing the dataset in lower dimensions.\n",
    "\n",
    "In this section,we will cover:\n",
    "\n",
    "- Dimensionality reduction Overview\n",
    "\n",
    "and how we can go about solving the problem of dimensionality by coming up with lower dimension representation of our data that maintains the majority of information as important to us within the dataset.\n",
    "\n",
    "- Pincipal Components Analysis\n",
    "\n",
    "We will find out how we can use this to come up with new features and lower dimensional space solving our problems in dimensionality.\n",
    "\n",
    "- Non-negative matrix factorization\n",
    "\n",
    "We will use it to come up with means of decomposing our initial data into only positive values and reduce the number of dimensions again.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5495f10f-809a-4e4f-8131-12c42240eab2",
   "metadata": {},
   "source": [
    "#### Curse of Dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a015caba-3829-4cb8-ba25-030545f778d2",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "Recall that due to the curse of dimensionality:\n",
    "    \n",
    "- In practice ,too many of these features leade to worse performance for our differen models.\n",
    "\n",
    "- Distance measures perform poorly and the incidence of outliers increases as we increase the number of dimensions.\n",
    "\n",
    "The reason is that if we think about just working with 1 dimension that has 10 positons, in order to fill up the entire space we only need 6 observations and we only needs 6 rows to cover 60% of this space.\n",
    "\n",
    "If we increase this to 2 dimensions,each one with 10 different positions , then we will need 60 differnt observations within our dataset in order to cover 60% of the possible positions.\n",
    "\n",
    "If we increase it to 3 Dimensions and beyond, we can seee how this number in other to cover thesame amount of space that is available increases exponentially as one 1 Dimension gets added up.\n",
    "\n",
    "This is a very common situation,especially with enterprice datasets that oftencontain many features.\n",
    "\n",
    "- Data can be represented by fewer dimensions(features) than the original dataset may have.\n",
    "\n",
    "- And ways to accomplish this will be either \n",
    "\n",
    "- To reduce dimensionality by selecting subset(featue elimination),that you deemed are the most important feature in that larger dataset that you are working with\n",
    "\n",
    "- You can combine with linear and non-linear transformations.(Which is what we are going to do here starting with PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f90ceb6-3a7f-49df-86f4-aa0d0ed57c75",
   "metadata": {},
   "source": [
    "+ How does PCA work?\n",
    "\n",
    "This idea of creating new features out of the many features actually worked.\n",
    "In this example, \n",
    "\n",
    "-we will start with two features, Phone usage(minutes) and  Data Usage.\n",
    "\n",
    "- Both features increases together(correlated), and visually it looks like the point lies very close to ny.\n",
    "- The question is this, can we reduce the number of features to one?\n",
    "\n",
    "- Create single features that is combination of phone and data usage. We can pick up this transformation as a scale addition of each of the two columns. Thus we now have one column created as a combination of the original columns.\n",
    "\n",
    "- This the the idea of principal Component Analysis (PCA)\n",
    "\n",
    "We will replace the columns by summing up combinations of those original columns and these linear combinations are going to be intelligently selected in other to preserve the underlying meaniing of our data ie trying to maintain as much of the original variance as possible.\n",
    "\n",
    "Finally, we have successfully created a single feature out of the two features we originally have, thus reducing the dimensionality of our feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d786ee0-29b2-4168-ba66-3ab35da486fb",
   "metadata": {},
   "source": [
    "+ Principal Component Analysis(PCA)\n",
    "\n",
    "- focus is on how PCA find these lines on which to project our data.\n",
    "\n",
    "- Linear Algebra have tools that can determine exactly where our axis is ,where we have the most variance.\n",
    "Direction (v1) Lenghth X1.\n",
    "\n",
    "Using linear algebra,we can find this primary vector that the dataset is distributed on. Mathematically, it will be called the primary right similar vector.This will account for the maximum amount of variance in any direction for our dataset.\n",
    "Excluding the primary singular vector, we will also have the second axis for this dataset. We are going to have another right singular vector, behind the primary one we just had.\n",
    "\n",
    "Once we had these into pepedincular vectors , each one of these vectors have moved to a pepedincular or third node ,one another.We can then determine a meaningful rejecting of our data.\n",
    "\n",
    "We will project to the direction where we have more data, as we can see from the diagram, we project toward s v1 because we have more data and can be able to project to the original variance but v2 have  small data and is narrow.\n",
    "\n",
    "+ Single value decomposition(SVD )\n",
    "\n",
    "- Single value decomposition(SVD ) is a matrix factorization method normally used for PCA.\n",
    "\n",
    "- it does not require a square data set\n",
    "\n",
    "- SVD is used by Scikit-learn for PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f9abc7-1122-4b81-bd17-671a5e4ec6e7",
   "metadata": {},
   "source": [
    "+ Truncated Single Value Decomposition "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22d3747-b5c5-45fa-b5f3-1fd08368df21",
   "metadata": {},
   "source": [
    "- How can SVD be used for dimensionality reduction?\n",
    "\n",
    "- The larger the value, the more important it will be.\n",
    "\n",
    "- principal components are calculated from V.\n",
    "\n",
    "- \"Truncated SVD\" used for dimensionality reduction(n ->K).\n",
    "\n",
    "+ Importance of Feature Scaling\n",
    "\n",
    "- PCA and SVD seek to find the vectors that capture the most variance.\n",
    "\n",
    "- Variance is sensitive to axis scale.\n",
    "\n",
    "- Note,that having unscaled data will allow one of those axis to have more ways to provide where the maximum variance may actually be. So if it is not scaled we may end up with this projection on the graph while in reality we needed a scaled projection.\n",
    "\n",
    "- Must scale data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa57172-641c-4f85-ac18-8f797ad0b937",
   "metadata": {},
   "source": [
    "+ PCA: The Syntax \n",
    "\n",
    "Now, in other to do PCA using sklearn we import:\n",
    "    \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "Then, Create an Instance of the class.\n",
    "    PCAinst = PCA(n_components=3)\n",
    "We need to say how many component we want to reduce our original data set to,\n",
    "We can passs the final number of components we want\n",
    "\n",
    "Fit the instance on the data and then transform the data.X_trans = PCAinst.fit_transform(X_train)\n",
    "\n",
    "for example, we can transform the customer chum dataset,which has around 20 numeric features to one with only 3 features,with those 3 features being combination of those original features that we have using that singular value decomposition that gave us that V-matrix to show us how to reduce the number of dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ef6cd-862a-4c36-ada2-36fb6e5ac60a",
   "metadata": {},
   "source": [
    "#### Introduction to Dimensionality Reduction Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cdc83c-7862-4022-b958-37c69d27ec7a",
   "metadata": {},
   "source": [
    "feature selection and feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b23a640-7d4b-48ca-ba6b-2391074d5a4a",
   "metadata": {},
   "source": [
    "Dimensionality reduction involves reducing the number of input variables or columns in modeling data. LDA is a technique for multi-class classification that can be used to automatically perform dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dd9b78-12c9-4c9b-9acf-8020f333ef27",
   "metadata": {},
   "source": [
    "Feature Elimination: we reduce the feature space by elimination feature. The advantages of the feature elimination method include simplicity and maintainability features. We’ve also eliminated any benefits those dropped variables would bring.\n",
    "\n",
    "Feature Extraction: PCA is a technique for feature extraction. So it combines our input variables in a specific way, then we can drop the “least important” variables while still retaining the most valuable parts of all the variables.\n",
    "\n",
    "When should I use PCA?\n",
    "\n",
    "1. Do you want to reduce the no. of variables, but are not able to identify variables to completely remove from consideration?\n",
    "\n",
    "2. Do you want to ensure your variables are independent of one another?\n",
    "\n",
    "3. Are you comfortable making your independent variable less interpretable?\n",
    "\n",
    "2.1.2: How Principle Component Analysis (PCA) work?\n",
    "We are going to calculate a matrix that summarizes how our variables all relate to one another.\n",
    "\n",
    "We’ll then break this matrix down into two separate components: direction and magnitude. we can then understand the direction of our data and its magnitude.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416836fe-c431-48a6-8858-9716fb0fde09",
   "metadata": {},
   "source": [
    "The following are the advantages of LDA:\n",
    "1. Reduces overfitting because of reduction in the number of features\n",
    "2. Model training can be expedited.\n",
    "§ Disadvantages of LDA\n",
    "There are three major disadvantages of LDA:\n",
    "1. Not able to detect correlated features\n",
    "2. Cannot be used with unsupervised or unlabeled data\n",
    "3. Some amount of information is lost when you reduce features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0334af-8a19-4de9-a6c6-04e379c44f3e",
   "metadata": {},
   "source": [
    "Dimensionality Reduction with PCA and LDA Using\n",
    "Sklearn\n",
    "Dimensionality reduction refers to reducing the number of features in a dataset in\n",
    "such a way that the overall performance of the algorithms trained on the dataset is\n",
    "minimally affected. With dimensionality reduction, the training time of statistical\n",
    "algorithms can be significantly reduced, and data can be visualized more easily\n",
    "since it is not easy to visualize datasets in higher dimensions.\n",
    "There are two main approaches used for dimensionality reduction: Principal\n",
    "Component Analysis (PCA) and Linear Discriminant Analysis (LDA). In this\n",
    "chapter, you will study both of them.\n",
    "10.1. Principal Component A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cda3407-98bb-4c7c-9ba5-afa87e4cb4f9",
   "metadata": {},
   "source": [
    "Why Use PCA?\n",
    "\n",
    "The following are the advantages of PCA:\n",
    "    \n",
    "1. Correlated features can be detected and removed using PCA\n",
    "\n",
    "2. Reduces overfitting because of reduction in the number of features\n",
    "\n",
    "3. Model training can be expedited.\n",
    "\n",
    "§ Disadvantages of PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d42440-3f36-40b7-8f34-fd9b58fee20c",
   "metadata": {},
   "source": [
    "There are two major disadvantages of PCA:\n",
    "    \n",
    "1. You need to standardize the data before you apply PCA\n",
    "\n",
    "2. The independent variable becomes less integrable\n",
    "\n",
    "3. Some amount of information is lost when you reduce features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9831633-56fc-4042-99b7-c5cb8d3b59db",
   "metadata": {},
   "source": [
    "### Feature Selection using Fisher Score and Chi2 (χ2) Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4412acec-b271-4ea6-a2db-3d14834db7e9",
   "metadata": {},
   "source": [
    "###### Feature Selection using Fisher Score and Chi2 (χ2) Test|Titanic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701e9311-5509-4a7c-9376-e1982a157775",
   "metadata": {},
   "source": [
    "+ What is Fisher Score and Chi2(X2) Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c2f753-c29e-49e1-b8e4-4e8ece99bde0",
   "metadata": {},
   "source": [
    "Fisher Score is one of the most widely used supervised Feature selection methods. However, it selects each feature independently according to their scores under the Fisher criterion which leads to a suboptional subset of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff5f1e7-1a36-4957-8a7a-3619ce7f92d1",
   "metadata": {},
   "source": [
    "+ High dimensional data is usually not good for classification due to the cost of the dimension length. It significantly increases the time and complexity of processing the data. Suppose you have a huge dimendion of data, it will definetely take more time and space to test and train the model. Moreover, in the presence of many irrelevant and redundant features learning methods fail too often and becomes less interpreteable. a common way to resolve this problem is feature selection which reduces the dimension lenght by selecting a subset of a feature from the input feature set and it is often used to reduce the computational cost and remove irrelevant and redundant features for problems with high dimensionality and one of the method is feature score which can be done by a chi2 test.\n",
    "\n",
    "We will be using the feature score on a chi 2 tset using the titanic dataset. This an be applied only on categorical data.\n",
    "\n",
    "It computes the distribution, frequency ,mean, mode ,median.\n",
    "\n",
    "Feature Score is one of the most widely used feature selection method. It selects each featureindependently according to their score and feature criteria, which can lead to some of the most subset of the features. In the univerate feature selection, we select  features individually by considering the effect of the other features. We may end up by selecting a sub optimal feature set. This can be used for screening purpose and for educational purpose. To enable us know the label or models for feature score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecdd0af-bd17-444c-a664-8aba37632ccc",
   "metadata": {},
   "source": [
    "+  Chi Square (X2) Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07701909-e469-4367-bc12-ff70d55c7a12",
   "metadata": {},
   "source": [
    "A chi-square test measures dependency between stochasticvariebles, so using this function'weeds out' the features that are the most likely to be independent of class and therefore irrelvant for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3655c4-d1c5-468f-b60c-8629f24cab78",
   "metadata": {},
   "source": [
    "A chi2 test is a statistical hypothesis test where the sampling distribution of the satistics is a chi square  distribution and it is used to determine  whether there is a significant difference between expected frequncy and  object frequency in one or more category that we want among features and it is applied only on categorical data set. chi square test is used to differentiate this statistical behaviour.\n",
    "\n",
    "Using this function it will solve the features that are most likely to be independent of the class and their relevance for the classification. This means we can remove those features which are irrelevant for the classification and not dependent,ie they are independent to the target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadbf003-b867-4e68-80c0-9fb362e3300a",
   "metadata": {},
   "source": [
    "The feature score and chi2 works only on categorical dataset. After we get the categorical dataset, we do the f-score , the p-value, then select the feature that have the lowest p-value, then we compare the performance of the algorithm after selecting the the traint test of the features . then how to improve the accuracy of the model by selecting some particular features instead of using complete feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f26f1425-2702-43ba-9065-7fa6163e365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9012825a-0a1e-4a94-bfb0-cd4e35de95d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "729914f0-ce56-4ed7-a271-8f695e4430ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed043d05-94ba-4761-9cdf-7be9d73f81fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43760d04-d291-4f0f-b0a1-364926d4dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The titanic dataset has a total of 14 classess and one class for output(survived)\n",
    "# Chi2 deals with categorical variable, hence, age , fare are not categorical variable.The pclass and class is the same, se, sibsp are categorical.\n",
    "# parch,fare embarked,who, adult_male,deck, embark_town,alive and alone are all categorical variables\n",
    "# we will calculate the feature score using the chi2 test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "833c2cf0-1654-4f35-8fa2-6b77b2aa22f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check for the sum of NaN value\n",
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c8a1a-d663-4d60-984e-0309178a66cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the output we have 177 null values in age, 2 nan value in embarked,688 nan values in deck and 2 in embark_town\n",
    "# Deck and Age have alo tof nan value so we will drop the columns and also  embark_town and embarked since we only need cat.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc2cc610-4fcb-4847-8f2a-893119747c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To drop nan values\n",
    "titanic.drop(labels= ['age', 'deck'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4b80172-95a7-4482-80b3-a7c39b459312",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "826e3119-d40e-45ab-aad1-3e080fcb484d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived       0\n",
       "pclass         0\n",
       "sex            0\n",
       "sibsp          0\n",
       "parch          0\n",
       "fare           0\n",
       "embarked       0\n",
       "class          0\n",
       "who            0\n",
       "adult_male     0\n",
       "embark_town    0\n",
       "alive          0\n",
       "alone          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06533266-cd7a-4d62-8e08-e5ff8060206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert the sex column into numerical (categorical data)\n",
    "# first ,lets make a copy of the cat.data we will be using \n",
    "data = titanic[['pclass', 'sex', 'sibsp', 'parch', 'embarked', 'who', 'alone']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a1244a5-bf85-4bb9-99d6-bba5f95b2a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>embarked</th>\n",
       "      <th>who</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>man</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>woman</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass     sex  sibsp  parch embarked    who  alone\n",
       "0       3    male      1      0        S    man  False\n",
       "1       1  female      1      0        C  woman  False\n",
       "2       3  female      0      0        S  woman   True\n",
       "3       1  female      1      0        S  woman  False\n",
       "4       3    male      0      0        S    man   True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da92911f-98f7-45c5-bae6-7720136c91ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass      0\n",
       "sex         0\n",
       "sibsp       0\n",
       "parch       0\n",
       "embarked    0\n",
       "who         0\n",
       "alone       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bb40807-5581-4141-9a77-cb4100e275d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the cat.var. on the sex column to numerical var.\n",
    "sex = {'male': 0, 'female': 1}\n",
    "data['sex'] = data['sex'].map(sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3592992-e84d-49f0-8939-d2718e55c331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>embarked</th>\n",
       "      <th>who</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>man</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>woman</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  sex  sibsp  parch embarked    who  alone\n",
       "0       3    0      1      0        S    man  False\n",
       "1       1    1      1      0        C  woman  False\n",
       "2       3    1      0      0        S  woman   True\n",
       "3       1    1      1      0        S  woman  False\n",
       "4       3    0      0      0        S    man   True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb800754-cd20-43bb-a1f6-9e59dbcf953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ports = {'S': 0, 'C': 1, 'Q': 2 }\n",
    "data['embarked'] = data['embarked'].map(ports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42fb5a5b-95db-4cb8-9140-f14b31f3b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "who = {'man': 0, 'woman': 1, 'child': 2}\n",
    "data['who'] = data['who'].map(who)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80493d5d-dd6f-4789-9279-8b8f8e688e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "alone = {True: 1, False: 0}\n",
    "data['alone'] = data['alone'].map(alone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61a7abaf-54ee-4238-bc97-7a2d0530ce32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>embarked</th>\n",
       "      <th>who</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  sex  sibsp  parch  embarked  who  alone\n",
       "0       3    0      1      0         0    0      0\n",
       "1       1    1      1      0         1    1      0\n",
       "2       3    1      0      0         0    1      1\n",
       "3       1    1      1      0         0    1      0\n",
       "4       3    0      0      0         0    0      1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0588a1a-6ac8-4012-99c5-c944900e17d1",
   "metadata": {},
   "source": [
    "#### Do F- Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5bf87d5-2a00-4dca-ae72-2371461bc607",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.copy()\n",
    "y = titanic['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1c2a6ed-98d0-4778-8e30-3af3982ba55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((889, 7), (889,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5c3d813-58ec-452a-b7b6-0ae50dc3edfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b17830dd-0fcb-4879-9be3-e82e9ad55f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score = chi2(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "681bc1ce-9f8c-45d2-a454-880526a3e572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 22.65169202, 152.91534343,   0.52934285,  10.35663782,\n",
       "         16.13255653, 161.42431175,  13.4382363 ]),\n",
       " array([1.94189138e-06, 3.99737147e-35, 4.66883271e-01, 1.29009955e-03,\n",
       "        5.90599986e-05, 5.52664700e-37, 2.46547298e-04]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48450601-f94e-4709-a507-b25ee477cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create series\n",
    "p_values = pd.Series(f_score[1], index = X_train.columns)\n",
    "p_values.sort_values(ascending = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d3553fc-836c-4372-9f25-7ab8a939a1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "who         5.526647e-37\n",
       "sex         3.997371e-35\n",
       "pclass      1.941891e-06\n",
       "embarked    5.906000e-05\n",
       "alone       2.465473e-04\n",
       "parch       1.290100e-03\n",
       "sibsp       4.668833e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d89c614-2b41-4082-9f97-fd462eba1cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the result the lowest p-value is held by who and sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f006fc6-fc51-4093-ba21-6344affeb0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's visualize with abar chart\n",
    "p_values.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20fe2f86-b6be-476e-a737-5e64df1c6b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features sex and who to find out the accuracy we are getting\n",
    "X_train_2 = X_train[['who', 'sex']]\n",
    "X_test_2 = X_test[['who', 'sex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c61dc856-509d-4e72-b0a6-317e662f67b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_randomForest(X_train, X_test, y_train, y_test):\n",
    "    clf = RandomForestClassifier(n_estimator=100, random_state=0, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('Accuracy: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cdec0601-c5fc-4631-bce5-9270cccc97fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'n_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7988/2601228990.py\u001b[0m in \u001b[0;36mrun_randomForest\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun_randomForest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'n_estimator'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_randomForest(X_train_2, X_test_2, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f256a6f-0bec-4f2a-b895-c8c650238659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's select the top 3 features and calculate the accuracy\n",
    "X_train_3 = X_train[['who', 'sex','pclass']]\n",
    "X_test_3 = X_test[['who', 'sex', 'pclass']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1fa9ebe4-800e-4489-9f50-2cfc833914bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3444\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_7988/671803503.py\"\u001b[0m, line \u001b[0;32m1\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    get_ipython().run_cell_magic('time', '', 'run_randomForest(X_train_3, X_test_3, y_train, y_test\\n')\n",
      "  File \u001b[0;32m\"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m2406\u001b[0m, in \u001b[0;35mrun_cell_magic\u001b[0m\n    result = fn(*args, **kwargs)\n",
      "  File \u001b[0;32m\"C:\\Users\\user\\anaconda3\\lib\\site-packages\\decorator.py\"\u001b[0m, line \u001b[0;32m232\u001b[0m, in \u001b[0;35mfun\u001b[0m\n    return caller(func, *(extras + args), **kw)\n",
      "  File \u001b[0;32m\"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\"\u001b[0m, line \u001b[0;32m187\u001b[0m, in \u001b[0;35m<lambda>\u001b[0m\n    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \u001b[0;32m\"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\"\u001b[0m, line \u001b[0;32m1280\u001b[0m, in \u001b[0;35mtime\u001b[0m\n    expr_ast = self.shell.compile.ast_parse(expr)\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\compilerop.py\"\u001b[1;36m, line \u001b[1;32m101\u001b[1;36m, in \u001b[1;35mast_parse\u001b[1;36m\u001b[0m\n\u001b[1;33m    return compile(source, filename, symbol, self.flags | PyCF_ONLY_AST, 1)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"<unknown>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    run_randomForest(X_train_3, X_test_3, y_train, y_test\u001b[0m\n\u001b[1;37m                                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_randomForest(X_train_3, X_test_3, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f79040-9d04-484c-b1c0-cdee5ab4676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_4 = X_train[['who', 'sex','pclass' 'embarked']]\n",
    "X_test_4 = X_test[['who', 'sex', 'pclass', 'embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e4fac-5d2d-486f-9098-5ed218f0fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_randomForest(X_train_4, X_test_4, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac73acc-ada8-4c86-a20c-1c911bbc7e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_4 = X_train[['who', 'sex','pclass' 'embarked','alone']]\n",
    "X_test_4 = X_test[['who', 'sex', 'pclass', 'embarked', 'alone']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb230f22-b421-41f1-aa63-b1bacdead92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_randomForest(X_train_5, X_test_5, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942fde8b-5f9d-42c2-b3e6-32d8de97737b",
   "metadata": {},
   "source": [
    "### Feature Dimension Reduction Using LDA and PCA in Python "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a988527-387f-4257-8d0c-ef1603d79b53",
   "metadata": {},
   "source": [
    "Feature Dimention Reduction Using LDA and PCA with Python | Principal Component Analysis in Feature Selection | KGP Talkie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c7647-d860-44fc-bb36-8b807552bc89",
   "metadata": {},
   "source": [
    "Watch full Playlist : https://www.youtube.com/playlist?list=PLc2rvfiptPSQYzmDIFuqN2PqN2n28ZjxDH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770777d0-c3e9-4e08-8287-82dfe8661391",
   "metadata": {},
   "outputs": [],
   "source": [
    "+ What is LDA (Linear Discriminant Analysis)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdbbbc4-027f-42aa-8887-e65db52dbf39",
   "metadata": {},
   "source": [
    "The idea behind LDA is simple. Mathematically speaking. We need to find a new feature space to project the data in order to maximize classes separability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283c35d4-3f14-4a0d-8501-cf74d4ca8b10",
   "metadata": {},
   "source": [
    "Linear Discriminant Analysis is a surpervised algorithm as it takes the class label into consideration. It is a way to reduce dimensionality while at the same time preserving as much of the class discrimination information as possibe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31777e49-1a88-4acc-a77f-8fb52dc05630",
   "metadata": {},
   "source": [
    "Basically LDA finds a centroid of each class datapoints.\n",
    "It is a way to reduce the dimension and at the same time preserving sms the class distribution formation we want to preserve.It reduces the total line result while maximizing the accuracy\n",
    "\n",
    "+ Why classterize?\n",
    "It reduces the dimension by clustering similar type of information together then maximize the projections between the classes\n",
    "\n",
    "It helps you to find the boundaries around the classes and it projects your data points on a line so that your clusters are seperted as much as possible, with each cluster having a relative distance to the centroid.\n",
    "\n",
    "+ How are these clusters defined and how do we get tp reduce the feature set?\n",
    "\n",
    "Basically LDA finds a centroid of each class datapoints.\n",
    "It is a way to reduce the dimension and at the same time preserving sms the class distribution formation we want to preserve.It reduces the total line result while maximizing the accuracy.\n",
    "\n",
    "\n",
    "For example, with thirteen different features LDA will find the centroid of each of its class using the thirteen different feature dataset. Now on the basis of this.It determines a new dimension which is nothing but an axis which should satisfy two criteria:\n",
    "\n",
    "1. Maximize the distance between the centroid of each class.\n",
    "We can create the maximum number of clusters equal to the total number of classes minus one. For e.g , if our data points have two classes then we can create max. one cluster. and if our data point normality class problem ,if it have 3 or four more than the 2 classes, for the 3 we can create a max of 2 clusters. Similarly ,it is the maximum dimension on the number of conponents will always be less than 1 of the total label number of classes\n",
    "\n",
    "\n",
    "2. Minimize the variation(which LDA calls scatter and its represented by s2), within each category.\n",
    "\n",
    "\n",
    "+What is PCA \n",
    "\n",
    "\n",
    "Principal Component Analysis(PCA) is a linear dimensionality reduction technique that can be utilized for extracitng information from a high-dimensional space by projecting it into a lower-dimensional sub-space .It tries to preserve the essential parts that have more variation of the data and remove the non-esential parts with fewer variation.it tries to maximize the accuracy at the same time.\n",
    "\n",
    "Dimensions are nothing but features that represent the data. For example, A 28 X 28 image has 784 picture elememts(pixels) that are the dimensions of features which together represent that image.\n",
    "\n",
    "\n",
    "One important thing to note about the PCA is that it is unsupervised dimensionally centered  because you dont consider the labels First, you reduce the dimension of the feature then you use surpervised learning tecniques ,then you can apply ML algorithms to do the final classification on reduced dimension of the data.\n",
    "\n",
    "According to the Wikipedia, the PCA is a testical procedure\n",
    "after transformation you use it to convert,accept equal related variable.\n",
    "At the first label,\n",
    "It tries to project the feature space in the dimension where we have the maximum variation. So it tries to project the data in maximun variation , then the second dimension variation and so on.\n",
    "\n",
    "\n",
    "+ When to do the PCA\n",
    "\n",
    "Data Visualization\n",
    "When you want to visualize the data. for e.g we can't visualize the data in the computer if it has more than 3 -dimensions. let's say your data is a 10 Dimension, how will you visualize the data? with the help of the PCA , you can reduce the data into 2-D or 3-D and you can visualize it. This can be the transformed data. But you can atleast understand the concept and it is correlated.\n",
    "\n",
    "+ Speeding Machine Learning (ML) Algorithm\n",
    "\n",
    "We use it to speed upour ML algorithm. Let's say you have 300 dimensions of your data. You can reduce the dimension into 2 dimension\n",
    "\n",
    "+ How to do PCA\n",
    "\n",
    "We can calculate a principal Component Analysis on a dataset using the PCA()class in the scikit-learn library. The benefit of this approach is that once the projection is calculated ,it can be applied to new data again and again quite easily.\n",
    "hence, the ML library scikit-learn has made our job very easy.\n",
    "\n",
    "When creating the class, the number of components can be specified as a parameter.\n",
    "\n",
    "The class is first fit on a dataset by calling the fit()function, and then the original dataset or other data can be projected into a subspace with the chosen number of dimensions by calling the transform() function.\n",
    "\n",
    "\n",
    "Once fit, the elgenvalues and principal components can be accessed on the PCA class via the explained_variance and components_attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9bf7f6f-616b-469c-8a7c-baf40c68c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3bcda29-de0c-4581-a58c-bd0709ec67cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ff734b6-a050-4f3f-8b7c-ff1f769f762c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "3   8     2     37                 0.0                    195.0   \n",
       "4  10     2     39                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                    195.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "0                      0.0                      0.0  ...   \n",
       "1                      0.0                      0.0  ...   \n",
       "2                      0.0                      0.0  ...   \n",
       "3                      0.0                      0.0  ...   \n",
       "4                      0.0                      0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "3                      0.0                      0.0                     0.0   \n",
       "4                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "3                     0.0                      0.0                      0.0   \n",
       "4                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                     0.0                     0.0   39205.170000       0  \n",
       "1                     0.0                     0.0   49278.030000       0  \n",
       "2                     0.0                     0.0   67333.770000       0  \n",
       "3                     0.0                     0.0   64007.970000       0  \n",
       "4                     0.0                     0.0  117310.979016       0  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\user\\\\Downloads\\\\santander-train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b71229-96a2-4560-b6b0-3c5549a3c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the last column is the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "005b6469-1bb8-4c2e-8c3f-7582f670b097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76020, 370), (76020,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop('TARGET', axis = 1)\n",
    "y = data['TARGET']\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c03d4944-99f1-4718-821c-4b1b8cfba37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state =0,stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8eba55-58c1-48e6-be88-e23a6b96a8b1",
   "metadata": {},
   "source": [
    "##### Remove Constant,Quasi Constant and Duplicate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4850b75c-9ebd-48ca-95da-91f763ef4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove constant and quasi constant features\n",
    "constant_filter = VarianceThreshold(threshold=0.01)\n",
    "constant_filter.fit(X_train)\n",
    "X_train_filter = constant_filter.transform(X_train)\n",
    "X_test_filter = constant_filter.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ad97519-065c-4e19-ba2a-0c7d1bc1ce82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60816, 274), (15204, 274))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_filter.shape, X_test_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "929800e8-16fb-40bf-934e-b5c4e7827e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate features\n",
    "X_train_T = X_train_filter.T\n",
    "X_test_T = X_test_filter.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18e24c83-10c3-4f51-9f01-237ec4a10db9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10104/3695243745.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_train_T\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_T\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_test_T\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mPd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_T\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Transpose data from rows to column and columns to rows\n",
    "X_train_T  = pd.DataFrame(X_train_T)\n",
    "X_test_T   = Pd.DataFrame(X_test_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85ffaa99-2e9f-4cbc-b677-eb873b330d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It takes a little time to load\n",
    "X_train_T.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf915a02-49e5-42a4-b304-eaa59b752983",
   "metadata": {},
   "outputs": [],
   "source": [
    "diplicated_features = X_train_T.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6996da55-696d-4740-94fb-52b2240ac46b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'duplicated_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10104/1497313483.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeatures_to_keep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mduplicated_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_train_unique\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train_T\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures_to_keep\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_test_unique\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test_T\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures_to_keep\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'duplicated_features' is not defined"
     ]
    }
   ],
   "source": [
    "features_to_keep = [not index for index in duplicated_features]\n",
    "\n",
    "X_train_unique = X_train_T[features_to_keep].T\n",
    "X_test_unique = X_test_T[features_to_keep].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34716a05-009d-4069-aad8-7df06931fdea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_unique' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10104/886064630.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_unique\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_train_unique\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_unique\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_test_unique\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_unique\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_unique' is not defined"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(X_train_unique)\n",
    "X_train_unique = scaler.transform(X_train_unique)\n",
    "X_test_unique  = scaler.transform(X_test_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a7227b9-cf37-48eb-9f5c-ff5999a18cac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_unique' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10104/1134234906.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train_unique\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_unique\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test_unique\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_unique\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_unique' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_unique = pd.DataFrame(X_train_unique)\n",
    "X_test_unique =  pd.DataFrame(X_test_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c487d06-e31a-4549-91fa-145a9378e169",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_unique' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10104/2423776958.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train_unique\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_unique\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_unique' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_unique.shape, X_test_unique.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9992c5c-208b-44e4-83eb-0c6df587fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Removal of correlated Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a699810-e2bd-4339-98d1-0441e0c2088f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_unique' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10104/1069358516.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcorrmat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train_unique\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_unique' is not defined"
     ]
    }
   ],
   "source": [
    "corrmat = X_train_unique.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b466a283-4e7f-465f-92b0-7adb7db9c510",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corrmat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10104/241410997.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# To get the shape of the corr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcorrmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'corrmat' is not defined"
     ]
    }
   ],
   "source": [
    "# To get the shape of the corr\n",
    "corrmat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5d4c2b-a743-4e8d-bb20-f588038c5563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find correlated features\n",
    "def get_correlation(data, threshold):\n",
    "    corr_col = set()\n",
    "    corrmat = data.corr()\n",
    "    for i in range(len(corrmat.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corrmat.iloc[i, j]) > threshold:\n",
    "                colname = corrmat.columns[i]\n",
    "                corr_col.add(colname)\n",
    "    return corr_col\n",
    "\n",
    "corr_features = get-corrlation(X_train_unique, 0.70)\n",
    "print('correlated features: ', len(set(corr_features)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5aa655-4291-495f-97bc-39f06a8bcab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_uncorr = X_train_unique.drop(labels=corr_featues, axis = 1)\n",
    "X_test_uncorr = X_test_unique.drop(labels=corr_featues, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b26e44d-a9d3-4825-b1f0-42738e77ae31",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_uncorr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10104/2026844609.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train_uncorr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_uncorr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_uncorr' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_uncorr.shape, X_test_uncorr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d45561c-598e-47f1-beb5-0b9137e4dc54",
   "metadata": {},
   "source": [
    "##### Feature Dimension Reduction by LDA or Is it a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2c9640cf-327d-4f8b-b3c8-0357b86fd11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d0c1a08f-507e-45d3-ac68-bc588c2e370d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_uncorr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10104/2047237725.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train_lda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_uncorr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_uncorr' is not defined"
     ]
    }
   ],
   "source": [
    "lda = LDA(n_components=1)\n",
    "X_train_lda = lda.fit_transform(X_train_uncorr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357773a4-521b-457b-bd6c-efe13c1a0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check the shape and dimension\n",
    "# the dimensio of the datawill always be 1\n",
    "X_train_lda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d966e08f-a645-4306-9535-af0ed3e67301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test dataset based on the trained dataset\n",
    "X_test_lda = lda.transform(X_test_uncorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03889341-661e-4f65-8122-f3f2d5400f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_randomForest(X_train, X_test, y_train, y_test):\n",
    "    clf =RandomForestClassifier(N_estimators=100, random_state=0, n_jobs=-1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('Accuracy on test set: ')\n",
    "    print(accuracy_score9y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be4b4ac-f9e1-4319-b13e-b3525ca21e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_randomForest(X_train_lda, X_test_lda, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b5b6320c-cc81-4005-802c-f89e78a54e98",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (Temp/ipykernel_10104/1475238861.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_10104/1475238861.py\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    run_randomForest(X_train, X_test, y_train, y_test\u001b[0m\n\u001b[1;37m                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# lets run this on the original dataset to see the accuracy score\n",
    "%%time\n",
    "run_randomForest(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6094e27c-32b6-47fd-9d7e-96882d4cc60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observation, training time for the transformed datasetbis more than that of the original dataset\n",
    "# The dimension of the original dataset is 370 btut for th etransforme it has just a single dimension\n",
    "# LDA does not guantee increase in accuracy but it greatly reduces the dimension\n",
    "# hence ,it helps to speed up our ML algorithm and visualize our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2444aee8-dcd9-47c1-a6f4-51b125cd132b",
   "metadata": {},
   "source": [
    "#### Feature Reduction by PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f4b7feb7-9c7d-4ec9-ab4b-2c737422fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature reduction with PCA to see how much accuracy we can get\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08d934c-5fd1-4af0-afad-fadfb98e91f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2, random_state=42)\n",
    "# pca = PCA(n_components=3, random_state=42)\n",
    "pca.fit(X_test_uncorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec8ff09-06d0-4cce-8307-d8ce82d0114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca.transform(X_train_uncorr)\n",
    "X_test_pca = pca.transform(X_test_uncorr)\n",
    "X_train_pca.shape,= X_train_uncorr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46abb0cd-b62b-40b2-ac30-2b5be93dfe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking accuracy usin 2 components\n",
    "%%time\n",
    "run_randomForest(X_train_pca, X_test_pca, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22079bea-3f02-4f16-abdf-6fc8b59ddc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation, i a win win situation, training time has reduced and the accuracy score have increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e0f10-b14b-460b-b4b0-5c90a90d2c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking accuracy using 3 components , we noticed that the accuracy has increased\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac75c9-175c-4808-9867-3bebd829a0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to check al the number of products accuracy for the pca\n",
    "# achieve tis you can use a for loop or greek search\n",
    "for component in range(1, 79):\n",
    "pca = PCA(n_components=component, random_state=42)\n",
    "pca.fit(X_test_uncorr)\n",
    "X_train_pca = pca.transform(X_train_uncorr)\n",
    "X_test_pca = pca.transform(X_test_uncorr)\n",
    "print('Selected Comp: ', component)\n",
    "run_randomForest(X_train_pca, X_test_pca, y_train, y_test)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d9eed2-51b4-46bd-9ff0-6cc87ecbb9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We observed that the higher the component the higher the acuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f2d59-c50e-4328-8e66-d35f8c6fb771",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\user\\\\Downloads\\\\santander-test.csv\", nrows = 20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d8f00d-5dc6-47a7-a459-491715b5dec3",
   "metadata": {},
   "source": [
    "#### Dimensionality Reduction: Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097e07ae-5717-41b2-a420-c04861648d50",
   "metadata": {},
   "source": [
    "1. ___Dimensionality reduction________________________ is simply the process of reducing the dimension of\n",
    "your feature set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f71011-e12d-48f8-9d36-c13d543bd446",
   "metadata": {},
   "source": [
    "2. An example of a feature set is ___Dataset___________________."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9b65f6-fc83-4d10-82a6-d60cef0ca77e",
   "metadata": {},
   "source": [
    "3. _____________________ refers to all the problems that arise when working with\n",
    "data in the higher dimensions that did not exist in the lower dimensions.\n",
    "\n",
    "Curse of dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8610e73-057d-41f8-b0a3-eaead002d4e7",
   "metadata": {},
   "source": [
    "The curse of dimensionality refers to various phenomena that arise when analyzing and organizing data in high-dimensional spaces that do not occur in low-dimensional settings such as the three-dimensional physical space of everyday experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9359512a-2812-4bf3-83b5-622f9dafd4fb",
   "metadata": {},
   "source": [
    "4. What is a major motivation for performing dimensionality\n",
    "reduction?\n",
    "\n",
    "Avoiding overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c1b0e8-30a1-4456-8781-4e7bf2dbc109",
   "metadata": {},
   "source": [
    "5. What is feature selection?\n",
    "\n",
    "Identifying and selecting relevant features for a sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2556f6fe-8b95-4972-93dd-139dd5e13e41",
   "metadata": {},
   "source": [
    ". Feature selection can be done either manually or programmatically. This statement is wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca37f4a-7827-4dce-a65e-ea9d10184a12",
   "metadata": {},
   "source": [
    "7. Two programmatic methods for feature selection are?\n",
    "Variance threshold and univariate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7d365b-aa2e-4157-91e6-53e713945810",
   "metadata": {},
   "source": [
    "Variance threshold and univariate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1eef97-0ece-4a5e-91bb-e9b774bef4e2",
   "metadata": {},
   "source": [
    "8. _Univariate________________________ feature selection examines each feature individually to determine the strength of the relationship of the feature with the response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d0ccc3-266f-4d2f-b673-d3b865dab2fd",
   "metadata": {},
   "source": [
    "Univariate feature selection examines each feature individually to determine the strength of the relationship of the feature with the response variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe003c5e-defd-41e6-8de0-156277503657",
   "metadata": {},
   "source": [
    "9. Which of these is NOT a type of linear dimensionality reduction methods?\n",
    "\n",
    "rincipal Component Analysis\n",
    "Factor Analysis\n",
    "Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49b9d78-adcd-486a-8163-23c581c578e2",
   "metadata": {},
   "source": [
    "10. Which of these is a type of non-linear dimensionality reduction methods?\n",
    "\n",
    "t-distributed Stochastic Neighbor Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dbe759-42f4-4683-b67c-de5f2a30c340",
   "metadata": {},
   "source": [
    "Kernel PCA, t-distributed Stochastic Neighbor Embedding (t-SNE), Multidimensional Scaling (MDS) and Isometric mapping (Isomap) are examples of non-linear dimensionality reduction methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf28bb8-23cc-46f7-8ed6-533e4b6dcc08",
   "metadata": {},
   "source": [
    "###\n",
    "‎Cluster analysis algorithms · Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters). It is a main task of exploratory data analysis, and a common technique for statistical data analysis, used in many fields, including pattern recognition, image analysis, information retrieval, bioinformatics, data compression, computer graphics and machine learning.‎Hierarchical clustering · ‎Dbscan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632224cf-4d13-4098-8a8a-4b04f572ce85",
   "metadata": {},
   "source": [
    "eg of clustering K-means\n",
    "\n",
    "you must explore all possible options \n",
    "clistering skills is used mostly in data science\n",
    "\n",
    "Application of clusterring\n",
    "for a company\n",
    "market segmentation\n",
    "using  a scatter plot\n",
    "young people that spend alot\n",
    "young people who dont spend alot\n",
    "middle people who spend alot\n",
    "middle\n",
    "benefits\n",
    "explore data and identify patterns\n",
    "pleliminary step\n",
    "used to draw conclusion\n",
    "\n",
    "image segmentation\n",
    "\n",
    "To enable you have a better pictorial view\n",
    "16,777,216 photos\n",
    "\n",
    "object recognition\n",
    "\n",
    "it helps machines to identify the world around them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2435d79c-104c-4012-8c95-5ebc974feacb",
   "metadata": {},
   "source": [
    "difference between classification and clustering\n",
    "\n",
    "+ Classification and clustering are techniques used in data mining to analyze collected data. Classification is used to label data, while clustering is used to group similar data instances together based on similarities among them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d92d7eb-d4e8-4e1d-93ba-b054c8e9d1f9",
   "metadata": {},
   "source": [
    "You must know how to measure the distance between them called eucledian distance you need to fing the angle between them\n",
    "\n",
    "it is called centroid\n",
    "\n",
    "the square root of the sum of the square distance of the diferences\n",
    "\n",
    "we will be finding the distance between clusters\n",
    "\n",
    "\n",
    "centroid is the mid point of the line between them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f569e2d4-08c2-41b7-962a-2acc44a446e5",
   "metadata": {},
   "source": [
    "K-mean Clustering\n",
    "\n",
    "\n",
    "k-means clustering is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid), serving as a prototype of the cluster. This results in a partitioning of the data space into Voronoi cells. k-means clustering minimizes within-cluster variances (squared Euclidean distances), but not regular Euclidean distances, which would be the more difficult Weber problem: the mean optimizes squared errors, whereas only the geometric median minimizes Euclidean distances. For instance, better Euclidean solutions can be found using k-medians and k-medoids."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf831d3-3593-451b-9302-f6448a144b89",
   "metadata": {},
   "source": [
    "Clustering is used in unsupervised learning\n",
    "\n",
    "classification is used in surpervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1081e3-84e4-4830-9910-69526880147e",
   "metadata": {},
   "source": [
    "Application of clustering \n",
    "\n",
    "K-means clustering \n",
    "k is the no\n",
    "choose the number of clusters\n",
    "specify  the cluster seeds\n",
    "\n",
    "assign each point to a centoid ie closert to the seed\n",
    "adjust the centoid\n",
    "\n",
    "recalculate the centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16771209-0e5f-48bf-8d37-8d2815c9116f",
   "metadata": {},
   "source": [
    "Unsupervised learning\n",
    "\n",
    "Clustering \n",
    "\n",
    "dimentionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc33ad87-2e55-40a3-8d03-377520f8cf89",
   "metadata": {},
   "source": [
    "itirative means repeatitive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeae4f8d-8061-40b6-ad8b-3c56267b56de",
   "metadata": {},
   "source": [
    "k-means has two types\n",
    "\n",
    "elbow method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a45904-8a40-4287-8f9c-e88d822e557d",
   "metadata": {},
   "source": [
    "A row is a horizontal alignment of data, while a column is vertical. D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d3256-5480-4a26-85dd-35975c625ca5",
   "metadata": {},
   "source": [
    "### Week 12: Day 2 – K-means Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3414d9d1-6e81-4b83-b590-ec0ead3833b6",
   "metadata": {},
   "source": [
    "#### Introduction to Cluster Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e6e8a7-62c7-4c8b-b5d6-d7e491146841",
   "metadata": {},
   "source": [
    "Cluster Analysis is a multivariate statistical technique that groups observations on the basis of some of their features or variables they are described by.\n",
    "\n",
    "Intuitively speaking , observations in a dataset can be divided into different groups and sometimes this is very useful. Let's quickly explore an example . Here is a list of 6 countries: \n",
    "USA\n",
    "FRANCE\n",
    "GERMANY\n",
    "UNITED KINGDOM\n",
    "AUSTRALIA\n",
    "CANADA\n",
    "\n",
    "Thes are our observations, imagine we have already performed the mysterious technique called Cluster Analysis and we got 3 groups:\n",
    "\n",
    "USA and CANADA - Cluster 1\n",
    "\n",
    "the second group  -- Cluster 2\n",
    "FRANCE\n",
    "GERMANY\n",
    "UNITED KINGDOM\n",
    "\n",
    "The third group  - Cluster 3\n",
    "AUSTRALIA\n",
    "\n",
    "We will call these three groups clusters\n",
    "\n",
    "After a short climse of the 3 clusters we can easily name them. The first one shows countries in north America\n",
    "\n",
    "The second shows those iin Europe and the third on shows a country in the continent of Australia.\n",
    "\n",
    "Obviously, the feature in which this country was clustered is called geographic proximity. This is cluster analysis in a nut shell.\n",
    "\n",
    "Moreso, we can take thesema data and cluster them into 2 clusters. One result may be the following:\n",
    "\n",
    "Cluster 1\n",
    "USA  \n",
    "CANADA - Cluster 1\n",
    "FRANCE\n",
    "GERMANY\n",
    "UNITED KINGDOM\n",
    "\n",
    "Cluster 2\n",
    "AUSTRALIA\n",
    "\n",
    "\n",
    "The first one shows countries in the northern hemisphere\n",
    "\n",
    "The second shows those in the southern hemisphere\n",
    "\n",
    "What if after dividing the observation in two clusters \n",
    "\n",
    "We obtain the result below instead\n",
    "\n",
    "\n",
    "Cluster 1:\n",
    "\n",
    "USA  \n",
    "\n",
    "CANADA \n",
    "\n",
    "UNITED KINGDOM\n",
    "\n",
    "AUSTRALIA\n",
    "\n",
    "Cluster 2\n",
    "FRANCE\n",
    "GERMANY\n",
    "\n",
    "In the\n",
    "USA \n",
    "CANADA\n",
    "UNITED KINGDOM\n",
    "AUSTRALIA\n",
    ", English is an official language while ingermany and french it is not.This is a fundamentally different clustering  solution.Both result are perfectly logical but in a different way.In the first two cases we are differentiating the clusters by geograpgic proximity while in the second by language.Geographic proximity and language are two differnt features ,which we can cluster the observations. That is to say that cluster analysis is extremely intuitive but difinitely tricky . After this brief example, the final goal of clustering is to maximize the similarity of observations within a cluster and maximize the dissimilarity between clusters . This is done with some feature or features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba05858-0dd2-44e7-a6bd-2a3b0c03124f",
   "metadata": {},
   "source": [
    "Course outline:\n",
    "\n",
    "+ We will explore several clustering problems\n",
    "\n",
    "+ We will learn how to perform cluster analysis\n",
    "\n",
    "+ How to find the optimal number of clusters \n",
    "\n",
    "+ How to identify appropriate features\n",
    "\n",
    "+ How to interprete the results.\n",
    "\n",
    "Our main tool will be the sklearn and pandas packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9436353-ea92-43b3-abdf-292ec54ec0ea",
   "metadata": {},
   "source": [
    "#### Some examples of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75948a36-3f03-434f-ace7-d24e9936a079",
   "metadata": {},
   "source": [
    "+  Why is clustering useful?\n",
    "\n",
    "We already know tht USA is in NORTH AMERICA and GREMANY in EUROPE.\n",
    "\n",
    "\n",
    "There are many applications of clustering.\n",
    "\n",
    "+ Market Segmentation\n",
    "\n",
    "+ Image Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181830e2-167f-4272-968e-7fc2ac00cecf",
   "metadata": {},
   "source": [
    "+  Market Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d0dd0b-c268-4a76-99f9-22f559c2a0d1",
   "metadata": {},
   "source": [
    "Imagine a retail chain that sells clothing, its marketing campaign has been disaatrous for the  past few years .You are appointed as the data scientist . The firm gives you all the data they have gathered and gives you green light to create the next marketing campaign.You have no idea who buys the product so you decide to create a scatter plot of all customers depending on the amount of money they spend and their age.\n",
    "\n",
    "The result is the following:\n",
    "\n",
    "Cluster analysis allows you to identify four big clusters.\n",
    "\n",
    "i, Young peolpe who spend alot and \n",
    "\n",
    "ii.Young people who spend a little bit.\n",
    "\n",
    "iii.Middle age people who spend alot \n",
    "\n",
    "iv.and the ones that doesnt spend much.\n",
    "\n",
    "What you have done with this clusters is to identify the target customers.\n",
    "\n",
    "There aren't many older people who are clients, moreover most of the data points are middle aged people who spend alot.\n",
    "\n",
    "That's most probably who we will earn the marketing at.\n",
    "\n",
    "+ i. Clustering Analysis:\n",
    "\n",
    "Clustering is often used as a preliminary step of all type of analysis.It is a very useful technique for exploring and identifying patterns in the data. Dta Scientist often turn to it when they have no idea where to start or what to expect. Cluster anlysis is where \n",
    "\n",
    "+ ii.Other type of analysis\n",
    "\n",
    "It is a method used in drawing conclusion but as we already mentioned .it is a great starting point. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba6061a-d151-4939-9cd6-f03bd8bffba2",
   "metadata": {},
   "source": [
    "+ Image Segmentation\n",
    "\n",
    "A more interesting and more visual example is image segmentation.It helps to segment elements in different colours. each color represents a different cluster.\n",
    "\n",
    "In the first photo, we had 3 clusters:\n",
    "\n",
    "White , Beige and Dark, it is vague because the dog is blending with the ground.\n",
    "\n",
    "in the second one we had 10 clusters or 10 colors,. There is already enough details to see if it is a dog laying on the ground. \n",
    "Moreover the colot=r of the vandana to the big enough cluster to actually preserve its blue color as a seperate cluster.\n",
    "\n",
    "In the 3rd photo, we have 30 clusters , although it seem like a small inprovement, there are 3 times more colors than the second one.We can see details of ear and different colors from afar.\n",
    "\n",
    "Notice that in the RGB color model, there are 16,777,216 possible colors. To reproduce a whole image , we will need that many clusters.\n",
    "\n",
    "That does not mean that the color will be perfect,some may blend and other may be reversed.\n",
    "\n",
    "We just turned a 17,000,000 color photo into one with 3, 10 or 30 colors. Such simplicity implies smaller size and we have compressed the photo.That is one of the ses of clustering \n",
    "\n",
    "\n",
    "For a short period of time , we thought that clustering can be used for object recognition ,computer vision,while it looks alright ,there are some problems with it.\n",
    "\n",
    "So clustering is made a way for better technique which have been developed to help machines detect the world around them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a041b20-09e8-4159-b687-759d8e8dac1b",
   "metadata": {},
   "source": [
    "In all our courses ,we will focus on the business implementation of our techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbf3a97-7f64-410b-93d3-66150a3e4b3f",
   "metadata": {},
   "source": [
    "#### Difference between classification and clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2bcd4e-d4b6-4f0a-b0d5-b056419566e0",
   "metadata": {},
   "source": [
    "When we discussed Linear and Logistic Regression, we said in the ML contest we will call them Regression and Classification.The both approach is used in Supervised learning . The defining trade of supervised learning is thatw e are dealing with labelle data.\n",
    "\n",
    "Labelled data means that we know the correct values for labells prior to creating the model .Then ,we create a model which fits the data as well as possible. the idea to deploty it on feature data. \n",
    "Model(inputs) -> Outputs -> Correct values for outputs\n",
    "\n",
    "In classification, one of the examples is to predict if a student will be in medical college base on SAT or Gender.\n",
    "\n",
    "Logit(SAT, Gender) -> Predictions -> Admitted data.\n",
    "\n",
    "We had 1's and 0's corresponding to each student.\n",
    "\n",
    "There were two classess: 1 and 0, Admitted and not Admitted.\n",
    "\n",
    "+ Clustering seems similar but infact very different.\n",
    "\n",
    "When we use cluster analysis,we dont have labels. In the context of ML it i scalled Unsupervised learning.We cluster the observations in differnt groups but we have no clue if these clussters are A- the right, number B- correct at all and  c- useful whatsoever.\n",
    "\n",
    "Moreover the output we get is something we must name ourselves. Let's check out the scatter plot from the same SAT and Gender example, We identify two clusters , male and female. It is kind of pointless because we already have some information.  We have another way to look at it.We can put a cut off line on the graph and tag it Good students and bad students in another cut of line. But this is not the real discovery. Obviosly cluster analysis is futile in this situation. It does not provide any real insight. That is why there are differnt approaches to different insights.\n",
    "\n",
    "In summary, Classification problem is predicting an output category given input data, train the model on the training data and then use it to predict future outcomes.  Clustering is about grouping data points together based on similarities among them and difference from others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c58de3f-d66a-4867-873f-88a0c170963f",
   "metadata": {},
   "source": [
    "#### Math prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8fffa0-bb2e-4672-b81e-bebb0278f2fc",
   "metadata": {},
   "source": [
    "There are two prerequisite required to unserstand this clustering technique.\n",
    "\n",
    "i. we must knw how to measure the distance between two data points \n",
    "\n",
    "ii. and we have to define the term centroid .\n",
    "\n",
    "Let's start from distance, we can see two data points at a plane. The co ordinates are (3,4.5 ) and (10,2.5). The most intuitive way to measure the distance between them is by drawing a straight line from one to the other. This is also known as Euclidean distance.\n",
    "\n",
    "The question is how to fine that distance.The easiest way to do that is to creat a right triangle. One side have a length of 10 - 3 = 7 , the other side has a size of 4.5 -2.5 = 2. Next we can use the pythagoran theory and find th 3rd side.It is the squareroot of 7^2 + 2^2\n",
    "\n",
    "the result is 7.28, ie √ 7^2+2^2 = 7.28\n",
    "Therefore the distance betwen the two points is 7.28 units. Can we parametirize this?\n",
    "\n",
    "say the co ordinate of the two points are (x1,y1) and (x2y2).\n",
    "\n",
    "In this case , the size of the triangle are the absolute values of the differences between the x's and the y's, then following the pythygoran , the Euclidaen distance between the points is the √root of the sum of the squared differences, this is also the Euclidean distance formula.  √(x1 - x2)2 + (y2-y1)2.\n",
    " \n",
    "While we are still here, let's generalze the notion to N- dimensional space. In 2 dimensional space, the distance between two points A and B is the √root of the sum of the  square of the differences of the the two coordinates for each point.\n",
    "2D space : d(A,B) = d (B,A) = √ ((x1 - x2)2 + (y2-y1)2.\n",
    "\n",
    "\n",
    "similarly in 3 dimensional space , we have the square root of the sum of the squares of the differences.But htis time ,we have all 3 coordinates.\n",
    "\n",
    "3D space : d(A,B) = d (B,A) = √ ((x1 - x2)2 + (y2-y1)2 +(z2-z1).\n",
    "\n",
    "In n dimensional space we will have the same formula but along each of the n- axis\n",
    "\n",
    "If the coordinates of A are (a1,a2,....an) and of B are (b1,b2, ....bn)\n",
    "\n",
    "N.dim space : d(A,B) = d (B,A) = √ ((a1 - b2)2 + (a2-b1)2 + ...+  +(an-bn)2. \n",
    "\n",
    "we need this concept for two reason \n",
    "\n",
    "i.When performing clustering we will be finding the distance between clusters . If we work in n dimensional space, we must know how to measure the distance.\n",
    "\n",
    "ii. In the next section ,this will be a central notion.\n",
    "\n",
    "+ Centroids : This is a mean posseession of a group of point. In pyhsics this is known as the center of mass. For our two points the centroid is the mid point of the line which connects them. For 3 points, it will be somewhere between them as shown in the graph. for 100 points. it will be at the center as shown in the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33acb8aa-2320-44b9-a15d-df03c11a7cf6",
   "metadata": {},
   "source": [
    "#### K-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cc93e1-91ce-4c1b-99a7-75c053612dc7",
   "metadata": {},
   "source": [
    "There are two dimensions or 2 features in  which we are performing clustering . for instance the age and money spentfron our earlier example.\n",
    "\n",
    "Certainly it made no sense to have only one cluster so we can zoom in to iedntify more clusters.\n",
    "How do we perform clustering in practice?\n",
    "\n",
    "There are different methods we can apply to identify clusters.The most popular one is \"K- MEANS CLUSTERING\"\n",
    "We can simplify the scatter plot to 15 points so that we an get a better graph and see what happens.\n",
    "\n",
    "+ This is how K_Means works:\n",
    "\n",
    "+ 1. Choose the number of clusters you want to have.\n",
    "K stands for the number of clusters we are trying to identify.we will start with 2 clusters.\n",
    "\n",
    "+ 2. Specity the Cluster seeds:\n",
    "A seed is basially is basically a starting centroid. It is choosen at random or specified by the data scientist with some prior knowledge about the data. On eo fthe clusters ii s a green cluster, the other one the orange cluster. These are the seeds.\n",
    "\n",
    "+ 3. Assign each point to a centoid \n",
    "you need to asign each point on the graph to a seed .\n",
    "This is done based on proximity. For instance,This point is close to the green seed than the orange one , therefore, it will move to join the green cluster. The other point is close to the orange seed,hence, it wil be a part of the orange cluster.\n",
    "\n",
    "In this way we can colour all points on the graph basedd on their Euclidean distance fro m the seeds.\n",
    "\n",
    "+ 4. Adjust the centroids\n",
    "\n",
    "Calculate the centroids of the green point and the orange point. the green seed will move closer to the green point to become the centroid and the orange will do thesame fo the orange point.\n",
    "From here ,we will repeat the last two steps.\n",
    "\n",
    "Let.s recalculate the distances.\n",
    "\n",
    "All the green points are obviously close to the green centroid and the orange point close to the orange centroid.\n",
    "\n",
    "After this we still have two more close to the green point ,sowe wil reassign them to the green centroid.\n",
    "Finally, we must recalculate the centroid to get a new result.\n",
    "\n",
    "Now all the green points are closer to the gren centroid and the orange one to the orange.\n",
    "\n",
    "We can no longer re-assign points which completes the clustering process. This is a two cluster solution.\n",
    "\n",
    "We do the same if we want to have 3 clusters or more.\n",
    "\n",
    "K- Means is an iterative process so we go back to the step where we associate each of the points with the closest seed.\n",
    "\n",
    "All orange points are settled so no movemment there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abb0662-169a-40be-902c-c0543c341acd",
   "metadata": {},
   "source": [
    "#### A simple example of clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b9e7b4-353e-4c7a-b51b-6f3d640736e8",
   "metadata": {},
   "source": [
    "Remember in the first example we used 6 countries.\n",
    "\n",
    "USA\n",
    "\n",
    "CANADA\n",
    "\n",
    "UNITED KINGDOM\n",
    "\n",
    "AUSTRALIA\n",
    "\n",
    "FRANCE \n",
    "\n",
    "GERMANY\n",
    "\n",
    "We are going to cluster this countries using K- Means.\n",
    "We will learn a couple of nice tricks along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f921e60a-e97e-4a18-ae5b-a2c0f537c2c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Basics of cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "651c3a03-c097-4bb3-aa3f-4d03c61fc707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59834636-7975-4137-996e-a7ef45a89d59",
   "metadata": {},
   "source": [
    "+ Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bdbc838-8f94-47bd-bd43-fd68e6590b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set() # to set the style of all graph to the seaborn 1\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17af9044-406a-4256-8cf1-a6e121547386",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f206502-d898-4c98-827b-583bd81c968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\user\\Desktop\\3.01. Country clusters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83e985bf-d32b-4689-979f-7bd10e978e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USA</td>\n",
       "      <td>44.97</td>\n",
       "      <td>-103.77</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Canada</td>\n",
       "      <td>62.40</td>\n",
       "      <td>-96.80</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>France</td>\n",
       "      <td>46.75</td>\n",
       "      <td>2.40</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UK</td>\n",
       "      <td>54.01</td>\n",
       "      <td>-2.53</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>51.15</td>\n",
       "      <td>10.40</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Australia</td>\n",
       "      <td>-25.45</td>\n",
       "      <td>133.11</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country  Latitude  Longitude Language\n",
       "0        USA     44.97    -103.77  English\n",
       "1     Canada     62.40     -96.80  English\n",
       "2     France     46.75       2.40   French\n",
       "3         UK     54.01      -2.53  English\n",
       "4    Germany     51.15      10.40   German\n",
       "5  Australia    -25.45     133.11  English"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb014307-d26e-4ca7-b7aa-aff2af8480e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have latitude, longitude, language and country. Let's see how we gathers the data\n",
    "# Country and language values are clear, what about the longitude and lagtitude values. The longitude and latitude corrresponds to the geographic centers of the countries in our dataset\n",
    "# That is one way to represent location\n",
    "# Example, if you google geographic center of US, you will get a wikepeia article indicating it to be some point i south dakota with a lat of 44 degrees 58' mins  02\" secs north and a longitude of \n",
    "# of 103 degrees 46'mins 17\" secs west. Then we can convert them to decimal degrees using some online converterlike the one provided by latlon.net, it s  imporatnt to note that th convention is \n",
    "# such that north and east are positive, while west and south are negative.\n",
    "# with this we got the decimal decrees of the geographic centres of the countries in the sample, that is not optimal as the choice of south decorder was biased by lasgan ,Hawaii but it will\n",
    "# not matter too much for the clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ad9d8-4103-467f-9e1d-0e88539f720f",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04dcfce8-e0a9-44bd-94fd-5410cdeb4e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD7CAYAAACPDORaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAaqElEQVR4nO3df3CT9QHH8XfbtFVovWpNiLpaD9zJhoN5VqXqEdlhaUxDpdI7lIHO8wpu6zo29QqbMn8gxbFr5w+GN72xId6UDVrpNVVPbRlXTq/cRAXhPAaICG2gzFIsJW2e/aFkFlqapCHN8/h5/UWePsn38zzAJ0+/yfM8SYZhGIiIiCUlj3QAERE5d1TyIiIWppIXEbEwlbyIiIWp5EVELEwlLyJiYSp5ERELs410gNMdPXqcYDA+X93Pzs7gyJGuuIwVa2bNbtbcYN7sZs0N5s0ez9zJyUlceOHoQX+ecCUfDBpxK/lT45mVWbObNTeYN7tZc4N5sydKbk3XiIhYmEpeRMTCVPIiIhamkhcRsTCVvIiIhQ2r5Ovq6vB4PHg8HpYvXw5AS0sLXq+XgoICqqurYxJSRESiE3XJd3d3s3TpUtasWUNdXR2tra28/fbbLF68mJUrV9LQ0MBHH31Ec3NzLPOKiEgEoi75vr4+gsEg3d3d9Pb20tvbS0ZGBrm5ueTk5GCz2fB6vTQ2NsYyr4iIRCDqk6EyMjKoqKjA7XZz/vnnc91119He3o7dbg+t43A4aGtri0lQERGJXNQlv3PnTv75z3/yzjvvkJmZyQMPPMDevXtJSkoKrWMYRr/H4cjOzog2UlTs9sy4jhdLZs1u1txg3uxmzQ3mzZ4ouaMu+c2bN5Ofn092djYAJSUlvPjii6SkpITW8fv9OByOiF73yJGuuJ0ObLdn4vcfi8tYsWbW7GbNDebNbtbcYN7s8cydnJx01oPjqOfkx48fT0tLC19++SWGYfD2228zadIk9uzZw759++jr66O+vp4pU6ZEO4SIiAxT1EfyN998Mzt27KCkpITU1FR+8IMfUF5ezk033UR5eTk9PT24XC4KCwtjmVdERCKQZBhGYlwq7WuargmPWbObNTeYN7tZc4N5s1tiukZERBKfSl5ExMJU8iIiFqaSFxGxMJW8iIiFqeRFRCxMJS8iYmEqeRERC1PJi4hYmEpeRMTCVPIiIhamkhcRsTCVvIiIhUV9qWEZeVu2H2J9826OdPaQfUE6Ja5x5E9wjnQsEUkgKnmTatq6n7/6dnKyNwjAkc4e/urbCaCiF5GQYU3XvP3225SUlOB2u3niiScAaGlpwev1UlBQQHV1dUxCypn+5vs4VPCnnOwNsr559wglEpFEFHXJ79+/nyVLlrBy5Upee+01duzYQXNzM4sXL2blypU0NDTw0Ucf0dzcHMu88rXDR7sHXH6ksyfOSUQkkUVd8m+++Sa33XYbTqeT1NRUqqurOf/888nNzSUnJwebzYbX66WxsTGWeeVrF194/oDLsy9Ij3MSEUlkUZf8qZt1L1iwgOLiYl5++WXa29ux2+2hdRwOB21tbTEJKv3Nc3+PNFv/v740WzIlrnEjlEhEElHUH7z29fXR2trKmjVrGDVqFPfffz/nnXceSUlJoXUMw+j3OBxnu1fhuWC3Z8Z1vFi55evcf/N9zOGj3Vx84fnMc3+PW67NGeFkQzPrPgfzZjdrbjBv9kTJHXXJX3zxxeTn53PRRRcBMG3aNBobG0lJSQmt4/f7cTgcEb2ubuQdHrs9kwmXZ7F8fn6/5Ym+PWbf52bMbtbcYN7slriR99SpU9m8eTOdnZ309fXxr3/9i8LCQvbs2ROayqmvr2fKlCnRDiEiIsMU9ZH8pEmTuO+++7jrrrsIBALcdNNN3HnnnYwdO5by8nJ6enpwuVwUFhbGMq+IiEQgyTCM+MyNhEnTNeExa3az5B7obOIZt3zXFNlPZ5Z9PhCzZk+k6Rqd8Spymi3bDw14NvEFmecx4fKskQ0nEiFdoEzkNOubdw94NvHffB+PUCKR6KnkRU4z2FnDg51lLJLINF0jcprsC9IHLPrBzjIGXRFUEpeO5EVOU+IaN+DZxPPc3xtw/VNz+KfeGE7N4W/ZfuicZxUZikpe5DT5E5zc7R4fug5Q9gXp3O0eP+jZxIPN4euKoJIINF0jMoD8Cc6wp1sGm8PXFUElEehIXmSYBrvyp64IKolAR/IiYWraup/V9dvP+HC1xDWu3/fqQVcElcShkhcJw5bth/hb4y56An3AwLdb1LdrJBGp5BOcvpqXGNY37w4V/CmnPlw9NX+vvxdJRJqTT2D6al7i0IerYlYq+QSmr+YlDn24Kmalkk9gOnpMHCWucaSnpvRbpg9XxQxU8glMR4+JI3+Ck5+XTjrjBCnNw0ui0wevCUxfzUsst1ybo0sNi+nE5Eh++fLlVFZWAtDS0oLX66WgoIDq6upYvPy31mCn1+voUUTCNewj+S1btrBhwwZuueUWTpw4weLFi1mzZg2XXHIJ8+fPp7m5GZfLFYus30r6ap6IDMewjuT/+9//Ul1dzYIFCwD44IMPyM3NJScnB5vNhtfrpbGxMSZBRUQkcsM6kn/kkUdYuHAhBw8eBKC9vR273R76ucPhoK2tLaLXPNu9Cs8Fuz0zruPFklmzmzU3mDe7WXODebMnSu6oS37dunVccskl5Ofns379egCCwSBJSUmhdQzD6Pc4HLqRd3jMmt2sucG82c2aG8yb3RI38m5oaMDv91NcXMwXX3zBl19+yYEDB0hJ+f93if1+Pw6HI9ohRERkmKIu+b/85S+hP69fv5733nuPRx99lIKCAvbt28d3vvMd6uvrueOOO2ISVEREIhfT78mnp6dTVVVFeXk5PT09uFwuCgsLYzmEiIhEIMkwjPhMgIdJc/LhMWt2s+YG82Y3a24wb/ZEmpPXZQ1ERCxMJS8iYmEqeRERC1PJi4hYmEpeRMTCVPIiIhamkhcRsTCVvIiIhankRUQsTCUvImJhKnkREQtTyYuIWJhKXkTEwlTyIiIWppIXEbGwYZX8s88+i8fjwePx8NRTTwHQ0tKC1+uloKCA6urqmIQUEZHoRF3yLS0tbN68mQ0bNlBbW8v27dupr69n8eLFrFy5koaGBj766COam5tjmVdERCIQdcnb7XYqKytJS0sjNTWVcePGsXfvXnJzc8nJycFms+H1emlsbIxlXhERiUDU93j97ne/G/rz3r178fl8/PjHP8Zut4eWOxwO2traInrds93G6lyw2zPjOl4smTW7WXODebObNTeYN3ui5B72jbw/+eQT5s+fz0MPPURKSgp79+4N/cwwDJKSkiJ6Pd3jNTxmzW7W3GDe7GbNDebNbpl7vG7dupV77rmHX//618ycOROn04nf7w/93O/343A4hjOEiIgMQ9Qlf/DgQX72s5+xYsUKPB4PAJMmTWLPnj3s27ePvr4+6uvrmTJlSszCiohIZKKernnxxRfp6emhqqoqtGz27NlUVVVRXl5OT08PLpeLwsLCmAQVEZHIJRmGEZ8J8DBpTj48Zs1u1txg3uxmzQ3mzW6ZOXkREUlsKnkREQtTyYuIWJhKXkTEwlTyIiIWppIXEbEwlbyIiIWp5EVELEwlLyJiYSp5ERELU8mLiFiYSl5ExMJU8iIiFqaSFxGxMJW8iIiFnZOS37hxI7fddhsFBQWsXbv2XAwhIiJhGPaNvE/X1tZGdXU169evJy0tjdmzZ3PDDTdw5ZVXxnooEREZQsyP5FtaWpg8eTJZWVmMGjWK6dOn09jYGOthREQkDDEv+fb2dux2e+ixw+Ggra0t1sOIiEgYYj5dEwwGSUpKCj02DKPf46Gc7V6F54LdnhnX8WLJrNnNmhvMm92sucG82RMld8xL3ul00traGnrs9/txOBxhP1838g6PWbObNTeYN7tZc4N5s1v6Rt433ngjW7ZsoaOjg+7ubt544w2mTJkS62FERCQMMT+SHzNmDAsXLmTevHkEAgFmzZrFxIkTYz2MiIiEIeYlD+D1evF6vefipUVEJAI641VExMJU8iIiFqaSFxGxMJW8iIiFqeRFRCxMJS8iYmEqeRERC1PJi4hYmEpeRMTCVPIiIhamkhcRsTCVvIiIhankRUQsTCUvImJhKnkREQuLuuS3bt3KrFmzKC4u5u677+bAgQMAdHZ2UlZWhtvtZs6cOfj9/piFFRGRyERd8g8++CBPPPEEdXV1eL1ennjiCQBqamrIy8vD5/NRWlrK0qVLYxZWREQiE1XJnzx5koqKCsaPHw/AVVddxcGDBwFoamoK3RWqqKiITZs2EQgEYhRXREQiEVXJp6WlUVxcDEAwGOTZZ59l2rRpALS3t2O32wGw2WxkZGTQ0dERo7giIhKJIe/x6vP5WLZsWb9lY8eOZfXq1Zw8eZLKykp6e3uZP3/+gM83DIPk5PDfS7KzM8JeNxbs9sy4jhdLZs1u1txg3uxmzQ3mzZ4ouYcsebfbjdvtPmP58ePHuf/++8nKyuJPf/oTqampADgcDg4fPozT6aS3t5fjx4+TlZUVdqAjR7oIBo3wt2AY7PZM/P5jcRkr1sya3ay5wbzZzZobzJs9nrmTk5POenA8rA9ec3NzqampIS0tLbTc5XJRW1sLQENDA3l5eaE3ABERia8hj+QHsmPHDt566y2uvPJKZs6cCXx1BP/nP/+ZiooKKisr8Xg8ZGZmsmLFipgGFhE5l7ZsP8T65t0c6ewh+4J0SlzjyJ/gHOlYUYuq5L///e+za9euAX+WlZXFqlWrhhVKRGQkbNl+iL/6dnKyNwjAkc4e/urbCWDaotcZryIiX1vfvDtU8Kec7A2yvnn3CCUaPpW8iMjXjnT2RLTcDFTyIiJfy74gPaLlZqCSFxH5WolrHGm2/rWYZkumxDVuhBINX1QfvIqIWNGpD1e/9d+uERGxqvwJTlOX+uk0XSMiYmEqeRERC1PJi4hYmEpeRMTCVPIiIhamkhcRsTCVvIiIhankRUQsTCUvImJhwy75HTt2cPXVV4ced3Z2UlZWhtvtZs6cOfj9/uEOISIiURpWyXd3d/P4448TCARCy2pqasjLy8Pn81FaWsrSpUuHHVJERKIzrJKvqqri7rvv7resqakJr9cLQFFREZs2ber3JiAiIvETdcm/9dZbnDhxgsLCwn7L29vbsdvtANhsNjIyMujo6BheShERicqQV6H0+XwsW7as37KxY8fS1dXF6tWrhxzAMAySk8N/L8nOzgh73Viw2zPjOl4smTW7WXODebObNTeYN3ui5E4yDMOI9Enr1q3j+eefZ/To0QDs3LmT8ePHs3btWmbMmMHLL7+M0+mkt7eX66+/nnfffZfU1NSwXvvIkS6CwYgjRcVuz8TvPxaXsWLNrNnNmhvMm92sucG82eOZOzk56awHx1FdT760tJTS0tLQ46uuuoq6ujoAXC4XtbW1LFiwgIaGBvLy8sIueBERia2Y3zSkoqKCyspKPB4PmZmZrFixItZDiIhImGJS8rt27Qr9OSsri1WrVsXiZUVEZJh0xquIiIWp5EVELEwlLyJiYSp5ERELU8mLiFiYSl5ExMJU8iIiFqaSFxGxMJW8iIiFqeRFRCxMJS8iYmEqeRERC1PJi4hYmEpeRMTCVPIiIhYWdcm3t7dTVlbG7bffzuzZs/nss88A6OzspKysDLfbzZw5c/D7/TELKyIikYm65B966CGmTp1KbW0txcXFoTtA1dTUkJeXh8/no7S0lKVLl8YsrIiIRCaqku/o6GDnzp3Mnj0bgDvuuINf/vKXADQ1NeH1egEoKipi06ZNBAKB2KQVEZGIRFXy+/fv59JLL6Wqqoo77riDX/ziF6Gbdbe3t2O32wGw2WxkZGTQ0dERu8QiIhK2Ie/x6vP5WLZsWb9lubm57Nixg/LychYtWsS6deuorKxkzZo1ZzzfMAySk8N/L8nOzgh73Viw2zPjOl4smTW7WXODebObNTeYN3ui5E4yDMOI9EmffvopM2fOZOvWrQB0d3czefJktm3bxo9+9CNefvllnE4nvb29XH/99bz77ruhI/2hHDnSRTAYcaSo2O2Z+P3H4jJWrJk1u1lzg3mzmzU3mDd7PHMnJyed9eA4qumayy+/HKfTSXNzMwDvvPMOEyZMAMDlclFbWwtAQ0MDeXl5YRe8iIjE1pDTNYN55plnWLJkCb///e/JyMigqqoKgIqKCiorK/F4PGRmZoa+dSMiIvEXdcmPHTt2wDn4rKwsVq1aNaxQIiISGzrjVUTEwlTyIiIWppIXEbEwlbyIiIWp5EVELEwlLyJiYSp5ERELU8mLiFiYSl5ExMJU8iIiFqaSFxGxMJW8iIiFqeRFRCxMJS8iYmEqeRERC1PJi4hYWNQl/9lnnzFnzhyKi4uZO3cuBw4cAKCzs5OysjLcbjdz5szB7/fHLKyIiEQm6pL/4x//iMfjoa6ujoKCAqqrqwGoqakhLy8Pn89HaWkpS5cujVlYERGJTNQlHwwG6erqAqC7u5vzzjsPgKamJrxeLwBFRUVs2rSJQCAQg6giIhKpJMMwjGie+OmnnzJ79mxSUlIIBAK88sor5ObmcvXVV/P+++9js311+9gpU6awbt06xowZE9PgIiIytCFv5O3z+Vi2bFm/ZWPHjqWnp4fHHnuMadOm8frrr/Pzn/+c11577YznG4ZBcnL4vzAcOdJFMBjV+07E7PZM/P5jcRkr1sya3ay5wbzZzZobzJs9nrmTk5PIzs4Y9OdDlrzb7cbtdvdb1tHRgdvtZtq0aQBMnz6dJUuWcPToURwOB4cPH8bpdNLb28vx48fJysoa3laIiEhUopqTv/DCC0lPT6e1tRWArVu3Mnr0aC666CJcLhe1tbUANDQ0kJeXR2pqaswCi4hI+IY8kh9IUlISzz77LI8//jgnTpxg9OjRPPPMMwBUVFRQWVmJx+MhMzOTFStWxDSwiIiEL6qSB5g4cSLr1q07Y3lWVharVq0aVigREYkNnfEqImJhKnkREQtTyYuIWJhKXkTEwlTyIiIWFvW3a86V5OQkS48XS2bNbtbcYN7sZs0N5s0er9xDjRP1tWtERCTxabpGRMTCVPIiIhamkhcRsTCVvIiIhankRUQsTCUvImJhKnkREQtTyYuIWJhKXkTEwr5VJV9TUxO6gxXAe++9xw033EBxcTHFxcUsWrQIgJMnT/Lggw/idruZOXMmu3fvHqnIIadn7+zspKysDLfbzZw5c/D7/UBiZgfYsGEDN998c2hfV1dXA4NvRyLZuHEjt912GwUFBaxdu3ak4wxp7ty5eDye0L7etm0bLS0teL1eCgoKQvs+UXR1dVFUVMRnn30GMGjWjz/+mJKSEqZPn85vfvMbent7RyoycGbuRYsWUVBQENrvb775JpAAuY1vgc7OTmPRokXGxIkTjaeffjq0/MUXXzRWrVp1xvovvPCC8fDDDxuGYRjvvfeeUVpaGrespxss+6OPPmo8//zzhmEYxoYNG4yKigrDMBIr+zc99thjxsaNG89YPth2JIpDhw4ZU6dONY4ePWocP37c8Hq9xieffDLSsQYVDAaNm2++2QgEAqFl3d3dhsvlMj799FMjEAgY9957r9HU1DSCKf/v/fffN4qKiowJEyYY+/fvP2tWj8dj/Pvf/zYMwzAWLVpkrF27NmFyG4ZhFBUVGW1tbWesO9K5vxVH8m+99RZXXHEFP/nJT/ot//DDD9m8eTNer5cFCxZw8OBBAJqampgxYwYA1113HR0dHXz++edxzw2DZ29qasLr9QJQVFTEpk2bCAQCCZX9mz788EM2bNiA1+vlgQce4IsvvgAG345E0dLSwuTJk8nKymLUqFFMnz6dxsbGkY41qP/85z8A3HvvvcyYMYOXXnqJDz74gNzcXHJycrDZbHi93oTZhldffZUlS5bgcDgABs164MABTpw4wQ9/+EMASkpKRnQbTs/d3d3N559/zuLFi/F6vTz99NMEg8GEyP2tKPnbb7+dsrIyUlJS+i3PzMxk7ty5bNy4EZfLxcKFCwFob2/HbreH1rPb7Rw6dCiumU8ZLPs3M9psNjIyMujo6Eio7N9kt9v56U9/ymuvvcYll1zCY489Bgy+HYni9P3pcDhoa2sbwURn19nZSX5+Ps899xyrV6/m73//O59//nnCbsPSpUvJy8sLPR5sfw/073okt+H03IcPH2by5Mk8+eSTvPrqq7S2tvKPf/wjIXIn3KWGh8Pn87Fs2bJ+y8aOHcvq1asHXP9U0QDceeed/OEPf+DYsWMYhkFS0v8v32kYBsnJ5/b9MNLspzuVcSSyf1M423Hfffdx6623Dvj8eOcdSjAYPGN/fvNxornmmmu45pprQo9nzZrF008/zbXXXhtalsjbMNj+TvS/h5ycHJ577rnQ47lz51JbW8u4ceNGPLelSt7tduN2u8NaNxgM8vzzz59xlJySksKYMWNob2/n8ssvB756lz71a9m5Ekl2+OoI5/DhwzidTnp7ezl+/DhZWVkjkv2bBtqOY8eOsXr1au655x7gq3/op/b5YNuRKJxOJ62traHHfr8/rvszUq2trQQCAfLz84Gv9vVll13W7wPtRN4Gp9M5YNbTl8f73/VQdu3axd69e5k+fTrw1X632WwJkTtxDpniLDk5mTfffJPXX38dgNraWiZNmsSoUaNwuVzU1dUBX/2nSU9P59JLLx3JuGdwuVzU1tYC0NDQQF5eHqmpqQmZfdSoUbzwwgts27YNgJdeeil0JD/YdiSKG2+8kS1bttDR0UF3dzdvvPEGU6ZMGelYgzp27BhPPfUUPT09dHV1sWHDBn71q1+xZ88e9u3bR19fH/X19Qm7DZMmTRow62WXXUZ6ejpbt24FoK6uLqG2wTAMnnzySb744gsCgQCvvPIKt956a0LkttSRfKSWL1/Oww8/zHPPPcdFF13EU089BXz1q9YjjzyCx+MhLS0ttDyRVFRUUFlZicfjITMzkxUrVgCJmT0lJYWamhp+97vfceLECa644opQrsG2I1GMGTOGhQsXMm/ePAKBALNmzWLixIkjHWtQU6dOZdu2bdx+++0Eg0HuuusurrnmGqqqqigvL6enpweXy0VhYeFIRx1Qenr6oFlXrFjBb3/7W7q6upgwYQLz5s0b4bT/N378eMrKyrjzzjvp7e2loKCAoqIiYORz685QIiIW9q2drhER+TZQyYuIWJhKXkTEwlTyIiIWppIXEbEwlbyIiIWp5EVELEwlLyJiYf8DF+whe1BYXRUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If we want our data to resemble a map, we must set the axis to refelct the natural domain of lactitude and longitude\n",
    "plt.scatter(data['Longitude'],data['Latitude'])\n",
    "plt.xlim(-180,180)\n",
    "plt.ylim(-90,90)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f100fa9-3fc3-4e4e-8c10-3b70e538a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you put the original map close to this one ,you will notice that this method is not bad at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec6bd77-c8a0-4a08-83ed-6f44224c0757",
   "metadata": {},
   "source": [
    "##### Select the features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e0edbff-15ce-4656-9bd4-2cd59075cf28",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_mapped' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6740/3844029548.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#x = data_mapped.iloc[:,3:4] # using one series\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_mapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# using last  3 sereis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# using last 3 series fronm the plot we observed that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#the 3 clusters turnd out to be on geographical location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# instead of language and location.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_mapped' is not defined"
     ]
    }
   ],
   "source": [
    "#x = data_mapped.iloc[:,3:4] # using one series\n",
    "x = data_mapped.iloc[:,1:4] # using last  3 sereis\n",
    "# using last 3 series fronm the plot we observed that\n",
    "#the 3 clusters turnd out to be on geographical location\n",
    "# instead of language and location.\n",
    "# we can also use 2 clusters and see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46b6dce8-a145-4fce-9253-9b26c005ab07",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6740/32546335.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2843aa8-a8f8-4a33-97a5-6fb89cf6886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our input will be contained in a variable called x, we will start by clustering based on location\n",
    "# We want x to conain lac. and long.\n",
    "# We will use the pandas method iloc which is a method that slices the dataframe\n",
    "# DataFrame.iloc(row indices,column indiced) slices the dataframe ,given orws and columns to be kept\n",
    "# The first arguement indicates the row indices we want to keep while the second,column indices.\n",
    "# If we want to keep all rows ,we will put column as the firts arguement\n",
    "# Pandas indices starts from zero,from the columns we need lactitude and longitude or colums 1 and 2, \n",
    "# so the approriate arguement is x = data.iloc[:, 1: 3) 1, this will slice the first and the second \n",
    "# column of the dataframe. Lets print x to see the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4832f84b-3aaf-403e-b592-d520a3b99368",
   "metadata": {},
   "source": [
    "##### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10448d11-613e-4635-aff5-07b4673778a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will declare a variable calle KMeans KM in(uppercase)\n",
    "# The righet size is actually the kmeans method that we imported from sklearn\n",
    "# The value in brac. is no clsters we want to produce, so our variable kmeans is now \n",
    "# an object we will use for the clusteing itself, similar to regression, the clustering\n",
    "# happens using the fit method,kmeans.fit(x), this line of code will apply kmeans \n",
    "# clustering with 2 clustersinput data from x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06de76eb-1b36-42b4-8bdd-6c1c32345692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans = KMeans(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12ab6b8f-47db-44c5-b28a-757be9c0496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa4c5de0-6b1c-4ec2-b858-36e390807ae7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6740/3740437983.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "kmeans.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "079eca0e-d33b-4804-a3cb-e3d1ce8ff836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usually we dont need to perform the clustering but our interest is in the cluster themselves,we can obtain the predicted clusters for each \n",
    "# observation using the fit .predict method\n",
    "# sklearn.cluster.KMeans.fit_predict(x) returns the cluster prediction in an array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7a9a4c-085a-4657-a654-91be4d945734",
   "metadata": {},
   "source": [
    "##### Clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52df40e9-3249-46ff-84a5-e63622e310fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6740/3466259377.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Lets declare a new variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0midentified_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0midentified_clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# Lets declare a new variable\n",
    "identified_clusters = kmeans.fit_predict(x)\n",
    "identified_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "167f52b3-497d-44f9-8c8c-6b1bb7f6d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The result is an array containing the predict clusters.\n",
    "#  There were 2 clusters indicated by 0,1 , the first 5 observations are indicated by 1 and the 6th observation by  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed84cf4e-a496-4f67-9e23-e712349656a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'identified_clusters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6740/165853591.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# create a new dataframe, add an additional column called cluster = identified clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata_with_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdata_with_clusters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Cluster'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midentified_clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdata_with_clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'identified_clusters' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's create a dataframe to hel us see things more clearly.\n",
    "# create a new dataframe, add an additional column called cluster = identified clusters\n",
    "data_with_clusters = data.copy()\n",
    "data_with_clusters['Cluster'] = identified_clusters\n",
    "data_with_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91f75945-4949-40e5-8abd-e80ce1cdab6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From here you can see that USa, Canada, France, UK , GERmany are in one cluster and Australia in another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f8f663a-04fe-413e-836a-ba0a3cd94377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finally ,let's plot it on a scatter plot, for it to resemble the map of the world, the y-axis will be the longitude \n",
    "# The x-axis lactitude\n",
    "plt.scatter(data_with_clusters['Longitude'],data_with_clusters['Latitude'])\n",
    "plt.xlim(-180,180)\n",
    "plt.ylim(-90,90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbb677d6-ac15-4fc5-bc07-d6a5ebbb4e75",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Cluster'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Cluster'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6740/1611996409.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# c=data_with_cluster ['cluster'] this shows we want to have as many colors as possible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# we set the coor map to rainbo to get more brighter colors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_with_clusters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Longitude'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_with_clusters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Latitude'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_with_clusters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Cluster'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rainbow'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Cluster'"
     ]
    }
   ],
   "source": [
    "# This is thesame graph as before, but this is the trick,in matplotlib , we can set the color to be detremined by a variable, in our case, it will be cluster.\n",
    "# c=data_with_cluster ['cluster'] this shows we want to have as many colors as possible\n",
    "# we set the coor map to rainbo to get more brighter colors\n",
    "plt.scatter(data_with_clusters['Longitude'],data_with_clusters['Latitude'],c=data_with_clusters['Cluster'],cmap='rainbow')\n",
    "plt.xlim(-180,180)\n",
    "plt.ylim(-90,90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f096808-4e26-4581-8b00-a762909974b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 2 clustering , red and purple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8d0d389-9ea7-4e13-9c9a-6b9757158e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we wan tot have three clusters we will need to readjust the input.ie lmaen = Kmeans (3)\n",
    "# we will have 3 colours with this ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1e2496-e9ff-4c17-a145-b130dac721e9",
   "metadata": {},
   "source": [
    "#### Clustering categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62776ee2-9edc-44dd-b5bb-7f610cface45",
   "metadata": {},
   "source": [
    "#### Map the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5d9a74b-c7ab-4993-872a-35b4573dd4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USA</td>\n",
       "      <td>44.97</td>\n",
       "      <td>-103.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Canada</td>\n",
       "      <td>62.40</td>\n",
       "      <td>-96.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>France</td>\n",
       "      <td>46.75</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UK</td>\n",
       "      <td>54.01</td>\n",
       "      <td>-2.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>51.15</td>\n",
       "      <td>10.40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Australia</td>\n",
       "      <td>-25.45</td>\n",
       "      <td>133.11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country  Latitude  Longitude  Language\n",
       "0        USA     44.97    -103.77         0\n",
       "1     Canada     62.40     -96.80         0\n",
       "2     France     46.75       2.40         1\n",
       "3         UK     54.01      -2.53         0\n",
       "4    Germany     51.15      10.40         2\n",
       "5  Australia    -25.45     133.11         0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One other information we didnt use is language, to make use of it ,we must encode it using numbers\n",
    "# lts greet a new variable called data mapped = data.copy(0\n",
    "# map the language,set English to 0, french to 1, germany to 2\n",
    "# Note this is not the optimal way to encode but it will work for now.\n",
    "data_mapped = data.copy()\n",
    "data_mapped['Language']=data_mapped['Language'].map({'English':0,'French':1,'German':2})\n",
    "data_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a85bb6bb-793e-414a-bff3-bf85fa50c725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(r\"C:\\Users\\user\\Desktop\\2_a-simple-example-of-clustering-exercise-dataset.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70477237-091e-4950-876b-3c9f6557f6d3",
   "metadata": {},
   "source": [
    "##### Select the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd5438f8-0b1e-4095-aa3d-2c4c0d1f2733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Language\n",
       "0         0\n",
       "1         0\n",
       "2         1\n",
       "3         0\n",
       "4         2\n",
       "5         0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's choose the features we wan to use for clustering, we can us single features .\n",
    "# We wiil slice all rows but only the last column we are left with is the language column\n",
    "# After this we can perform clustering\n",
    "x = data_mapped.iloc[:,3:4]\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b9e833-b0a1-485d-a9df-2caf2e58613c",
   "metadata": {},
   "source": [
    "##### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d634407-2f8f-40bf-ab16-fc742923d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have the same code ready so we will use it\n",
    "# We are running K-means clustering with 3 clusters\n",
    "kmeans = KMeans(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca2223e0-082a-421c-8fc8-e0b57a64568f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de46bd3-eb24-4042-8964-53437f6f3621",
   "metadata": {},
   "source": [
    "#### Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4823fd44-048b-4851-bf09-d467d7923e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 1, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identified_clusters = kmeans.fit_predict(x)\n",
    "identified_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bc5f0ce-957d-4626-8d77-997120eb29d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Language</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USA</td>\n",
       "      <td>44.97</td>\n",
       "      <td>-103.77</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Canada</td>\n",
       "      <td>62.40</td>\n",
       "      <td>-96.80</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>France</td>\n",
       "      <td>46.75</td>\n",
       "      <td>2.40</td>\n",
       "      <td>French</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UK</td>\n",
       "      <td>54.01</td>\n",
       "      <td>-2.53</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>51.15</td>\n",
       "      <td>10.40</td>\n",
       "      <td>German</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Australia</td>\n",
       "      <td>-25.45</td>\n",
       "      <td>133.11</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country  Latitude  Longitude Language  Cluster\n",
       "0        USA     44.97    -103.77  English        0\n",
       "1     Canada     62.40     -96.80  English        0\n",
       "2     France     46.75       2.40   French        2\n",
       "3         UK     54.01      -2.53  English        0\n",
       "4    Germany     51.15      10.40   German        1\n",
       "5  Australia    -25.45     133.11  English        0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_clusters = data.copy()\n",
    "data_with_clusters['Cluster'] = identified_clusters\n",
    "data_with_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b81e90e0-0e3b-4495-aaf1-a55138080b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data_with_clusters['Longitude'],data_with_clusters['Latitude'],c=data_with_clusters['Cluster'],cmap='rainbow')\n",
    "plt.xlim(-180,180)\n",
    "plt.ylim(-90,90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "791a4f45-58d9-4618-b7dc-ad8ca157014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plot is unequivical, the 3 clusters are USA,CANADA< UK AND AUSTRALIA in the first one,France in the scond and GERMANY in the third.\n",
    "# This is pricisely , what we expected, English ,French and German.\n",
    "# We are still using th Longitude and Latitude as axis of the plot\n",
    "# Unlike regression, when doing clustering ,you can plot the data as you wish\n",
    "# the cluster info. is contained in the cluster column in the dataframe and it is the color oof the points on the plot\n",
    "# Note, we can use both numerical and categorical data in clustering\n",
    "# From our input data x ( under select the features ) lets take the last 3 series X= data_mapped.iloc[:,1:4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a6b708-21f5-4526-82fb-46b1545b50e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### How to choose the number of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3518d3-3d18-4f06-8d19-0f3bbda3f083",
   "metadata": {},
   "source": [
    "+ The Elbow method is the widely adopted criterion for selecting the proper number of clusters.\n",
    "\n",
    "The rational behind the elbow method :\n",
    "\n",
    "i. Clustering is about minimizing the distance between points in a cluster\n",
    "\n",
    "ii. And maximixing the  distance between between clusters\n",
    "\n",
    "In K-Means , this two occurs simultaneusly.\n",
    "\n",
    "If we minimize the distance between points in a cluster, we are automatically maximizing the distance between clusters.\n",
    "Anothe thing to worry about is the fact that the distance between points in a cluster sounds clumsy. The distance is measured in sum of squares.\n",
    "The academic term is\n",
    "'Within-clusters sum of squares', or WCSS\n",
    "\n",
    "Similar to SST,SSR and SSE, WCSS is a measure developed within the anova framework.\n",
    "\n",
    "If we minimize WCSS< we have reached the perfect clustering solution.\n",
    "\n",
    "Here is the problem, If we have thesame 6 countries and one of them is a different cluster.and a total of 6 clusters, then WCSS = 0, This is because there is just one point each cluster and we can't have a within cluster sum of squares.\n",
    " \n",
    " Observations : 6\n",
    " \n",
    " Clusters : 6\n",
    " \n",
    " WCSS = 0\n",
    " \n",
    " Furthermore , the clusters are as far as they can possibly be.\n",
    " Imagine this with 1 million observations, a 1 milloin observation of clusters is of no use.\n",
    " \n",
    " Similarly , if all observations are on thesame cluster,the solution is useless and WCSS is out of maximum.\n",
    " \n",
    " Observations : 1,000,000\n",
    " \n",
    " Clusters : 1,000,000\n",
    " \n",
    " WCSS = 0 =min\n",
    " \n",
    " There must be some middle ground.\n",
    " We easily reach the conclusion that we dont really want WCSS to be minimized.\n",
    " \n",
    " Instead we want it to be as low as possibe and we can still have a small number of clusters so that we can interprete them\n",
    " \n",
    " Observations : N\n",
    " \n",
    " Clusters : Small\n",
    " \n",
    " WCSS = low\n",
    " If we plot WCSS against the number of clusters .\n",
    " \n",
    " We get a graph that look like an elbow and hence the name. The point is that the within clusters sum of squares is  a simultaneously decreasing function which is lower for bigger number of clusters.\n",
    " \n",
    " The big revelation is that in the beginning WCSS is declining really fast and at some points it reaches the elbow afterward we are not reaching a much better solution in terms of WCSS by increasing the number of clusters , for our case ,we say that the optimal number of clusters is 3 which is the elbow. That is the significant number of cluster of which we are getting a signifant decrease in WCSS. Hereafter, there is almost no improvement\n",
    " \n",
    " To put this to use  we need two pieces of information\n",
    " i . The number of clusters  K\n",
    " \n",
    " ii.  The WCSS for a specific number of Clusters\n",
    " \n",
    " k is set by us at the beginning of the process while there is an sklearn method that gives us the WCSS.\n",
    " \n",
    " For instance, to get the WCSS for our last example we will us the following codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81643b0c-80d1-4623-b082-5b49d3573314",
   "metadata": {},
   "source": [
    "##### Selecting the number of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d796db-4f7c-46f9-915e-e9773b417a49",
   "metadata": {},
   "source": [
    "###### WCSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99ad1cee-5748-4ec0-a621-b41a289c6d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get the WCSS for our last e.g ,\n",
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7020470-3027-40c3-aea7-ce3559239055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To plot the elbow we actually need to solve the problem with 1,2,3,4,5,6 clusters and calculate WCSS for each of them\n",
    "# We will use a loop to do it\n",
    "# Declare an empty list called WCSS, declare the variables, fit the data\n",
    "# Calculate the WCSS fro the iteration using the initial method\n",
    "# Then add the WCSS for the iteration to the WCSS list\n",
    "# we use the append method to do it.list.append(x) appends a new item\n",
    "# with value x to the end of the object(list,array, etc)\n",
    "# just pick the list .append and in bracket,include the list values you would like to append on the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df11200c-9956-4934-826a-53a742765d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss=[]\n",
    "\n",
    "for i in range(1,7):\n",
    "    kmeans = KMeans(i)\n",
    "    kmeans.fit(x)\n",
    "    wcss_iter = kmeans.inertia_\n",
    "    wcss.append(wcss_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ae06e06-1aa9-4637-82ba-411be5743b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.5, 0.5, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wcss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a81d9be-8cfd-495c-a632-e6f19f3afe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have clusters 1 to 6 and from the result we observed that the seqence is decreasing with a very big leaps\n",
    "# in the firts two steps, band much smaller ones later ones later on.\n",
    "# Each point is a seperate cluster and we have  a WCSS = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ae4d6e-2f07-4295-ae8b-e5e57c044a75",
   "metadata": {},
   "source": [
    "##### The Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "951779ed-c358-4803-91c4-dde910fbc2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Within-cluster sum of Squares')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's declare a variable called num. clusters which is a list from 1-6\n",
    "# use conventional plotting code to get the graph\n",
    "number_clusters = range(1,7)\n",
    "plt.plot(number_clusters,wcss)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Within-cluster sum of Squares')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "324243cd-1221-4ccf-b4e0-320f645846b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the elbow method to decide the optimal number of clusters\n",
    "# There are 2 points that can be the elbow\n",
    "# A 3 cluster solution is the better one\n",
    "# After it there is not much to gain\n",
    "# A two cluster solution in this case will be sub optimal as \n",
    "# the leap from 2 to 3 is very big in terms of wcss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c01e67-a48a-46be-b453-5e99d9402a08",
   "metadata": {},
   "source": [
    "#### Pros and Cons of K-means and clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5017449e-0600-498c-ab0b-2d5eadce898a",
   "metadata": {},
   "source": [
    "There is no data science without.'probles with', i\n",
    "'issues with' or 'limitations of x. \n",
    "\n",
    "+ Pros  \n",
    "\n",
    "1. It is simple to undersand \n",
    "\n",
    "2. Fast to cluster\n",
    "\n",
    "3. widely available\n",
    "There aremany packages that offer it.\n",
    "\n",
    "4. Easy to implement\n",
    "\n",
    "5. Always yields a result\n",
    "Costing it always yields a result, no mattter the data it will always fish out a solution( Also a con, as it may be deceiving)\n",
    "\n",
    "+ Cons \n",
    "\n",
    "1. We need to pick k \n",
    "\n",
    "2. K Means is sensitive to initialization.\n",
    "This is a very interesting problem\n",
    "Given thsame initial seed ,we get thesame clusters because that is how K-means works. It takes the closet points to the seeds. So if your initial seeds are problematic the whole  solution is meaningless.\n",
    "\n",
    "3. K-means is sensitive to outliers\n",
    "If there is a single point that is too far away from the rest ,it will always be placed in its one point cluster.\n",
    "For example, AUSTRALIA was the sole cluster in almost all the solutions we have for our countries cluster example, it is so far away from the rest of the countries ,hence destine bring its own cluster\n",
    "\n",
    "\n",
    "4. k-means produces spherical solutions\n",
    "This means that on a 2-d plane we have seen, we will more often see clusters that looks Spherical rather than Elliptic shapes. Te reason for that is that we are using Euclidean distance from the centroid, this is also why outliers is such a bi issue for K-means\n",
    "\n",
    "5. Standardization\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "+ Remedies \n",
    "\n",
    "1. The elbow method fixes that but it is not  extremely scientific per say\n",
    "\n",
    "\n",
    "2 ' K-means ++\n",
    "\n",
    "The solution to it is k-means ++, the idea is that a prilinary,iterate algorithm is run prior to k-means to determine the most appropriate seed for the clustering itself.\n",
    "\n",
    "If we check our code ,we will se that sklarn employs kmeans ++ by default. So we are safe. but if we are using a different package is important to remember that initialization matters.\n",
    "\n",
    "3.  remove Outliers before clustering\n",
    "Alternatively ,if you do the clustering and splot one point cluster , remove them and cluster again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6dea06-2409-4a81-9e1f-7bdd6c689f67",
   "metadata": {},
   "source": [
    "#### To standardize or to not standardize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218142ac-f11b-4217-bb10-cfa623e95670",
   "metadata": {},
   "source": [
    "Exploring a  scatter plot with four apartment, the x axis shows the size and the y-axis the price. This is a very common regression relationship. Since we are doing clusstering so instead of causality ,think about how we can group the 4 observations. A  is a 500sqft apartment that is worth $50,000 dollars. B is a 500 sqft apartment that is worth $100,000, C is 12000 sqft apartment with $50,000 dolloars,Dis 12,000sqft  apartment with $100,000 .\n",
    "\n",
    "If we are to create 2 clusters just by looking atthe plot. they are likely to be( A,B )and( C,D) .What if we standardize the X axis(ie the size) .\n",
    "\n",
    "After the calculation, the x-axis are either -1 or 1, \n",
    "How can we group the observations?\n",
    "A,C (50,000) and B,D (100,000) looks reasonable. Let,s also standardize the y axis or price.The y axis ara only -1 or 1 as well.\n",
    "\n",
    "What we have is a perfect square ,we have no idea on deciding if the cluster should be  A,B and C,D or A,C and B,D . Hence we went from one solution to a totally different solution and to no solution whatsoever.\n",
    "\n",
    "+ Why did this happen?\n",
    "\n",
    "The altemate aim of standardization is to reduce the weight of higher numbers and increase that of lower ones.\n",
    "\n",
    "\n",
    "Looking at the first graph,if both axis have the same scale ,say from 0 -100,000, We will gat a very narrow graph. \n",
    "A K-means alforithm will immediately cluster A with C and B with D.\n",
    "Just because the scale of price is quite different    compared to size in terms of mere numbers, so scale matters.\n",
    "\n",
    "The last graph resulted in a square because there are only two values for each axis.\n",
    "Logically every rectangle on a graph after being standardized turns into a square .\n",
    "\n",
    "So no matter how you choose hthe axis or how far away they are from each other, a long as they were in the shape of a rectangle the standardized output would have been a square.\n",
    "\n",
    "By standardizing both axises we remove the weight introduced by the high price value.\n",
    "\n",
    "To sum up, if we dont standardize the range of the value will serve as weight for each variable. price has much higher values which will indicate to K-means that the price is more important. This will lead t clusters based on price. A,c (Economy cluster) and B,D( Luxury cluster).\n",
    "\n",
    "Note , that clustering will barely care about size . So if we dont standardize we are not taking advantage of the size data whatsoever. Therefore ,it is  agood pracice to standardize the data before clustering especially for beginners\n",
    "\n",
    "\n",
    "+ When You should not Standardize?\n",
    "\n",
    "As standardization is trying to put all variables on equal footing , in some cases we donnt need to do that.If we know that one variable is inherently more important than another. Then, Standardization should not be used.\n",
    "\n",
    "An example is our price / size relationship.\n",
    "\n",
    "Most people are affected by the price much more than the size. If you cant afford the price , you will notcare about the size.\n",
    "\n",
    "+ How can you know this prior ot clustering ?\n",
    "\n",
    "Experience plays a big role. So practice when the time comes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8575cc2b-6823-4107-b804-54a366cac339",
   "metadata": {},
   "source": [
    "#### Relationship between clustering and regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0909e970-023f-4a16-af76-abe03f1f5972",
   "metadata": {},
   "source": [
    "Looking at the graph we discussed previously , if it was a real life situation ,you will have many points. Potentially forming  4 clusters. With the risk of over simplifying the mater,B could represent small expensive apartments(rip-offs),A would represent Small reasonably priced apartments, D would reps Big reasonably price apartments and C would represent Big cheap apartments(bargains)\n",
    "\n",
    "Small apartments will be cheaper and bigger apartments will be more expensive. Maybe the rip-offs will be representing the apartments in the city centre while the bargains , apartments in the suburbs.\n",
    "\n",
    "If we seperate them from the rest, we will be left with something that looks very familiar.\n",
    "\n",
    "Our good old regression.\n",
    "\n",
    "And that is how different statisticla methods communicate with each other.\n",
    "\n",
    "+ What about the initial four cluster situations\n",
    "\n",
    "Clustering in this case can help us identify immediate variable bias. In this situation,you can think about clustering as a method of exploring the data and realising that one or more significant variable have not been included in the analysis , so instead of ppredicting price based solely on size ,we may need to include location,to get a better prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f6c74d-5af1-49eb-b22f-4c898623d789",
   "metadata": {},
   "source": [
    "#### Market Segmentation with Cluster Analysis (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30323448-a6cd-469d-b462-e17083723504",
   "metadata": {},
   "source": [
    "##### Market Segmentation example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3fa764-62ae-4494-8e18-3e960901528f",
   "metadata": {},
   "source": [
    "#### Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0cf8afe9-6a5f-4956-b59a-6bebe622c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1908dd0-e18b-4c7b-89a8-991c565f61f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\user\\Desktop\\8_a_market-segmentation-with-cluster-analysis-part-1-dataset.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5ea3d54-7c72-4afe-98e2-bc1a660740b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Satisfaction</th>\n",
       "      <th>Loyalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>-1.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Satisfaction  Loyalty\n",
       "0              4    -1.33\n",
       "1              6    -0.28\n",
       "2              5    -0.99\n",
       "3              7    -0.29\n",
       "4              4     1.06\n",
       "5              1    -1.66\n",
       "6             10    -0.97\n",
       "7              8    -0.32\n",
       "8              8     1.02\n",
       "9              8     0.68\n",
       "10            10    -0.34\n",
       "11             5     0.39\n",
       "12             5    -1.69\n",
       "13             2     0.67\n",
       "14             7     0.27\n",
       "15             9     1.36\n",
       "16             8     1.38\n",
       "17             7     1.36\n",
       "18             7    -0.34\n",
       "19             9     0.67\n",
       "20            10     1.18\n",
       "21             3    -1.69\n",
       "22             4     1.04\n",
       "23             3    -0.96\n",
       "24             6     1.03\n",
       "25             9    -0.99\n",
       "26            10     0.37\n",
       "27             9     0.03\n",
       "28             3    -1.36\n",
       "29             5     0.73"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df174d33-3704-4175-b6a7-3d8489439962",
   "metadata": {},
   "source": [
    "We have data from a Retail shop. There are 30 observations , each observations, each observation is a client and we have a score for customer satisfaction and grand loyalty.\n",
    "Lets look at how the data was gathered,\n",
    "\n",
    "satifaction was self porported:\n",
    "Prople were basically asked to rate their experience from 1 to 10, where 10 means extremely satisfied.\n",
    "\n",
    "Therefore satisfaction here is a \n",
    "discrete variable and its integer values\n",
    "Type of data : Discrete\n",
    "\n",
    "range : 1, 2, 3, 4, 5, 6, 7, 8, 9, 10.\n",
    "\n",
    "Brand Loyalty :\n",
    "This on the other hand was a tricky metric.\n",
    "There is no widely accepted technique to measuer it but there are proxies like churn rate, retention rate,or customer lifetime value(CLV)\n",
    "\n",
    "In this dataset, loyalty was measured through the number of purchasse from that shop for a year and severall other factors found to be significant . The range is from around (-2.5 to 2.5) as the variable is already standardized.This is something that often occurs when creating liten variables like this one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cee5fc0-3274-4c4e-9a65-950d4f256996",
   "metadata": {},
   "source": [
    "##### Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "431cb350-3cd0-414b-8acb-a9d3256b09e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loyalty')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data['Satisfaction'],data['Loyalty'])\n",
    "plt.xlabel('Satisfaction')\n",
    "plt.ylabel('Loyalty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee20cab7-1f09-4150-aae3-d10f1a4773a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By looking at the graoh we can identify two clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b217f8-2ebf-47a7-97e7-599a2920d02a",
   "metadata": {},
   "source": [
    "Before doing any analysis, let's reason about the problem for a while. We can ivide the graph into 4 squares.\n",
    "\n",
    "i . Low satisfaction\n",
    "    Low Loyalty\n",
    "\n",
    "ii. Low Satisfaction\n",
    "    High Loyalty\n",
    "    \n",
    "iii. High satisfaction\n",
    "     Low Loyalty\n",
    "     \n",
    "iv.    High satisfaction\n",
    "       High Loyalty  \n",
    "       \n",
    " Going back to our 2 cluster solution, we realised it didn't make much sense   .\n",
    " \n",
    " The first cluster  represents   Low satisfaction\n",
    "    Low Loyalty while the second cluster have a touch of the remaining 3 groups.\n",
    "    Hence , a 2-cluster soluiton will not work here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ae368b-1934-46e1-bd43-8b2609de5e6e",
   "metadata": {},
   "source": [
    "##### Select the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "165367bc-c548-41e1-bde8-d90841fb19d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets copy the data into a new variable x \n",
    "x = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145d3806-ccf9-45ea-a63e-ab058b54f4c2",
   "metadata": {},
   "source": [
    "##### Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55d81147-d9c1-4637-8c7c-28e0e7f07a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and use the data we have used so far\n",
    "kmeans = KMeans(2)\n",
    "kmeans.fit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb311f7-f836-4b69-a7d5-d1eedf7d60e6",
   "metadata": {},
   "source": [
    "##### Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3e3c381-b9ad-40fd-8a35-804214ac7018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster is a duplicate of x\n",
    "# the column'cluster_pred of clusters' will contain the prediction\n",
    "# ie the cluster were a particular observation was predicted to be placed by the algorithm\n",
    "clusters = x.copy()\n",
    "clusters['cluster_pred']=kmeans.fit_predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f2ad98b-93a7-4bc6-8a5a-5b48bc41569c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loyalty')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets plot the data\n",
    "plt.scatter(clusters['Satisfaction'],clusters['Loyalty'],c=clusters['cluster_pred'],cmap='rainbow')\n",
    "plt.xlabel('Satisfaction')\n",
    "plt.ylabel('Loyalty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "86dfd17b-0557-4b99-bd88-504c97704b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see 2 clusters but not the 2 we imagined . If we examine this plot closely ,you will realize that there is a cut off line . Satis factin value of 6\n",
    "# Everything on the right is 1 cluster and every thing on the left is another cluster\n",
    "# This solution may make sense to some , but most probably the algorithm only considers satisfaction as a feature\n",
    "# This is because we did not standize the variables\n",
    "# The satisfaction values are much higher than that of loyalty.and kmeans disregarded loyalty asa feature,when ever we cluster on the basis of a single\n",
    "# feature, the result looks like this graph as if it was cut off by a line, thats one of the ways to spot that something fishy is going on\n",
    "# Satisfaction and loyaly are important features for market segmentation\n",
    "# How can we fisx this problem ? \n",
    "# How can we give them equal weight?\n",
    "# By standardizing Satisfaction\n",
    "# there are several ways to do that in sklearn\n",
    "# The simplest ies the preprocessing model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5131cb-05ff-4f0b-b2e1-75b396e59517",
   "metadata": {},
   "source": [
    "##### Standardize the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "adf1785b-f0e8-4606-9028-adc70dd704e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.93138063, -1.3318111 ],\n",
       "       [-0.15523011, -0.28117124],\n",
       "       [-0.54330537, -0.99160391],\n",
       "       [ 0.23284516, -0.29117733],\n",
       "       [-0.93138063,  1.05964534],\n",
       "       [-2.09560642, -1.6620122 ],\n",
       "       [ 1.39707095, -0.97159172],\n",
       "       [ 0.62092042, -0.32119561],\n",
       "       [ 0.62092042,  1.01962097],\n",
       "       [ 0.62092042,  0.67941378],\n",
       "       [ 1.39707095, -0.3412078 ],\n",
       "       [-0.54330537,  0.38923705],\n",
       "       [-0.54330537, -1.69203048],\n",
       "       [-1.70753116,  0.66940768],\n",
       "       [ 0.23284516,  0.26916393],\n",
       "       [ 1.00899568,  1.35982816],\n",
       "       [ 0.62092042,  1.37984035],\n",
       "       [ 0.23284516,  1.35982816],\n",
       "       [ 0.23284516, -0.3412078 ],\n",
       "       [ 1.00899568,  0.66940768],\n",
       "       [ 1.39707095,  1.17971847],\n",
       "       [-1.31945589, -1.69203048],\n",
       "       [-0.93138063,  1.03963316],\n",
       "       [-1.31945589, -0.96158562],\n",
       "       [-0.15523011,  1.02962706],\n",
       "       [ 1.00899568, -0.99160391],\n",
       "       [ 1.39707095,  0.36922486],\n",
       "       [ 1.00899568,  0.02901767],\n",
       "       [-1.31945589, -1.36182938],\n",
       "       [-0.54330537,  0.72944425]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "x_scaled = preprocessing.scale(x)\n",
    "x_scaled\n",
    "#scale is a method that scales each variable seperately in otherwords each column will be standardized with respect to itself\n",
    "# sklearn.preprocessing.scale(x)scales (standadizes with mean 0, and standard deviation of 1 by default) each variable(column) seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9519c422-2ff7-4ae8-bbea-30b6c43d41ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_scaled is an array which conains the standardized'Satisfaction' and the same values for 'loyalty'\n",
    "# That is cos loyalty was already standardized ,it has a mean od sero and a standard deviation of 1.\n",
    "# Since we dont know the number of clusters needed ,elbow method will come in handy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639bb11f-57f9-489f-b075-18646383f499",
   "metadata": {},
   "source": [
    "##### Take advantage of the Elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aceed815-d2e4-4265-a121-2e354d5fd902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[59.999999999999986,\n",
       " 29.818973034723143,\n",
       " 17.913349527387968,\n",
       " 10.247181805928422,\n",
       " 7.792695153937187,\n",
       " 6.586212092192189,\n",
       " 5.326631124753926,\n",
       " 4.642275782463054,\n",
       " 3.773115467885196]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets declare a list\n",
    "# note the range is from 1 -10 so we will get the WCSS for 1 to 9 -cluster solutions (completely arbitrarily chosen number)\n",
    "wcss =[]\n",
    "\n",
    "for i in range (1,10):\n",
    "    kmeans = KMeans(i)\n",
    "    kmeans.fit(x_scaled)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "wcss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e0d711f1-4f15-44c0-8dc1-21ed880a5148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have a total of 9 clusters\n",
    "# lets plot wcss verse the number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3024f18-5898-4d2a-89d4-8b90eb385dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'wcss')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,10),wcss)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('wcss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cf99126d-3c14-4d0d-9862-78d042f8e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given this gaph think about the correct number of clusters we should use ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859b7628-96cc-4612-8182-9a32fc302765",
   "metadata": {},
   "source": [
    "#### Market Segmentation with Cluster Analysis (Part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47ae515b-6fb9-48a9-91d3-d63a3e99e6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the elbow , we can see 5 clusters. \n",
    "# the limitation of the elbow method is that we can see the change but we dont now the solution that is the best one\n",
    "# lets try 2 clusters, qualitatively, this is probably a sub optimal solution but it is worth inspecting the differnce\n",
    "# with standardized variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b21b00-22d1-4eeb-829b-d9840608a282",
   "metadata": {},
   "source": [
    "##### Explore clustering solutions and select the number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "055c6b81-55ee-4713-8c87-ed00fb37f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets decale a variable called kmeans_new = kmeans (2) \n",
    "# lets fit the the x_scaled \n",
    "# create a nwe dataframe alled clusters _new containing the values from x\n",
    "# Cluster_pred will contain the predicted cluster will contain new clustering solution predictx-scaled\n",
    "kmeans_new = KMeans(2)\n",
    "kmeans_new.fit(x_scaled)\n",
    "clusters_new = x.copy()\n",
    "clusters_new['cluster_pred'] = kmeans_new.fit_predict(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d95f468-83e8-436b-aa96-c1bd931d9eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Satisfaction</th>\n",
       "      <th>Loyalty</th>\n",
       "      <th>cluster_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Satisfaction  Loyalty  cluster_pred\n",
       "0              4    -1.33             0\n",
       "1              6    -0.28             1\n",
       "2              5    -0.99             0\n",
       "3              7    -0.29             1\n",
       "4              4     1.06             1\n",
       "5              1    -1.66             0\n",
       "6             10    -0.97             1\n",
       "7              8    -0.32             1\n",
       "8              8     1.02             1\n",
       "9              8     0.68             1\n",
       "10            10    -0.34             1\n",
       "11             5     0.39             1\n",
       "12             5    -1.69             0\n",
       "13             2     0.67             0\n",
       "14             7     0.27             1\n",
       "15             9     1.36             1\n",
       "16             8     1.38             1\n",
       "17             7     1.36             1\n",
       "18             7    -0.34             1\n",
       "19             9     0.67             1\n",
       "20            10     1.18             1\n",
       "21             3    -1.69             0\n",
       "22             4     1.04             1\n",
       "23             3    -0.96             0\n",
       "24             6     1.03             1\n",
       "25             9    -0.99             1\n",
       "26            10     0.37             1\n",
       "27             9     0.03             1\n",
       "28             3    -1.36             0\n",
       "29             5     0.73             1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "272695a5-72d6-4f70-be00-771d7f4219ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataframe contains the original values but the predicted clusters are based on the solution using the standardized data.\n",
    "# This is very important, we will plot the data without standardizing the AXES but the solution will be the standardized one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d375e4e0-7227-453b-b9ec-8ff59e6706ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loyalty')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(clusters_new['Satisfaction'],clusters['Loyalty'],c=clusters_new['cluster_pred'],cmap='rainbow')\n",
    "plt.xlabel('Satisfaction')\n",
    "plt.ylabel('Loyalty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "436a26da-aa7f-48e4-903b-87a0d106f2af",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_6740/1273935280.py, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_6740/1273935280.py\"\u001b[1;36m, line \u001b[1;32m22\u001b[0m\n\u001b[1;33m    $=# the 3rd cluster we will call the 'All that is left Cluster\"\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### By keeping th original x-axis we get an intuition for HOW SATISFIED Were the Customers\n",
    "# If we plot the standardized values, we will be deceived. \n",
    "# the middle part of the two graphs are differnt. The original values is 5.5, and the \n",
    "# standardized graph the mid point 0 actually corresponds to the mean of the variable or 6.4\n",
    "# We often choose to plot using the original values for clearer intepretability.\n",
    "# Note. the discrepancy we observe here depends on the range of the axes,too\n",
    "# we can see 2 clusers as we specified the numbers to be 2,what is different \n",
    "# though is the cluster itself, comparing this result with the previous one , we can clearly \n",
    "# see that both dimensions were taken into account.\n",
    "# Moreover, these two clusters coincides  with our initial speculation that those two will \n",
    "# be the result of k=2, we are now much more confident that standardization is equally  a good thing.\n",
    "# however , the problem is not yet solved , this 2 cluster solutiion does not make a whole lot of sense\n",
    "# But is good start, lets name the 2 clusters , cluster 1 Alienated (low loayalty and low satisfaction)\n",
    "# Note, that naming your clusters is very important . In unsupervised machine learning , the algorithm wil\n",
    "# do the magic but we need to interpret the result.\n",
    "# Cluster 2 , the everything else cluster( Satisfied and loyal customers)\n",
    "# We wil now re-run the code using the 3 cluster we saw at the elbow and visualize tthe result.\n",
    "# with 3 clusters , we still have the alienated cluster but the everything else cluster splitted into 2\n",
    "# We will now call the 3rd cluster group the \"Supporters\", they are not paticularly happy with the shopping \n",
    "# experience but they are happy with the brand and wants to keep coming back but we just have a hand full of them\n",
    "# A small cluster.\n",
    "$=# the 3rd cluster we will call the 'All that is left Cluster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b05442b-556c-4483-bdde-5a6991df4217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try a 3 cluster solution\n",
    "\n",
    "kmeans_new = KMeans(3)\n",
    "kmeans_new.fit(x_scaled)\n",
    "clusters_new = x.copy()\n",
    "clusters_new['cluster_pred'] = kmeans_new.fit_predict(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8288b1-2556-457c-998a-3adabe25c761",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935c818b-d59c-40f5-ace4-6611d2653923",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(clusters_new['Satisfaction'],clusters['Loyalty'],c=clusters_new['cluster_pred'],cmap='rainbow')\n",
    "plt.xlabel('Satisfaction')\n",
    "plt.ylabel('Loyalty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70dd5e9-7c5f-41af-893f-3055c335e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try a 4 cluster solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a7dde-ac35-4c61-8a85-5528d1f3e240",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_new = KMeans(4)\n",
    "kmeans_new.fit(x_scaled)\n",
    "clusters_new = x.copy()\n",
    "clusters_new['cluster_pred'] = kmeans_new.fit_predict(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba5bdef-f09d-4d18-9209-3f9d5a1c13ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46c6970-b1b4-40fd-86a7-420c16f129f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(clusters_new['Satisfaction'],clusters['Loyalty'],c=clusters_new['cluster_pred'],cmap='rainbow')\n",
    "plt.xlabel('Satisfaction')\n",
    "plt.ylabel('Loyalty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759d666a-f8f0-49d2-81fb-0d3ff221ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have the Alienated , the Supporters and 2 new ones\n",
    "# the upper right one consists of satisfied and loyal customers, we will call them fans\n",
    "# Eventually we hope that all the points on the graph will turn into fans.\n",
    "# The last cluster consists of people predominantly satisfied and loyal but some \n",
    "# of them are disloyal, We will call them Roamers . They like your brand but not very loyal to it.\n",
    "# This solution is definitely the best one we have seen so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c955e8-967c-4ce4-a321-9ea3ad3fc151",
   "metadata": {},
   "outputs": [],
   "source": [
    " Lets try a 5 cluster solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d09ef05-d3ec-4501-8c36-7ee4a274deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_new = KMeans(5)\n",
    "kmeans_new.fit(x_scaled)\n",
    "clusters_new = x.copy()\n",
    "clusters_new['cluster_pred'] = kmeans_new.fit_predict(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96af020-aeec-4dc6-afbe-cb0a9a5c40c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8412564b-f192-4f9a-b2bd-e4fed093e2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(clusters_new['Satisfaction'],clusters['Loyalty'],c=clusters_new['cluster_pred'],cmap='rainbow')\n",
    "plt.xlabel('Satisfaction')\n",
    "plt.ylabel('Loyalty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f57529-810b-4275-a0de-97e90a0fd1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There we have Cluster 1 the Alienated\n",
    "# Clusster 2  The supporters\n",
    "# Cluster 3  , the fans \n",
    "# Cluster 4 the Roamers part 1\n",
    "# cluster 5 : the Roamers part 2, they are almost in the middle of our standardized graph\n",
    "# they are almost neutral on the loyalty feature but are generally satisfied .\n",
    "# The solution split the Roamers into 2  sub clusters , those that are extremely satisfied and those thata are just satisfied\n",
    "# There isn't mush value added to our segmentation.\n",
    "# we can carry on with as many clusters as we want but from now on we would just further segment the 4 core clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a7cd08-6b0b-41f6-a3de-71cb4e4f1f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets finish up with 9 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23d27cc-3add-4646-8e3f-317ff4b2c5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_new = KMeans(9)\n",
    "kmeans_new.fit(x_scaled)\n",
    "clusters_new = x.copy()\n",
    "clusters_new['cluster_pred'] = kmeans_new.fit_predict(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd6b6e3-bdb6-4c97-88ce-badb3e76b03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f940f218-d3b6-4b6d-ba2e-7a17222d4fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(clusters_new['Satisfaction'],clusters['Loyalty'],c=clusters_new['cluster_pred'],cmap='rainbow')\n",
    "plt.xlabel('Satisfaction')\n",
    "plt.ylabel('Loyalty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818e1bb5-8c0b-4bd2-98d9-096154aae8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to what we had in the last cluster of 5,many of the clusters were further segmented and it is extemely hard to name all of them\n",
    "# Even if we do, we would porbably need to use alot of adjectives .\n",
    "# for instance , the Alienated clusters is split into 2, we can name them (Very Alienated Cluster and Moderately alienated cluster) .\n",
    "#but there is not much t game by using it.\n",
    "# The 4 and 5 cluster solutions were the best ones\n",
    "# The one you want to use depends on the problem at hand !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2521807e-ec2d-4239-a621-d709781029e5",
   "metadata": {},
   "source": [
    "#### How is clustering useful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5725fdd1-a77d-4787-b19a-44a93a6eed06",
   "metadata": {},
   "source": [
    "##### Types of analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a335a3-1ab1-4cc5-885d-3e8d75f3345e",
   "metadata": {},
   "source": [
    "+ Exploratory\n",
    "+ Comfirmatory\n",
    "+ Explanatory "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6112ac9-2ee1-4b34-8396-7c510bdb0a74",
   "metadata": {},
   "source": [
    "+ Exploratory Analysis:\n",
    "    \n",
    "It involves getting aquainted with the data  \n",
    "\n",
    " -search for patterns \n",
    " \n",
    "- Plan :  And determining what matters may be useful to investigate further.\n",
    "\n",
    "Tehniques such as data visualization , descriptive statistics and clustering are great ways to get aquinted with the data, without explicitly trying to explain anything  .\n",
    "\n",
    "There is no straight definition of Comfirmatory and \n",
    "Explanatory analysis,but they different from each other.\n",
    "They are used to :\n",
    "\n",
    "+ Explain a phenomenon\n",
    "\n",
    "+ Comfirm a hypothesis\n",
    "\n",
    "+ Validate some previous research\n",
    "\n",
    "This is where we will normally use hypothesis testing and regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d412f502-3c1c-4404-beba-1923e81ee47b",
   "metadata": {},
   "source": [
    "+ Clustering can be used for all types of analysis:\n",
    "\n",
    "> Exploratory\n",
    "\n",
    "> Comfirmatory\n",
    "\n",
    "> Explanatory\n",
    "\n",
    "+ Most commonly , it is used for Explanatory Analysis\n",
    "Our market segmntation problem was an a prime example of Explanatory market Segmentation \n",
    "\n",
    "+ Clustering cam also be used as a comfirmation of past list. Maybe ,we knew the different clusters and just want to assign each observation with differnt clusters. That is rearly the case though as classification is much more precise technique to deal with that.\n",
    "\n",
    "The big example in this case will be that when the market segment are changing , a clustering solution may show that the clusters no longer look in the same way thus the market exchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3f57c8-e8c7-440b-a8a8-bce965b8a0eb",
   "metadata": {},
   "source": [
    "+ How to apply the 4 clusters from our previous lecture in real life.\n",
    "\n",
    "The 4 clusters are as follows:\n",
    "\n",
    "i . The Alienated Customers\n",
    "\n",
    "ii. The Supporters \n",
    "\n",
    "iii. The fans\n",
    "\n",
    "iv. The roamers\n",
    "\n",
    "When designing the strategy of the company , We ultimately wants to get as many people as possible as fans. We want them to be both satisfied and loyal. In other to turn the supporters into fans , we must increase their shopping satisfaction. But aren't they already loyal , you may ask. Ye. but they are as close to becoming fans than becoming  Alienated .If we donrt address their feedback we may loose them as as clients ,therefore we must increase their customer satisfaction by taking additional steps.For example, there is a big supermarket close t me  but i dont g there  because the queue there is devastating , so i prefer not going there. his isan example of bad shopping experience. I am loyal but don't know for how long as i dont want to spend alot of time waiting in line.So if the supporters  dnt like waiting in long queues to pay, the shop must get more cashier or optimize th eprocess in some other way otherwise , they risk loosingg them as customers .\n",
    "\n",
    "Note, that it is quite possible that by increasing the customer satisfaction ,Supporters may transit into fans, but also some people from the'Alieanated custer may move to the Roamers cluster .\n",
    "\n",
    "we are addressing the same feature, satisfaction.\n",
    "\n",
    "The 'Roamers' are satisfied but not loyal,in other to get them to come more often we may introduce loyalty programs\n",
    "\n",
    "Examples are Discount vouchers, Loyalty cards, Raffles and so on.\n",
    "\n",
    "This may encourage the 'Alienated clusters to become more loyal.Noth necessarily making them more satisfied, putting them in the supportes group .\n",
    "\n",
    "Finally, it doesn't relly make sense to address the 'Alienated' clusters first,They are too far away fro the fans, By default, they are not likely to even enter our shop as they are already dissatisfied and disloyal. \n",
    "\n",
    "+ what else can we do? \n",
    "More and more we encounter 'targeted ads' on the internet, one strategy is to gather as much informaion as possble about our Fans cluster, then find people of similar age,interest, income and so on who have never had of us and target them in our ad campaings.\n",
    "\n",
    "This startgy is used by google ,amazon and facebook.\n",
    "They have seen your personal preferences, they compare you to peoplre in a similar situation and offer you product you or people similar to you are likely to buy.\n",
    "\n",
    "Clustering is one of the methods that can be used for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b0a0c8-e054-44ac-ab67-351ccf9ede79",
   "metadata": {},
   "outputs": [],
   "source": [
    "(r\"C:\\Users\\user\\Desktop\\Categorical.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fcb5ab-0d9d-4837-895c-ef82bdb6e004",
   "metadata": {},
   "source": [
    "#### Required Reading: K Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d33fc1-9f15-43a9-b652-2c2a9c77cf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(r\"C:\\Users\\user\\Desktop\\2_a-simple-example-of-clustering-exercise-dataset.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c57e4-52f3-4297-82c9-8c22cbc911b0",
   "metadata": {},
   "source": [
    "##### K-means Clustering: Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe96a64-4c63-488f-8251-c1d4e3339729",
   "metadata": {},
   "source": [
    "1. The goal of clustering a set of data is to ___________________."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5060e43-20be-46e9-9e8d-ea92f0211a13",
   "metadata": {},
   "source": [
    "ans Divide them into groups of data that are near each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b21622b-1012-42b3-8929-09038880e87d",
   "metadata": {},
   "source": [
    "The goal of clustering is to find distinct groups or “clusters” within a data set. Using a machine language algorithm, the tool creates groups where items in a similar group will, in general, have similar characteristics to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfa6bb1-cab8-4a26-8db8-f96ed9cbde91",
   "metadata": {},
   "source": [
    "2. . The k-means algorithm ____________________________. Choose all that apply."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4033c5d-f2a6-4881-a99f-ab49f1a64159",
   "metadata": {},
   "source": [
    "ans.\n",
    "\n",
    "Can converge to different final clustering, depending on initial choice of representatives\n",
    "\n",
    "Is widely used in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d3eb0-d9ef-428e-961c-378630a96824",
   "metadata": {},
   "source": [
    "The K-means algorithm can converge to different final clustering results, depending on initial choice of representatives. To avoid K-means getting stuck at a bad local optima, we should try using multiple randon initialization. The centroids in the K-means algorithm may not be any observed data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9385cf3c-16bc-4706-a204-47d1b8a1e492",
   "metadata": {},
   "source": [
    ". The choice of k, the number of clusters to partition a set of data into ___\n",
    "\n",
    "ans. Depends on why you are clustering the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9006a53d-f832-417b-88ef-711c605d32c2",
   "metadata": {},
   "source": [
    "4. Which of the following statements about the K-means algorithm are correct?\n",
    "\n",
    "\n",
    "ans :\n",
    "\n",
    "\n",
    "The K-means algorithm is sensitive to outliers.\n",
    "\n",
    "The centroids in the K-means algorithm may not be any observed data points.\n",
    "\n",
    "\n",
    "The centroids in the k-means algorithm may not be any observed data points. True. Because the centroids are simply the average of all points in a cluster, this may not be a point in the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8015a07a-277e-4cef-aa9b-d9675753a136",
   "metadata": {},
   "source": [
    "For different initializations, the K-means algorithm will definitely give the same clustering results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d654d35a-9cec-4c15-9fc2-30fc3814ef0e",
   "metadata": {},
   "source": [
    "Given kmeans iterative nature and the random initialization of centroids at the start of the algorithm, different initializations may lead to different clusters since kmeans algorithm may stuck in a local optimum and may not converge to global optimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc004db-3d01-4195-9035-de135ae9d44e",
   "metadata": {},
   "source": [
    "“K-means can't handle non-convex sets”. Convex sets: In Euclidean space, an object is convex if for every pair of points within the object, every point on the straight line segment that joins them is also within the object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec54e7e-5ef1-4df8-a62c-7d1c5110a64f",
   "metadata": {},
   "source": [
    "5. Considering the K-median algorithm, if points (0, 3), (2, 1), and (-2, 2) are the only points which are assigned to the first cluster now, what is the new centroid for this cluster?\n",
    "\n",
    "\n",
    "ans. 0,2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ef28c7-0068-42c0-8132-75d663c4841a",
   "metadata": {},
   "source": [
    "6. Considering the K-means algorithm, after current iteration, we have 3 centroids (0, 1) (2, 1), (-1, 2). Will points (2, 3) and (2, 0.5) be assigned to the same cluster in the next iteration?\n",
    "\n",
    "Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c69ad6-c0b3-4fb6-b01c-db754911306b",
   "metadata": {},
   "source": [
    "7. The Iris dataset contains information about Iris setosa and versicolor. What is the Euclidean distance between these two objects?\n",
    "\n",
    "\n",
    "ans 2.8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99cec81-081a-45b5-b9bb-e595ca6a24d5",
   "metadata": {},
   "source": [
    ". Which of the following statements are true? Choose all that apply."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24faf24-b3a7-46ae-9cd9-357bd4b00095",
   "metadata": {},
   "source": [
    "Answer ;\n",
    "\n",
    "Graphs, time-series data, text, and multimedia data are all examples of data types on which cluster analysis can be performed.\n",
    "\n",
    "Agglomerative clustering is an example of a hierarchical and distance-based clustering method.\n",
    "\n",
    "When dealing with high-dimensional data, we sometimes consider only a subset of the dimensions when performing cluster analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ef15c8-767f-444a-8141-b2110c38fe6b",
   "metadata": {},
   "source": [
    "9. Which of the following statements are true?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83dc054-67e7-4910-97e5-65dc1739b238",
   "metadata": {},
   "source": [
    "ans.  \n",
    "Clustering analysis in unsupervised learning since it does not require labeled training data.\n",
    "\n",
    "Clustering analysis has a wide range of applications in tasks such as data summarization, dynamic trend detection, multimedia analysis, and biological network analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a1c9c7-4be1-4c9e-996d-016639685920",
   "metadata": {},
   "source": [
    "What are the applications of clustering analysis?\n",
    "\n",
    "Clustering analysis is broadly used in many applications such as market research, pattern recognition, data analysis, and image processing.\n",
    "\n",
    "Clustering can also help marketers discover distinct groups in their customer base. And they can characterize their customer groups based on the purchasing patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6e46dd-bf7d-41ed-a06d-facfe7e55de9",
   "metadata": {},
   "source": [
    "It is impossible to cluster objects in a data stream. We must have all the data objects that we need to cluster ready before clustering can be performed. False.\n",
    "\n",
    "This is false because clustering algorithms can be adapted to perform clustering in a streaming fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb76e68-b69c-4e63-be7d-45c761d64693",
   "metadata": {},
   "source": [
    "10. What are some common considerations and requirements for cluster analysis?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ans\n",
    "\n",
    "\n",
    "We need to consider how to incorporate user preference for cluster size and shape into the clustering algorithm.\n",
    "\n",
    "In order to perform cluster analysis, we need to have a similarity measure between data objects.\n",
    "\n",
    "We need to be able to handle a mixture of different types of attributes (e.g., numerical, categorical).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ca3fef-dbc1-4389-b629-bbaabcd7b230",
   "metadata": {},
   "source": [
    "+ Applications of clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a9ba3c-4c57-42e5-911a-08200efa4887",
   "metadata": {},
   "source": [
    "There are 7 examples of clustering algorithms in action.\n",
    "\n",
    "Identifying Fake News. Fake news is not a new phenomenon, but it is one that is becoming prolific. ...\n",
    "Spam filter. ...\n",
    "Marketing and Sales. ...\n",
    "Classifying network traffic. ...\n",
    "Identifying fraudulent or criminal activity. ...\n",
    "Document analysis. ...\n",
    "Fantasy Football and Sports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c9d76e-44ee-42df-9410-3d826222811c",
   "metadata": {},
   "source": [
    "types of clustering algorithm\n",
    "\n",
    "partitioned based clustering\n",
    "\n",
    "relatively efficient\n",
    "eg k means k median, fuzzy c -means\n",
    "\n",
    "\n",
    "+ Hierachical clustering \n",
    "produces trees of clusters\n",
    "e.g Agglomerative ,Divisive \n",
    "\n",
    "Density based clustering \n",
    "produces arbitrary shaped clusters \n",
    "e.g DBSCAN algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3b885e-51e3-4a35-b768-8af1e92781f6",
   "metadata": {},
   "source": [
    "### Week 12: Day 3 – Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191f0e71-0cd0-4e43-b57d-a7d60b468129",
   "metadata": {},
   "source": [
    "###  Intro to Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9b44a7-26f6-41eb-81b9-5c4dd546b650",
   "metadata": {},
   "source": [
    "Course outline\n",
    "\n",
    "+ High Level application to clustering\n",
    "\n",
    "+ Application to Clustering \n",
    "\n",
    "+ Different types of clustering Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99707a0-be6c-484e-b532-1a0d7e20ba01",
   "metadata": {},
   "source": [
    "Imagine that you have a customer data set and you need to apply customer segmentation on thus historical data.\n",
    "\n",
    "Customer Segmentation is a practice of pratitioning a customer base to group some individuals that have similar characterictics . It is a significant strategy as it allows the business to allow specific group of customers so as to more effectively allocate resources. For example,one group may contain customers who have high profit and low risk ie more likely to purchase product or subscibe for a service.Knowing this information allows the business to devote more time and attention to retaining these customers. Another group may include customers from non profit or organisations and so on.\n",
    "\n",
    "A General segmentation process is not usually feasible for large volumes of varied data therefore you need an analytical approach to derive insightment and groups from  large datasets. Customers can be grouped based on several factors,including Age, Gender, Interest,Spending habits and so on. The important requirement is to use the available data to understand and identify how customers are similar to each othe . Lets see how to divide a set of customers into categories based on characterictics they share. One of the most adopted approach that can be used for customers segmenation is Clustering .Clustering can group data only on supervised based on te similarity of customers to each other. It will partition your customers into mutually exclusive groups.\n",
    "for example, into 3 clusters. The customers and each cluster are similar to each other demographically.\n",
    "Now we can create a profile for each group considering the common characteristics of each cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435e8b6c-9342-4385-8012-90b09de09834",
   "metadata": {},
   "source": [
    "Cluster       Group Name \n",
    "\n",
    "Group 1  :    Affluent and Middle Aged\n",
    "\n",
    "Group 2 :     Young Educated and Middle Income\n",
    "\n",
    "Group 3 :   Young and Low Income\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f517f5-9a50-4a55-91df-4c357b78562e",
   "metadata": {},
   "source": [
    "Finally , we can assign each individual in our dataset to one of this group or segment of customers . Imagine that you cross join this segment of dataset with the dataset of the product or services that customers purchase from your company. This information will really help to understand and protect the difference in individual customer preferences and their buying behaviours across various products.\n",
    "\n",
    "Indeed having this information will allow your company to develop personalized experiences for each segment. customer Segmentation is one of the popular usages of clustering.Cluster analysis also have many other applications and different domians "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f153f2-facb-4d85-a29a-88c17884096b",
   "metadata": {},
   "source": [
    "+ What is Clustering ?\n",
    "\n",
    "\n",
    "Clustering means finding clusters on a dataset unsupervised.\n",
    "\n",
    "\n",
    "+ What is a Cluster? \n",
    "\n",
    "This is a group of objects that are similar to other objects in the cluster, and dissimilar to data points in other clusters.\n",
    "\n",
    "+ What is the difference between clustering and classification?\n",
    "\n",
    "Classification algorithms predict categorical class labels . This means assigning instances to predetermined classes such as 'Defautled' or 'non Defaulted'.\n",
    "\n",
    "For e.g if an analyst want to analyse customer data in other to know which customer might default on her payment. She uses a labelled dataset as training data and uses classification approach such as decision trees ,support vector machines or svm or logistic regression to predict a default value for a new or unknown customer.\n",
    "\n",
    "Generally speaking classification is a supervised learning where each training data instance belongs to a particular class.In clustering however, the data is unlabelled and the process is unsupervised.For example, we can use a clustering algorithm such as K-means to group similar customers as mentioned and assign them to a cluster based on whether they share similar attributes such as age ,education and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5438ceef-f2d2-49e6-982e-eacafe03af78",
   "metadata": {},
   "source": [
    "+  Clustering  Applications:\n",
    "    \n",
    " + In the Retail/ Marketing Industry:\n",
    " \n",
    "i. Identifying buying patterns of customers\n",
    "Clustering is used to find association among customers based on their demographic characteristics and use that information in identifying buying patterns of various customer group.\n",
    "\n",
    "ii. Recommendating new books or movies to  new customers \n",
    "\n",
    "It can be used in recommendation systems to find the group of similar items or similar users and use it for collaborative filtering to recommend things like books and movies to customers.\n",
    "\n",
    "iii. Banking:\n",
    "In banking analyst finds clusters of normal transactions to find the pattrens of fraudulent credict card usage . \n",
    "\n",
    "It is also used to identify clusters of customers(e.g.to find loyal custors vs chain customers)\n",
    "\n",
    "iv. Insurance:\n",
    "\n",
    "Clustering is used in fraud detection in claims analysis or to evaluate the insurance risk of certain customers based on their segments.\n",
    "\n",
    "v. Publication / media :\n",
    "Clustering is used to Auto-categorize news based on their content or to tag news then cluster it so as to recommend similar news articles to readers.\n",
    "\n",
    "v1. Medicine:\n",
    "It can be used to categorize patient behaviour based on their similar characteristics. So as to identify successful medical therapies for different illnesses.\n",
    "\n",
    "vii. Biology:\n",
    "Clustering is used to group genes with similar expression patterns or to cluster genetic markers to identify family ties "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c6ad1d-29c0-42cf-95d4-19b606e1b1ed",
   "metadata": {},
   "source": [
    "+ Why Clustering ?\n",
    "\n",
    "If you look around ,you will find many other application of clustering, generally , clustering can be used for one of the following purposes: \n",
    "\n",
    "1. Exploratory data analysis\n",
    "\n",
    "2. Summary generation or reducing the scale\n",
    "\n",
    "3. Outlier detection especially to be used for fraud detection or noise removal.\n",
    "\n",
    "4. Finding duplicates in dataset\n",
    "\n",
    "5. Pre-processing step in data prediction, other data mining task or as part of a complex sysytem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29813757-a78e-4dd5-9dcb-56265d0c4828",
   "metadata": {},
   "source": [
    "+ Clustering algorithms\n",
    "We have different clusterin algorithm\n",
    "\n",
    "a. Partitioned-based Clustering:\n",
    "    \n",
    "This  is a group of clustering algorithm   that produces fear like clusters  such a L-Means, K-Median, Fuzzy c-Means. These algorithms are relatively efficient and are used for medium and large size data bases\n",
    "\n",
    "b. Hierachical Clustering:\n",
    "This produces trees of clusters such as agglomerative  and Divisive algorithm. Thes group of algorithm are very intuitive and are generally good for use with small size dataset\n",
    "\n",
    "c. Density-based Clustering:\n",
    "This produces arbitrary shape clusters, thy are especially good when dealing with special clusters ohen there is no icing in your dataset e.g the DBSCAN algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069633de-43a8-4180-8c65-d8a2d5691d23",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Intro to Hierarchical Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce1990f-2d63-4dc5-8780-395f7babe379",
   "metadata": {},
   "source": [
    "An international team of scientist lead by UCLA biologist used this dendogram to report genetic data for more than 900 dogs from 85 breeds and more than 200 wild gade wolves, including populations from north America, Europe, the middle East and East Asia. The y use molecular genetic techniques to analyze more than 48,000 genetic markers.\n",
    "\n",
    "This diagram shows hierachical clustering of these animals based on the similarity in their genetic data.\n",
    "\n",
    "Hierarchical Clustering algorithms build a Hierarchy\n",
    "of clusters where each node is a cluster consists of the clusters of its daughter nodes.\n",
    "\n",
    "Strategies for hierarchcal clstering generally falls into two types:\n",
    "\n",
    "i. Divisiive\n",
    "\n",
    "ii. Agglomerative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169abb4d-3930-4ee5-8c29-e196c69a44a2",
   "metadata": {},
   "source": [
    "i. Divisiive :\n",
    "    \n",
    " Divisiive is top down, so you start with all observations in large clusters and break it down into smaller pieces.This means dividing the cluster.\n",
    " \n",
    " \n",
    "ii. Agglomerative:\n",
    "Agglomerative is the opposite of divisive.\n",
    "It is button up where each observation starts in its own cluster and pairs as clusters are matched together as they move up the hierarchy. ii. Agglomeration means to emash or collect things, which is exactly what this does with cluster.\n",
    "\n",
    "The Agglomerative approach is more popular among data scientist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b9f91f-b34e-4337-9587-6ea4d6c406e8",
   "metadata": {},
   "source": [
    "###### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8de7f6-aaf4-4e70-b39d-ab5154bfebad",
   "metadata": {},
   "source": [
    "Sample of Agglomerative clustering:\n",
    "    \n",
    "This method builds the individual hierarchy by progressively merging clusters. For e.g ,let's say we want to cluster 6 citis in Canada based on their distances from one another, They are \n",
    "\n",
    "+ Toronto\n",
    "\n",
    "+ Ottawa\n",
    "\n",
    "+ Mentreal  \n",
    "\n",
    "+ Winnipeg\n",
    "\n",
    "+ Vancouver\n",
    "\n",
    "+ Edmonton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8743937-688c-4150-ad78-f3687f673301",
   "metadata": {},
   "source": [
    "We constuct distance matrix at this stage where the numbers in the rows, i column j(dis(i,j) is the distance between the i and j cities. Infact this tabel shows the distances between each pair of cities. The algorithm is started by assigning each city to its own cluster. So if we have 6 cities ,we have 6 clusters,each conaining just one city. Lets know each city bty showing the first 2 characters of its name. The first step is to determine which city(Cluster) to march into a cluster. Usually , we want to take the 2 closest clusters according to the chosen distance. Looking at the matrix distance , Ottawa\n",
    "and  Mentreal are the closest clusters, so we make a luster out of them (OT, MO), notice that we just used a single 1 dimensional picture feature hre but our object can be multi-dimensional and distance measuerment can either be Euclidean, Pearson, average distance or many others depending on data set and domain knowledge. Anyhow we have to merge this two closest cities and distance matrix as well. So rows and columns are merged as thte cluster is constructed. as we can see in the distance matrix constructed .As you can see in the distance matrix,Row and columns related to (OT/MO) are merged as the cluster is constructed.\n",
    "\n",
    "Then, the distance from all these cities to new clusters get updated .\n",
    "\n",
    "+ How does this happen?\n",
    "+ How do we calculate the distance from Winnipeg to the OT/MO cluster.\n",
    "\n",
    "There are differnt approaches ,but let's assume you just select a distance from the center of the OT/MO cluster to WI. Updating the distance matrix ,we now have one less cluster.\n",
    "\n",
    "Next, we look for the closest cluster once again\n",
    "\n",
    "OT/TO/Mo which creates another cluster. In the next step, the closest distance is between the VA/ED clustter. Forming a new cluster their data in the cluster table gets updated.\n",
    "\n",
    "Essentially , the rows and columns are merged as the clusters are merged and the distance updated.\n",
    "\n",
    "This is a common way to implement this type of clustering and has the benefit of catching distances between  clusters. In thesame way,Agglomerative algorithm proceeds by merging clusters.\n",
    "\n",
    "We will repeat the process until al clusters are merged and the tree becomes completed. It means until all cities are clustered into a single cluster of size 6"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0270a78-443d-46b4-a74f-7f76499b7c2f",
   "metadata": {},
   "source": [
    "         TO    OT    VA      MO      WI          ED \n",
    "    \n",
    "+ TO             351    3363   505    1510        2699\n",
    "\n",
    "+ OT                  3543    167    1676       2840\n",
    "\n",
    "+ VA                          3690   1867       819\n",
    "\n",
    "+ MO                                  1824       2976               \n",
    "\n",
    "+ WI                                             1195\n",
    "\n",
    "+ ED\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae8bc644-12cb-4f24-b5ca-fda7f09fb71c",
   "metadata": {},
   "source": [
    "                 TO/OT/MD              VA/ED/WI\n",
    "    \n",
    "TO/OT/MO                                 1676                          \n",
    "\n",
    "VA/ED/WI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3601ded5-435a-47ca-af86-94cbfd46b896",
   "metadata": {},
   "source": [
    "+ Hierarchical clustering is typically visualized as a dendogram as shown on the slide. Each merge is represented by a horizontal line, the white coordinate of the horizontal line is the similarity of the two clusters that emerged where cities are view as  singleto the clusters by moving up from the button layer to the top node. A dedogran allows us to reconstruct the history of merges that resulted in the depicted clustering.\n",
    "\n",
    "Essentially, hierarchical clustering does not require a pre specified number of clusters. However, in some applications,we want to partition or disjoint clusters ,just as in flat clustering.\n",
    "\n",
    "In those case, the hierachy needs to be cut at some point. For example here, cutting in a specific level of similarity, we create 3 clusters of similar cities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d455cec2-2e33-4bbf-aaab-ee2cd719d8ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### More on Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b5e3f6-ddd4-421a-a8be-799145f1dd14",
   "metadata": {},
   "source": [
    "+ Agglomerative algorithm for hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c932c4-870b-49a8-a527-e1c7ab42f4bb",
   "metadata": {},
   "source": [
    "Agglomerative algorithm is a buttom top approach.\n",
    "Let's say our dataset has n dataset:\n",
    "\n",
    "1. Create n cluster,one for each data point.\n",
    "Then each point is assigned as a cluster.\n",
    "\n",
    "2. Compute the Proximity Matrix, which will be an n x n table. \n",
    "3. Repeat \n",
    "after that, we want to iteratively run the following steps until the specified cluster number is reached or until there is only one cluster left.\n",
    "First,\n",
    "i. Merge the two closet clusters\n",
    "Distances are computed already\n",
    "ii.Update the proximity matrix with the mean values.\n",
    "we stop after we have rached the specified number of clusters or \n",
    "\n",
    "4. Until  there is only one cluster remaining.\n",
    "\n",
    "with the result stored in the dendogram. In the proximity matrix, we have to measyre the distances between clusters and also merge the clusters that are nearest.\n",
    "\n",
    "The key operation is the computation of the proximity between the clusters with one point and also clusters with multiple data points. \n",
    "At this point there are number of key points that needs to be answered.\n",
    "\n",
    "For instance, how do we measure the distances between clusters and how do we define the nearest among clusters. We can also can ask, which point to be used.\n",
    "\n",
    "+ How to calculate the distance between two clusters with one point each.\n",
    "\n",
    "let's assume that we have a dataset of patient 1 and patient 2 and we want to cluster them using hierarchical clustering. So our data points are patients with the feature set of 3 dimension for example, age , Body mass Index and Blood Pressure."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0316a42a-2670-4253-9dd2-424cd7baec16",
   "metadata": {},
   "source": [
    "Patient 1                            Patient 2\n",
    "\n",
    "Age     BMI       BP                Age     BMI       BP\n",
    "54      190      120                 50     200      125\n",
    "\n",
    "\n",
    "     Dis(p1,p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093a940a-f1e7-4f90-a9fd-d0dac4c142be",
   "metadata": {},
   "source": [
    "We can use different distance measuerment to calculate the proximity matrix, for instance, Euclidean distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee0ef53-e9c6-4a06-b4c1-0344c1979c3f",
   "metadata": {},
   "source": [
    "+ Similarity / Distance\n",
    "\n",
    "If we have a dataset of n patient, we can build an n x n disimilarity distance matrix. It will give us the distance of clusters with one data point. However,as mentioned we merged clusters in agglomerative clustering.\n",
    "Now , the question is , how can we calculate the distance between clusters when there multiple patientsin each cluster. We can use different criterias to find the closest clusters and merge them.\n",
    "\n",
    "In general,it completely depends on the data type, dimensionality of data and most importantly the domain knowledge of the data set.\n",
    "\n",
    "Infact, differnt approaches to definning the difference between clusters to distinguish the different algorithms.\n",
    "\n",
    "As you mighf imagine , there are multipl ways we can do this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f075be95-c4d8-4dd6-a4a6-9f26e9fde823",
   "metadata": {},
   "source": [
    "Distance between clusters\n",
    "\n",
    "+ Single-Linkage Clustering;\n",
    "   + Minimum distance between clusters.\n",
    "It is defined as the shortest distance between two points in each cluster, such a point A and B\n",
    "  \n",
    "  \n",
    "+ Complete-Linkage Clustering\n",
    "  + Maximum distance between clusters\n",
    "We are finding the longest distance between the points in each cluster, such as the distance between point A abd Point B.\n",
    " \n",
    "+ Average linkage Clustering or the mean distance.\n",
    "  + Average distance between clusters\n",
    "This mean that we are looking at the average distance of each point from one cluster to every point in another cluster.\n",
    "\n",
    "+ Centroid Linkage Clustering \n",
    "Centroid is th e average of the feature set of points in a cluster\n",
    "  + Distance between cluster centroids\n",
    "This linkage takes into account the centroid of each cluster and when determining the minimum dustance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fac1161-e26b-4cd2-b83e-d22b95509e3c",
   "metadata": {},
   "source": [
    "+ There are 3 main advantages to use in hierarchical clustering.\n",
    "\n",
    "i. Doesn't require number of clusters to be specified\n",
    "\n",
    "ii. Easy to implement.\n",
    "\n",
    "iii. Produces a  dendrogran, which helps with understanfing the data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "+ Disadvantages\n",
    "\n",
    "i. Can never undo any precious steps throughout the algorithm.\n",
    "For example, The algorithm clusters 2 points and later on we see that the connection was not a good one. the program cannot undo that step\n",
    "\n",
    "ii. Generally has long runtimes.\n",
    "The time complexity for the clustering can result in very long computation time in comparison with efficient algorithms such as KMeans.\n",
    "\n",
    "iii. Sometimes difficult to identify the number of clusters by the dendrogram.Finally, if we have a large dataset it can become difficult to determine the correct number of clusters by the dendrogram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ad4de5-1fe0-4083-88d6-1a2cc6888bbe",
   "metadata": {},
   "source": [
    "##### Hierarchical clustering Vs. K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70a477-e50c-4a8d-a390-33cc2273a76d",
   "metadata": {},
   "source": [
    "+ K-means\n",
    "\n",
    "1. Much more efficient for large dataset\n",
    "\n",
    "2. Requires the number of cluster to be specified\n",
    "\n",
    "3. Gives only one partitioning of the data based on the predefined  number of clusters.\n",
    "\n",
    "4. Potentially returns diferent  clusters each time it is run due to random initialization of centroids\n",
    "\n",
    "\n",
    "\n",
    "+ Hierarchical Clustering\n",
    " \n",
    "1. Can be slow for large datsets\n",
    "2. Does not require the number of clusters to run (to be specified)\n",
    "3. Gives more than one partitioning depending on the resolution\n",
    "\n",
    "4. Always generated the same cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b2efb9-1ea7-40ac-969b-7f6dc496c103",
   "metadata": {},
   "source": [
    "### Python Training Hierarchical Clustering Explained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aee4b6-49e4-4058-8e00-366d1c50dea1",
   "metadata": {},
   "source": [
    "+ Hierarchical Clustering  - Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93897ddf-d9c8-4aac-a265-19b0c3ede14b",
   "metadata": {},
   "source": [
    "+ Hierarchical Clustering\n",
    "\n",
    "This is an Approach to clustering that builds hierarchies in to main approaches.\n",
    "+ Clustering is griouping of points into various various clusters or group.\n",
    "\n",
    "There are two main types of Hierarchical Clustering\n",
    "\n",
    "+ Agglomerative :\n",
    "\n",
    "This is a buttom -up strategy were each observation starts in their own cluster,and pairs to the nearest and forms a pair of a clusters are merged upwards in the hierarchy and we will be left only with one cluster.\n",
    "The most commonly used clustering is Agglomerative.\n",
    "\n",
    "+ Divisive: \n",
    "\n",
    "This is a top-down approach were all observations start out in the same cluster,and then the clusters are split recursively downwards in the hierarchy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48778bd2-ee8b-4ec7-9ad9-0b44ed3b3700",
   "metadata": {},
   "source": [
    " Agglomerative Clustering :\n",
    " \n",
    "+ The idea behind it is to ensure nearby points ends up in the same cluster\n",
    "\n",
    "+ Starts with a collction of C of n singleton Clusters\n",
    "  - each cluster contains one data point: ci={xi}\n",
    "  If we hae n number of data points we can have n number of clusters.\n",
    "If we are working on clustering , we need to specify the number of clusters\n",
    "+ Repeat until onlt one cluster is left:\n",
    "Let's assume we start with 5 data, the two data points will be form 1 cluster, the remaining 2 data points will form another cluster, then it combines into a single cluster. This cluster keeps on repeating until only one cluster is left.\n",
    "\n",
    "  - find a pair of clusters that is closest:  min D(ci,cj)\n",
    "  \n",
    "  - merge the clusters ci, cj into a new cluster ci+j\n",
    "  \n",
    "   - removes ci,cj from the collection Ci add ci+j\n",
    "   \n",
    "+ Produces a dendrogram: hierarchical tree of clusters \n",
    "We can use a scatter plot to describe or to demonstrate the clusters or we can use a dendrogram. Dendrogram is the most appropriate chart we can use to show the hierarchical trees of cluters\n",
    "\n",
    "+ We need to define a distance metric over clusters\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70af27a-ec25-497a-bdeb-aa5eaaa3e5a0",
   "metadata": {},
   "source": [
    "##### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91e22579-fe09-41e2-a68e-23c0980cd121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster,datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c4eb1b71-eaa4-472b-b880-9145b580e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris dataset\n",
    "iris=datasets.load_iris()\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4092759d-6d46-4808-af91-0b835b2a76fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be clustering on only 2 variables,the sepal length and sepal width\n",
    "# Lets create a variable x\n",
    "# We will be extracting the sepal lengthand width in centi meter.\n",
    "x=iris.data[:,:2]\n",
    "y_iris=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8315f21d-1f8b-41b2-adba-4d34e978b6ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5]\n",
      " [4.9 3. ]\n",
      " [4.7 3.2]\n",
      " [4.6 3.1]\n",
      " [5.  3.6]\n",
      " [5.4 3.9]\n",
      " [4.6 3.4]\n",
      " [5.  3.4]\n",
      " [4.4 2.9]\n",
      " [4.9 3.1]\n",
      " [5.4 3.7]\n",
      " [4.8 3.4]\n",
      " [4.8 3. ]\n",
      " [4.3 3. ]\n",
      " [5.8 4. ]\n",
      " [5.7 4.4]\n",
      " [5.4 3.9]\n",
      " [5.1 3.5]\n",
      " [5.7 3.8]\n",
      " [5.1 3.8]\n",
      " [5.4 3.4]\n",
      " [5.1 3.7]\n",
      " [4.6 3.6]\n",
      " [5.1 3.3]\n",
      " [4.8 3.4]\n",
      " [5.  3. ]\n",
      " [5.  3.4]\n",
      " [5.2 3.5]\n",
      " [5.2 3.4]\n",
      " [4.7 3.2]\n",
      " [4.8 3.1]\n",
      " [5.4 3.4]\n",
      " [5.2 4.1]\n",
      " [5.5 4.2]\n",
      " [4.9 3.1]\n",
      " [5.  3.2]\n",
      " [5.5 3.5]\n",
      " [4.9 3.6]\n",
      " [4.4 3. ]\n",
      " [5.1 3.4]\n",
      " [5.  3.5]\n",
      " [4.5 2.3]\n",
      " [4.4 3.2]\n",
      " [5.  3.5]\n",
      " [5.1 3.8]\n",
      " [4.8 3. ]\n",
      " [5.1 3.8]\n",
      " [4.6 3.2]\n",
      " [5.3 3.7]\n",
      " [5.  3.3]\n",
      " [7.  3.2]\n",
      " [6.4 3.2]\n",
      " [6.9 3.1]\n",
      " [5.5 2.3]\n",
      " [6.5 2.8]\n",
      " [5.7 2.8]\n",
      " [6.3 3.3]\n",
      " [4.9 2.4]\n",
      " [6.6 2.9]\n",
      " [5.2 2.7]\n",
      " [5.  2. ]\n",
      " [5.9 3. ]\n",
      " [6.  2.2]\n",
      " [6.1 2.9]\n",
      " [5.6 2.9]\n",
      " [6.7 3.1]\n",
      " [5.6 3. ]\n",
      " [5.8 2.7]\n",
      " [6.2 2.2]\n",
      " [5.6 2.5]\n",
      " [5.9 3.2]\n",
      " [6.1 2.8]\n",
      " [6.3 2.5]\n",
      " [6.1 2.8]\n",
      " [6.4 2.9]\n",
      " [6.6 3. ]\n",
      " [6.8 2.8]\n",
      " [6.7 3. ]\n",
      " [6.  2.9]\n",
      " [5.7 2.6]\n",
      " [5.5 2.4]\n",
      " [5.5 2.4]\n",
      " [5.8 2.7]\n",
      " [6.  2.7]\n",
      " [5.4 3. ]\n",
      " [6.  3.4]\n",
      " [6.7 3.1]\n",
      " [6.3 2.3]\n",
      " [5.6 3. ]\n",
      " [5.5 2.5]\n",
      " [5.5 2.6]\n",
      " [6.1 3. ]\n",
      " [5.8 2.6]\n",
      " [5.  2.3]\n",
      " [5.6 2.7]\n",
      " [5.7 3. ]\n",
      " [5.7 2.9]\n",
      " [6.2 2.9]\n",
      " [5.1 2.5]\n",
      " [5.7 2.8]\n",
      " [6.3 3.3]\n",
      " [5.8 2.7]\n",
      " [7.1 3. ]\n",
      " [6.3 2.9]\n",
      " [6.5 3. ]\n",
      " [7.6 3. ]\n",
      " [4.9 2.5]\n",
      " [7.3 2.9]\n",
      " [6.7 2.5]\n",
      " [7.2 3.6]\n",
      " [6.5 3.2]\n",
      " [6.4 2.7]\n",
      " [6.8 3. ]\n",
      " [5.7 2.5]\n",
      " [5.8 2.8]\n",
      " [6.4 3.2]\n",
      " [6.5 3. ]\n",
      " [7.7 3.8]\n",
      " [7.7 2.6]\n",
      " [6.  2.2]\n",
      " [6.9 3.2]\n",
      " [5.6 2.8]\n",
      " [7.7 2.8]\n",
      " [6.3 2.7]\n",
      " [6.7 3.3]\n",
      " [7.2 3.2]\n",
      " [6.2 2.8]\n",
      " [6.1 3. ]\n",
      " [6.4 2.8]\n",
      " [7.2 3. ]\n",
      " [7.4 2.8]\n",
      " [7.9 3.8]\n",
      " [6.4 2.8]\n",
      " [6.3 2.8]\n",
      " [6.1 2.6]\n",
      " [7.7 3. ]\n",
      " [6.3 3.4]\n",
      " [6.4 3.1]\n",
      " [6.  3. ]\n",
      " [6.9 3.1]\n",
      " [6.7 3.1]\n",
      " [6.9 3.1]\n",
      " [5.8 2.7]\n",
      " [6.8 3.2]\n",
      " [6.7 3.3]\n",
      " [6.7 3. ]\n",
      " [6.3 2.5]\n",
      " [6.5 3. ]\n",
      " [6.2 3.4]\n",
      " [5.9 3. ]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ec339b49-4393-4856-bc9b-96fec58b16b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Agglometric clusteringand plot using a scatter plot\n",
    "# definse the number of clusters(n_clusters=2)\n",
    "# linkage='ward' means from button to top\n",
    "# We need x and y to plot into a scatter ploy\n",
    "# we will create the clusters in thesame chart instead of multiple chart\n",
    "hc=AgglomerativeClustering(n_clusters=2,affinity='euclidean',linkage='ward')\n",
    "y_hc=hc.fit_predict(x)\n",
    "plt.scatter(x[y_hc==0,0],x[y_hc==0,1],s=10,c='red',label='cluster1')  \n",
    "# Add 1 more cluster\n",
    "plt.scatter(x[y_hc==1,0],x[y_hc==1,1],s=10,c='blue',label='cluster2')  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1f6bb52c-ebc4-4956-a522-e6cfd03e58e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In agglometric clus, we need to find out the 2 nearest clusters from our plot and combine them and form into one new cluster\n",
    "# We find another nearest cluster\n",
    "# we can decrease the size of the value to hel us understand our scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5b73b2f0-c697-4738-85be-aeda05fc155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets target only 10 values\n",
    "x=iris.data[:10,:2]\n",
    "y_iris=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b796fa0-3152-4c34-a756-9a898aca6077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5]\n",
      " [4.9 3. ]\n",
      " [4.7 3.2]\n",
      " [4.6 3.1]\n",
      " [5.  3.6]\n",
      " [5.4 3.9]\n",
      " [4.6 3.4]\n",
      " [5.  3.4]\n",
      " [4.4 2.9]\n",
      " [4.9 3.1]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "debd3f9e-1fe7-4f1b-a60e-f9ce6c75a687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hc=AgglomerativeClustering(n_clusters=2,affinity='euclidean',linkage='ward')\n",
    "y_hc=hc.fit_predict(x)\n",
    "plt.scatter(x[y_hc==0,0],x[y_hc==0,1],s=10,c='red',label='cluster1')  \n",
    "# Add 1 more cluster\n",
    "plt.scatter(x[y_hc==1,0],x[y_hc==1,1],s=10,c='blue',label='cluster2')  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b5892723-d630-459c-add6-cc7b47d99569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The hiegth of the graph depends on the distance between 2 clusters or the Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5f0286f0-3d01-4387-9e6b-c3736fc16ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If i want to present the graph as a dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "63ce7d37-1980-44e8-a2bc-1025fb1d5ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=iris.data[:,:2] # this includes all the data\n",
    "y_iris=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "03d5bc9e-3d79-4701-9444-1c45678beb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dendrogram=sch.dendrogram(sch.linkage(x,method='ward'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e5f2a08c-b930-4438-9877-5aa4e55d2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to create for 20 records\n",
    "x=iris.data[:20,:2]\n",
    "y_iris=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ed957a7d-67c1-4d8f-a012-cbabc0388736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dendrogram=sch.dendrogram(sch.linkage(x,method='ward'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "970b274a-ae14-42b6-b87f-e8c38c7d3c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you observe the numbers are not in sequence, this is bcos it automatically finds out the nearest 2 clusters  and place them \n",
    "# Te height btw 0 and 17 is less,5 and 16 is less, it means that the steps btw these 2 clusters are very less.\n",
    "# We also have the euclidean distance.\n",
    "# we can count the headers to find the number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2c0be1d7-1ff4-4eac-85be-5ae5e8d5b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBSERVATION: MY NUMBERS FOR THE DENDROGRAM IS NOT SHOWING ????"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9185e1-bdf2-4e66-90e7-a54163849acd",
   "metadata": {},
   "source": [
    "+ What is the businees use /implication of these clustering ?\n",
    "\n",
    "+ It can be useful in a study to predict the cost impact of deregulation and it will  perform the requisite analysis Economics will be required to build a detailed cost model of the various utilities.\n",
    "\n",
    "+ and it would save a considerable amount of time and effort by clustering the similar type of utilities, building a detailed cost model for just one typical utility in each cluster and then scaling up from these models to estimate the result of all utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1e21e9b9-da74-4aa1-9c88-18a7d8930c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\Desktop\\\\Wholesale+customers+data.csv'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(r\"C:\\Users\\user\\Desktop\\Wholesale+customers+data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc607abc-eeed-4372-92fa-29c04f9841ef",
   "metadata": {},
   "source": [
    "### Required Reading: Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e820a383-14c4-4b9b-8250-9f8c5bfef4e4",
   "metadata": {},
   "source": [
    "+  Hierachical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd5af9-dc9c-42ea-a3a9-87b013194347",
   "metadata": {},
   "source": [
    "builds a hierachy of clusters where each node is a cluster consists of the clusters of its daughter nodes.\n",
    "\n",
    "It has two startegies \n",
    "\n",
    "Divisive\n",
    "you start with al observations in a llarge cluster and break it dowm into smaller pieces. it can also be defined as dividing the cluster of dividing cluster\n",
    "\n",
    "Agglomerative\n",
    "\n",
    "It is the opposite of divisive , it is button up where each observation starts in its own cluster and pairs as clusters are matched together as they move up the hierachy.\n",
    "\n",
    "Agglomeration means to emmasss or colllect things. this approach is more popular among data scientist\n",
    "\n",
    "E.g if we want to cluster 6 cities in America based on their distances from one another.\n",
    "\n",
    "hierarical clustering is represented as a dendrogram ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53df683-103c-453a-9150-0d64e8fee01a",
   "metadata": {},
   "source": [
    "Why Use Hierarchical Clustering?\n",
    "\n",
    "Hierarchical clustering has the following advantages:\n",
    "    \n",
    "1. Unlike K Means clustering, for hierarchical clustering, you do not have to sp\n",
    "the number of centroids clustering.\n",
    "2. With dendrograms, it is easier to interpret how data has been clustered.\n",
    "Disadvantages of Hierarchical Clustering Algorithm\n",
    "The following are some of the disadvantages of the hierarchical clustering\n",
    "algorithm:\n",
    "1. Doesn’t scale well on unseen data.\n",
    "2. Has higher time complexity compared to K Means clustering.\n",
    "3. Difficult to determine the number of clusters in case of a large dataset.\n",
    "In the next section, you will see how to perform agglomerative clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4f8d19-e03b-4cf8-9994-f797933dae11",
   "metadata": {},
   "source": [
    "#### Hierarchical Clustering: Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda760c1-5a19-4bc4-b687-66c404b48b71",
   "metadata": {},
   "source": [
    "1. Which of the following clustering type has characteristic shown in the below figure?\n",
    "\n",
    "\n",
    "hierachical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07741dad-74c3-4577-9cb9-ed81505df066",
   "metadata": {},
   "source": [
    "2. Point out the correct statement.\n",
    "\n",
    "Hierarchical clustering is also called HCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a427d5a4-bfe2-4f16-96ee-88819769a60a",
   "metadata": {},
   "source": [
    "The choice of an appropriate metric will influence the shape of the clusters, as some elements may be close to one another according to one distance and farther away according to another.\n",
    "he choice of an appropriate metric will influence the shape of the clusters\n",
    "Hierarchical clustering is also called HCA\n",
    "In general, the merges and splits are determined in a greedy manner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b499b6-5624-40e3-a384-a221fe3a69f1",
   "metadata": {},
   "source": [
    "3. Which of the following is finally produced by Hierarchical Clustering?\n",
    "\n",
    "Tree showing how close things are to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6c3097-f607-4dd2-9cbc-4ad5a44715d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78842d54-bf40-4538-a878-61f97bff8242",
   "metadata": {},
   "source": [
    "Final estimate of cluster centroids\n",
    "Tree showing how close things are to each other\n",
    "Assignment of each point to clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08b6f86-21d8-4818-81e5-1ccd5fa31faa",
   "metadata": {},
   "source": [
    "4. Which of the following is required by K-means clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3ad3ef-ef10-4e4a-965e-59975b5363c9",
   "metadata": {},
   "source": [
    "Defined distance metric\n",
    "Number of clusters\n",
    "Initial guess as to cluster centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d5df51-c980-4cdb-901e-077d312458ee",
   "metadata": {},
   "source": [
    "5.Which of the following combination is incorrect?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069cf72a-3068-4c6d-bdcf-fbecac3e12ed",
   "metadata": {},
   "source": [
    "Continuous – euclidean distance\n",
    "Continuous – correlation similarity\n",
    "Binary – manhattan distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730e320f-bc4e-4114-97f5-a44371a53fea",
   "metadata": {},
   "source": [
    "Tree showing how close things are to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c2a1c31a-5863-4839-ac58-d6bf44cb6116",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (Temp/ipykernel_6740/1298962659.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_6740/1298962659.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    08173631392\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n"
     ]
    }
   ],
   "source": [
    "08173631392"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a87a08e-206a-4a4a-9bf7-4c917d4f0e8d",
   "metadata": {},
   "source": [
    "Graph\n",
    "\n",
    "directed\n",
    "\n",
    "undirected\n",
    "\n",
    "Weighted graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9461f519-e8e2-4e98-8772-02ac1fd13382",
   "metadata": {},
   "source": [
    "● Weighted Graphs\n",
    "Many graphs can have edges containing a weight associated to\n",
    "represent a real world implication such as cost, distance, quantity \n",
    "\n",
    "\n",
    "Weighted graphs could be either directed or undirected graphs.\n",
    "The one we have in this example is an undirected weighted graph.\n",
    "The cost or distance from node green to orange and vice versa is 3.\n",
    "We could represent this relationship as a triplet like (u, v, w)\n",
    "which shows from where the edge is coming in, where it goes and\n",
    "the cost or distance between the two nodes. Like our previous\n",
    "example, if you want to travel between two cities, say city green and\n",
    "orange, we would have to pay off a cost of 3$ or in other terms, we\n",
    "would have to drive 3 miles. These metrics are self-defined and\n",
    "could be changed according to the situations. For a more\n",
    "elaborated example, consider you have to travel to the city pin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5978a80c-39dc-419c-8785-581f1ab13687",
   "metadata": {},
   "source": [
    "special graph\n",
    "\n",
    "tree\n",
    "\n",
    "The most important type of special graph is a tree. It’s an\n",
    "undirected graph with no cycles. Equivalently, it has N nodes andN — 1 edge\n",
    "\n",
    "\n",
    "● Rooted Tree\n",
    "A rooted tree is a tree with a designated root node where all other\n",
    "nodes are either coming towards the root or going away from the\n",
    "root\n",
    "\n",
    "The node which is in red color is the root node. The leftmost tree is\n",
    "called an In-tree because all other nodes are coming towards the\n",
    "root node. The two other trees are Out-trees, because all other\n",
    "nodes are going away from the root."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992412f1-490c-4139-9dd4-4e57a2297ed4",
   "metadata": {},
   "source": [
    "● Directed Acyclic Graphs (DAGs)\n",
    "\n",
    "DAGs are directed graphs with no cycles. These graphs play\n",
    "an important role in representing structures with dependencies\n",
    "such as schedulers and compilers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79643c1c-0d1e-4ce1-82dc-b51b3fa08b98",
   "metadata": {},
   "source": [
    "● Bi-Partite Graphs\n",
    "\n",
    "A Bi-Partite Graph is a one whose vertices could be divided into two\n",
    "disjoint sets, say U and V, where each edge in the graph connects\n",
    "the vertices between U and V. Another similar definition to a BiPartite Graph is that the graph would be two colourable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8b2191-fac0-413a-9b98-6cbef3ef2f6a",
   "metadata": {},
   "source": [
    "Complete Graph\n",
    "\n",
    "We call a graph Complete iff, each pair of vertices has a unique edge\n",
    "connecting between them. A complete graph with n vertices is\n",
    "denoted as Kn.\n",
    "\n",
    "Complete graphs are considered to be the worst case graphs\n",
    "because of the number of edges to be traversed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8751562a-4850-4ffb-90fb-e1ab5add233a",
   "metadata": {},
   "source": [
    "Representation of Graphs\n",
    "\n",
    "\n",
    "Adjacency Matrix\n",
    "\n",
    "The efficient way is to use a matrix of size NxN where N is the\n",
    "number of nodes. We call this matrix an adjacency matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bad185-fa79-4235-8537-a388eb3a7384",
   "metadata": {},
   "source": [
    "Adjacency Lists\n",
    "\n",
    "Another important structure we use to store the node and edge\n",
    "information is an adjacency list. This is a map from nodes to lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c69588-d71d-48ee-9d47-93c7ae75bffd",
   "metadata": {},
   "source": [
    "● Edge Lists\n",
    "\n",
    "AN edge list is a way to represent a graph simply as an unordered\n",
    "list of edges. Assume the notation for any triplet (u, v, w) means:\n",
    "“ the cost from u to v is w”.\n",
    "\n",
    "The edge list is given in the right hand side corresponding to the\n",
    "directed weighted graph on the left hand side. Each pair in the list\n",
    "shows edge information between two nodes and associated weight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649d9889-9bf2-4ab8-91a5-066d884c8d61",
   "metadata": {},
   "source": [
    "Graphs size and shape can change\n",
    "\n",
    "isomophin two graphs that use thesame can also look diffent\n",
    "\n",
    "the structure of graph is non Eucledian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22357473-8f44-4590-a4ba-9818c5539d79",
   "metadata": {},
   "source": [
    "SCII, stands for American Standard Code for Information Interchange. It is a 7-bit character code where each individual bit represents a unique character. This page shows the extended ASCII table which is based on the Windows-1252 character set which is an 8 bit ASCII table with 256 characters and symbols. It includes all ASCII codes from standard ASCII, and it is a superset of ISO 8859-1 in terms of printable characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab42c16-b561-4c4b-af50-897bda614d76",
   "metadata": {},
   "source": [
    "Epoch comprise of one or more batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0224a74-a85f-4c65-b2c5-a8bfc9188c30",
   "metadata": {},
   "source": [
    "### Week 12: Day 4 – Graphs and Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da102bd-ca81-410b-b967-e811fe0fb973",
   "metadata": {},
   "source": [
    "#### Getting started with Graph Theory (16 Pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1201802b-9456-4991-9293-fae913f2bec9",
   "metadata": {},
   "source": [
    "### Understanding Graph Neural Networks 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977a06fd-a8f9-4a12-9ddb-436e459c7d37",
   "metadata": {},
   "source": [
    "#### An Introduction to Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e553ee76-e9bc-4b5f-937a-6558c3f88dc5",
   "metadata": {},
   "source": [
    "+ A simple Graph \n",
    "\n",
    "Graph consisits of nodes or vertices and connections between nodes whcih are called edges.The information about this connections in a graph can be represented in an adjacency matrix. The elements of the matrix indicates neted nodes with a 1, and disconnected nodes with a 0.\n",
    "\n",
    "Besides Adjacency matrices, exists  other ways to represent the connection such as adjency list.\n",
    "\n",
    "We will continue using the matrix representation. Finally the nodes and edges can have other properties called Node features and edge features.\n",
    "\n",
    "Let's assaume this graph is a molecule and the nodes are adams. And the nodes features which are the blue bars close to the nodes in the diagram can be for the adams type or the number of pro terms.\n",
    "\n",
    "for the edge features indicated by a black bar, we can use further informations such as the bond type.\n",
    "This is all we need to know about graphs to understand GNNs.\n",
    "\n",
    "Even though GNNs might be new for you. Graph data exists in many areas. Alot of datasets with molecules exists in\n",
    "\n",
    "+ medicine or pharmacy. These molecules as already mentioned . Is strcuterd as a graph consisting of Adams and bonds.\n",
    "\n",
    "+ Recommender sysyems\n",
    "\n",
    "E-commerce companies often use large knowledge graphs to build full recommended system.Interesting products or movies.\n",
    "\n",
    "+ Social Networks\n",
    "\n",
    "Another self explaining example are social networks such as face book where people stands for nodes which are connectd in self relationship. The people can have features such as Age,gender, favourite music and so on.\n",
    "\n",
    "+ 3D Games / Meshes\n",
    "\n",
    "Graph structures can be found in 3D games where the objects are mold as a polygon match,which is a connection of vertices.edges and phases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dda087a-57e8-4d07-aba0-e26ce3dc2191",
   "metadata": {},
   "source": [
    "+ Examples for Machine Learning Problems with Graph Data\n",
    "\n",
    "Some of the problems we can solve using graph in the ML context are as follows;\n",
    "+ Node-level Predictions\n",
    "This means you have a graph with unlabelled nodes and you want to predict attributes about these nodes or classify them. E.g Does this person smoke? (Unlabelled node).\n",
    "\n",
    "+ Edge-level prediction(Link prediction)\n",
    "\n",
    "Here you predict whether there will be a connection between two nodes in a graph. This used by companise to predict which customer is likely to buy which products next. Basically ,the connection between people and items. Next Netflix video?\n",
    "\n",
    "+ Graph-level preictions\n",
    "You can use the whole graph as input to classify it or predict an attribute of interest. This is commonly done with molecule data.For instance ,you want to identify if a molecule is a suitable drug.\n",
    "Is this molecule a suitable drug?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab5598b-5b1b-4bfe-9fc8-6be3e63ff366",
   "metadata": {},
   "source": [
    "+ Neural Networks\n",
    "\n",
    "In the past their are other approaches to handle graphs such as hand graphed features as input for ML models G = (V,E). However, graph data have some interest in properies that made it difficult to work with.\n",
    "\n",
    "We will find out how GNNs cope with all of these difficulties.\n",
    "\n",
    "As you might Know Neural network expect the fixed size input and this brings us to the first difficulty of graph data.\n",
    "\n",
    "Problems  of Graph data;\n",
    "\n",
    "+ Graph data is different\n",
    " - Difference 1 : size and shape\n",
    " \n",
    " The size and shape of graph might change within the data set. This might also be true for our data type such as images . Hre ,you can simple resize part or crop the images to thesame size.\n",
    " \n",
    " Such operations are not defined on graph data. If you have additional nodes or edges you cannot simply remove them. therefore, we need a method that can handle arbitrary input chips. \n",
    "+ Differrence 2\n",
    "   + Another feature of graph which is called isomorphism in graph theory says that graph that looks difference can still be structurally identical.\n",
    "If you flip the image on the left,you will get an entirely new image.\n",
    "If you flip the graph on the left  however, the only thing that changes is the order of the nodes. The algorithm that is supposed to handle graph data is to be Permutation Invariance. This is also the reason why you cannot directly use, Adjacency matrix as input for a fit forward network as it is sensitive to changes in the node order.\n",
    "\n",
    "+ Difference 3 - Grid Structure\n",
    "\n",
    "Finally,the strcture of graph is non euclidean. For images ,you have a clear grid that can be expressed by x and y coordinates. Graphs are dynamic strctures that are laid differently in space and distance matrix such as Euclidean distance are not clearly defined. for instance, you cannnot clearly say how close node A are. You can add credit card in it but they did not incoperate the edge information between nodes. This is also the reason why the machine learning area of graphs is called geometrics deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915dec79-2800-46e8-ab5e-1b9bb8a0e316",
   "metadata": {},
   "source": [
    "+ Fundamental Idea of GNNs\n",
    "\n",
    "i.Learning a for neural networks suitable representation of graph data\n",
    "It is also called Representation learning.\n",
    "\n",
    "Further information about the graph including the node features stored in an Adjancy matrix, GNN output neural representations which are also called embeddngs(node level embeddings) for each of the nodes. This node embeddings contains the strap roll as well as the feature information about the other nodes in the graph. This means each node ,know something about the other node, the connection to this node and its context in the graph(graph Knowledge).\n",
    "\n",
    "The embeddings can finally be used to perform predictions. The way and how you use them depends on the ML problem you want to solve. For instance, you want to perform node level predictions, you can simply use the node enbedding of a specific unlabelled node to obtain a prediction. Let's assume that this sample graph has 4 labelled nodes and 1 unlabelled node (white). It will simply use the embedding matrix of these nodes and preict the nodes label with it. If you want to perform graph label pedictions however,you will use all of the nodes embedding , combine them in a certain way amd get a representation of the whole graph.\n",
    "\n",
    "Alternatively, you can include pulling operations to iteratively compress the graph into a fixed size vector.\n",
    "\n",
    "This representation can then be used to run the prediction.\n",
    "\n",
    "similar nodes means nodes with similar feature or similar context will lead to similar nodes embeddings. Same way similar grapg will lead to similar graphs embedings using a GNNs.\n",
    "\n",
    "The size of the node embeddings is a hyperparameter and can differ from initial node feature size. Let's assume that the graph input is a molecule  and the adam feature vectorhave a size of 50.This means we have 50 properties such as the adam type or the number of protorns available for each node and the embedding have a size of 128, howevr ,these embedding values cannot directly be interpreted as they are artificial compound of the node and egde information within the graph. Finally, edge features can also be processed in a GNN and will be combuned into this node embeddings.within the graph NN we have several so called 'Message passing layers'.\n",
    "\n",
    "These are the core building blocks of GNNs. They are responsible for combining the nodes and edge information into the node embeddings on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c69456-c740-4617-9e24-54f19a0520e6",
   "metadata": {},
   "source": [
    "###  Understanding Graph Neural Networks | Part 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82cbd1a-18a4-40c7-b666-e43ee92686ec",
   "metadata": {},
   "source": [
    "#####  Understanding Graph Neural Networks and its Variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471897cf-b593-4f6a-8110-d08a55ed865d",
   "metadata": {},
   "source": [
    "+  How do Graph Neural Networks Work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759ab054-226b-41b8-9529-3b469ef7f61d",
   "metadata": {},
   "source": [
    "The graph information including node features and structural properties pass through message passing layers.These layers constructs the node embeddings that contains the knowlwdge about other nodes and edges in a compressed format.This is done by gathering the current node information of neighbor nodes combining it in certain ways to get a new enbeddings and updating node features of states to this embeddings. This approach is also called Graph convolution.It can be seen as an extention of convolution to graph data.\n",
    "\n",
    "The diagram shows image convolution on the left and graph convolution on the right. For images you simply slide on the learneable kunnels over the regular great structures of the pixels which extracts the most important information. This can also be seen as combining the information in a local area by using all the pixels in this neighborhood.\n",
    "\n",
    "For non Euclidean graph structures, this idea is extended as we simply use this information and nodes neighborhood and combine it into a new embedding record. We look at the'red' node in the graph, this simply means that the neighboring nodes share their current embeddings with it. This is done simultaneously for all the nodes. Sharing mechanism i alo called message passing as the state can be seen as many messages pasing back and forth between the nodes. Now let, have a complete example to better understand this idea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9762ad87-335b-47f8-a139-1b3a1f9ae26f",
   "metadata": {},
   "source": [
    "+ What is happening in the Mesage Passing Layers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920f2908-950c-4b34-8713-ffeace28160b",
   "metadata": {},
   "source": [
    "Let's assume the diagram above is our input graph in the following , we can see we have the yellow node with number 1,with the yellow node feature electron or state. This is the node we will focus on in the following.\n",
    "\n",
    "To update the node state,we collect information of the direct neighbors which means we perform the message passing,whta we end up with is the information about our current nodes state and the information about our neighbors node state.\n",
    "\n",
    "These states are usually denoted with age.Currently ,we are in time steps k, then we perform an aggregation on the neighbour state to combine their information.\n",
    "finally , we put our current state and combine neighbor information together to geta new state or enbeddding in layer k + 1. Note, how some of the feature infomation of the blue node enter into state of the yellow node.\n",
    "Now we updat our intertations in the graph .\n",
    "\n",
    "This message passing is done by all nodes and therefore ,we have new enbeddings for every nodes in our graph.The size of this new embedding is a hyperparameter.It depends on the graph data you use. As you can see the node with no 5 only holds information about the blue nodes and itself because it is green and blue.Currently yhis node doesnt know about the yellow node with the number 1, but this will change. Let's form another message passing step to see what happens . Actually ,we can perform several of this message passing steps which corresponds to the number of letters in the GNN. Again we use the current node embedding of our yellow node. Collect the state messages of its neighbors and aggregate them in some ways .if we update the yellow nodes embedding now we can see that some information about the green node passed into it.This means that node 1 knows something about node 5.But additionally in our example, every single node in the graph know something about all other nodes.This knowledge is stored in each of our node enbeddings . It contains the feature base as well as structural information about the node. Eventually we can use the embeddings to perform predictions,as it contains all information about the graph that we need,and this is the best idea of GNNs , we learn these embeddings by intuitively combining the node information in a local neighborhood.Intuitively means we first learnt something about the direct neighbors and about the neighbor's neighbors and so on.\n",
    "\n",
    "This local feature aggregation can be compare to learnable CNN kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda9f767-eb25-47a4-a3b2-3f6caebfd2b8",
   "metadata": {},
   "source": [
    "+ computation Graph Representation\n",
    "\n",
    "We can actually visualize how deep we dive into the graphs from each node perspective.This means we can undersatnd which neighbors and neighbor neighbors and so on ,we learn about.This is usually called the computation graph for specific node. When we structure our graph like the diagram above,we can automatically see which nodes are the direct neighbors of our yellow node. This means in the first layer of our message passing GNN, the yellow node incorperates information about the blue nodes. If we add the diret neighbors for each of these nodes, we can see the next layer. Two of our blue nodes are connected to blue and yellow and the 3rd blue node is connected to green.We can see that after 2 layers , the yellow node already contains the information about all nodes in the graph. The number of layers in  a GNN defines how many layers neighborhood hub will perform.The number of MP-layers is a hyperparameterand depends on the graph data we use. If you have small graphs such as smaller molecules, you can quickly learn all the informations in a few layers.The number of layers also depends on the learning task. Sometimes ,only a local area if the graph might be relevant for your predictions.\n",
    "\n",
    "+ Over-smoothing in GNNs\n",
    "\n",
    "Taking too many message passing layers in a GNN can also lead to a phenomenon called over-smoothing .\n",
    "\n",
    "In our previous example, the node embeddings contains most of the informations already after the second layer.If you keep combining this state over many more layers,you will not learn anything new but instead make all node states indistinguishable from each other .There already exists methods such as paranorms which can handle these issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad633312-b07d-48a6-bf9c-3ee8a85bec1e",
   "metadata": {},
   "source": [
    "+ Message Passing Update and Aggregate Functions\n",
    "\n",
    "Let's formulate the operations in a message passing layers more mathematically.\n",
    "The state update for a new  U, is mainly  performed using  the two already introduce operations, AGGREGATE and UPDATE\n",
    "\n",
    "\n",
    "\n",
    "hu^(k+1) = UPDATE^(k)(hu^(k), AGGREGATE^(k)({hv^(k),∀ V Ḕ  N (u)}))\n",
    "\n",
    "AGGREGATE uses the state of all direct neighbors of V of a node you and aggregate them on a specific way.\n",
    "\n",
    "UPDATE\n",
    "\n",
    "The update operation uses this current state in terms of k and combines it with the aggregates of neighbor state.\n",
    "\n",
    "If we think of our previous example, our node U is the yellow node and its neighbors are the 3 blue nodes from the diagram. We use their states in terms of k and combine them with the yellow state to get a new enbedding for the yellow node.This basic formula stattes the same for all variance of mmesaage passing neural networks.The only thing in which they are  different is how they perform the UPDATE and  AGGREGATE function.\n",
    "\n",
    "Many different operations have already been published in literature and besides simple Mean or Max operations, there are more advanced methods like Recurrent NN"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2cf98ab-f556-4e1a-be55-eaa1cc05e3a0",
   "metadata": {},
   "source": [
    "+ Some Examples\n",
    "\n",
    "+ Mean             +  Mean           \n",
    "\n",
    "+ Max               + Max             ->     GNN variants\n",
    "\n",
    "+ Neural Networks   + Normalized Sum  \n",
    "\n",
    "+ Recurrent NN      + Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f605e2d-27f2-4ad8-9917-40fbfc5356cb",
   "metadata": {},
   "source": [
    "+ GNN Variants\n",
    "\n",
    "One of the first famous work from Kipf and Welling(2016) Graph Convolutional Networks Uses two interesting ideas.\n",
    "\n",
    "First of all they aggregate the neighbor formation as a normalized sum of the state,additionally ,they incoporate the update operation into this aggeregation by adding a self loop for a particular node including it into the summation. It means update and aggregate are combined into one computation.\n",
    "\n",
    "\n",
    "hu^(k) = α ( self-loop\n",
    "           ( W^(k)   Σ  \n",
    "                    vEN(u)∪(u)    hu/ √|N(u)||N(v)|)\n",
    "                    \n",
    "                          sum of normalized embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a73860-fe40-418d-8909-d560e7aa3e3c",
   "metadata": {},
   "source": [
    "+ multi-layer-Perception as Aggregator,Zaheer et al.(2017)\n",
    "\n",
    "This uses multi layer perception . Basically fit forwar networks to perform the aggregate operations. This means that there are leaneable weights which can be optimized for the best aggregation of the neighour states.\n",
    "\n",
    "\n",
    "Aggregate message\n",
    "|\n",
    "mN(u)  = MLP0   (   Σ  MLPØ (hv)) send states through a \n",
    "     (trainable)   vEN(u)          MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f32f943-d928-4844-b65a-17d5db1a67e3",
   "metadata": {},
   "source": [
    "+ Graph Attention Networks, Velickovic et al.(2017)\n",
    "\n",
    "Graph attention mechanisms to GNns. This means that the importance of the features of the neighbor states is considered for the aggregation,as a result , the updated embeddings contains more informations about the important neigbor features.\n",
    "\n",
    "mN(u) =  Σ        αu,vhv\n",
    "        veN(u)   Attention weights\n",
    "        \n",
    "         αu,v  = Σ = exp(a^T[Whu O Whv]) /                                Σv1EN(u)exp(a^T[Whu O Whv*1])\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088fd010-085d-4aca-b41b-c3119eff985d",
   "metadata": {},
   "source": [
    "+ Gated Graph Neural Networks , Li et al.[2015]\n",
    "\n",
    "This use a recurrent unit to update the state intuitively over time.\n",
    "\n",
    "hu^(k) = GRU(hu^(k-1), m^(k)N(u))   Recurrent update of the state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2159ddc-656e-4cbe-97ec-6b3594b9adae",
   "metadata": {},
   "source": [
    "Besides these introduced variance, there exists many more literature. They just all use different approaches for the aggregate and update function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31788b3b-87d6-42d4-804b-e29536e30862",
   "metadata": {},
   "source": [
    "Further literature\n",
    "\n",
    "William L.Hamilton, Graph Representations learning book-https://www.cs.mcgill.ca/~wlh/grl book/files/GRL Book.pdf\n",
    "\n",
    "\n",
    "Graph Representation Learning\n",
    "\n",
    "Willian l. Hamilton\n",
    "McGul University 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546b120c-3abb-4808-a4b7-302f82f6c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ⓔ\tCircled Latin Small Letter E Symbol\n",
    "ℰ\tScript Capital E Symbol\n",
    "ℇ\tEuler Constant Symbol\n",
    "∃\tThere Exists Symbol\n",
    "Ḕ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fcb97c-e54e-480b-9cdd-94fb833058c3",
   "metadata": {},
   "source": [
    "### Understanding Graph Neural Networks | Part 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fd3efe-d806-4f1f-8ecf-c84fa463c642",
   "metadata": {},
   "source": [
    "+ Hands-on with Pytorch Geometric and RDKit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a1f25f-efdc-46b8-b2c4-ed9935c8fc7b",
   "metadata": {},
   "source": [
    "##### Installing Pytorch Geometric and RDKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10340fe1-1001-406f-ace2-1f53705608a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Installation will work on cuda version 10.1\n",
    "and run time change to GPU session\n",
    "check for this version 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab02296-ed95-4ae8-b9a7-ad9c22fd46a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "+ Pytorch Geometric =. Build Graph Neural Network\n",
    "\n",
    "+ RDKit => Handle Molecule Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9b3b0576-dff1-4357-8006-6feaa764e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4491c540-7f1a-47a7-ac84-2477ba362e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "ModuleNotFoundError: No module named 'torch'\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "ModuleNotFoundError: No module named 'torch'\n",
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# title\n",
    "# Check pytorch version and make sure you use a GPU kernel\n",
    "!python -c \"import torch; print(torch.__version__)\"\n",
    "!python -c \"import torch; print(torch.cuda)\"\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c6833a8d-f83e-44ad-b291-50c31ec2a2ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_11372/282726940.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_11372/282726940.py\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    if__name__--\"__main__\":\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#import rdkit\n",
    "logger.info(\"rdkit.{} installation finished!\",format(rdkit.__version__))\n",
    "\n",
    "if__name__--\"__main__\":\n",
    "    install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2b788874-83c1-4462-bb52-3b2bc245e1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - rdkit\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main/win-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/win-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "  - https://repo.anaconda.com/pkgs/msys2/win-64\n",
      "  - https://repo.anaconda.com/pkgs/msys2/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install rdkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3792aa-54ac-4552-bee9-9608cfab37bd",
   "metadata": {},
   "source": [
    "###### Background information on the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256d0c14-471b-4023-806c-1b8dee06c834",
   "metadata": {},
   "source": [
    "+ The dataset we are using comes from pythongemetric. e.g Amazon, knowledge graph etc. We will be using molecule dataset, it comes from a large collection of molecule data called molecule net. We will use one specific dataset called ESOL.\n",
    " ESOL. is a small dataset consisting of water solubility data for 1128 compounds.The dataset has been used to train models that estimate solubility directly from chemical structure as encoded in SMILES strings).Note ,that these structures don't include 3D coordinates,since solubility is a property of a molecule and not of its particular conformers.\"\n",
    " \n",
    " ML task: How are different molecules dissolving in water?\n",
    " \n",
    " \n",
    "#Source :https://www.diferencebetween.com/difference-between-solubilit:product/\n",
    "\n",
    "\n",
    "Solute\n",
    "\n",
    "i.  Solvent\n",
    "\n",
    "ii. Solution\n",
    "\n",
    "+ What it means is that we have a solute that is a molecule, we have a solvent which is water and we have a Solution which we want to predict,and this will be a regresion value which tells us how different molecules are dissolving in water.\n",
    "\n",
    "We have the data provided in a SMILES string .\n",
    "\n",
    "For instance, if you have a molecule for example,ibuprofen, you can represent the graph structure of this molecule also have a string and this string is called SMILES string . This includes all the adams like the carbon adam, oxygen . \n",
    "\n",
    "            Ibroprofen\n",
    "            \n",
    "cc(c)c<:<<<(<<:)(c)c(0)=0 \n",
    "\n",
    "This representation tells you how the molecules looks like. You should not directly use this representation because it is not unique and thre exists also different parameters on the SMILES string . The better way is to use the graph representation.\n",
    "\n",
    "+ Using the plan SMILES string as input is not suitable\n",
    "\n",
    "+ This will not consider the molecule structure but rather the grammer of the SMILES string \n",
    "\n",
    "+ The SMILES string  can be different for a molecule,depending on the notation(a unique molecule can have multiple SMILES strings)\n",
    "\n",
    "+ Chemical graphs however , are invariant to permutations -> Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28acefc-caaf-4e8b-94d6-b276fc5da0ec",
   "metadata": {},
   "source": [
    "##### looking into the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73f55e0-8ce4-4374-ba69-d48d9e9a3329",
   "metadata": {},
   "outputs": [],
   "source": [
    "We can simply load it using torchgeometric.dataset\n",
    "We import molecule net and specify th "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666bdbfd-7872-43f9-9c5a-ac2546267f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from torch_geometric.datasets import Molecule\n",
    "\n",
    "# load the ESOL dataset\n",
    "data = Moleculeeliet(root=\",\", name=\"EsOL\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5b0207-82b0-40b9-ab54-2ad9a05de4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating the dataset\n",
    "print(\"Dataset type: \", type(data))\n",
    "print(\"Dataset features: \", data.num_features)\n",
    "print(\"Dataset target: \", data.num_classes)\n",
    "print(\"Dataset length: \", data.len)\n",
    "print(\"Dataset sample: \", data[0])\n",
    "print(\"Dataset nodes: \", data[0].num_nodes)\n",
    "print(\"Sample  edges: \", data[0].num_edges)\n",
    "\n",
    "# edge_index = graph connections\n",
    "# smiles = molecules with its atoms\n",
    "# x = node features (32 nodes have each 9 features)\n",
    "# y = labls (dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b71cc0-3edb-4c2c-a048-8727ead4e655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating the features\n",
    "# Shape : [num_nodes, num_node_features]\n",
    "data[0].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949d2876-97f3-4ab8-839b-0afafe01f98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating the edges in sparse COO forest\n",
    "# it tells us the connection of the nodes\n",
    "# it is more efficient than Adjency matrix\n",
    "# Shape[2, num_edges]\n",
    "data[0].edge_index.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b12deb-3ab6-461e-8f92-a687df5d3808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the target value\n",
    "data[0].y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145c41b8-9c11-4a10-802a-d770a6c68e4f",
   "metadata": {},
   "source": [
    "In the following ,we will perform predictions based on the graph level. This means we have one y-label for the whole graph,as shown on the left\n",
    "image below . The right image would be node-level-predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af423f-a9bf-4393-922f-4b3e9c88c52f",
   "metadata": {},
   "source": [
    "##### Converting SMILES to RDKit molecules- Visualising molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be13fc8-7bac-4b6e-85ac-0626c54fd248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next , we want to have our SMILES molecules as graphs\n",
    "data[0][\"smiles\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c089d52b-2e74-4fc6-8630-9d1f8d8b10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use rdkit to generate features\n",
    "# If you have youe dataset ,you can use rdkit to generate features like the adam type,protons m=, the bon type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c078c046-11cd-45fa-ae21-85d1ddc59e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chew.Draw import IPythonConsole\n",
    "molecule = Chew.MolFromSmiles(data[0][\"smiles'])\n",
    "molecule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd00c502-f3ec-4448-a1d5-cf1ab2f8c0de",
   "metadata": {},
   "source": [
    "+ you can also obtain the features from this RDKit representation.\n",
    "\n",
    "+ It tells us everything we need to know e.g aton feature size,,, )edge,... \n",
    "\n",
    "In our case however,it is even easier as we have the information more explicitly given already in the dataset.\n",
    "\n",
    "+ Otherwise, we would calculate the node features from those atoms properties.\n",
    "\n",
    "For datasets containing SMILES representation, this would be the way to go."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1348a8c0-f0ac-45b1-ae97-311c95963d8c",
   "metadata": {},
   "source": [
    "##### Implementing the Graph Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1dd95f-a2b7-4c5e-b27b-c551704eac92",
   "metadata": {},
   "source": [
    "Building a Graph Neural Network works thesame way as building a Convolutional Neural Network, we simple add some layers\n",
    "The GCN extends torch.nn.module GCNConv expects\n",
    "\n",
    "+ in_channels = size of each input sample\n",
    "+ out_channels = Size of each output sample\n",
    "\n",
    "We apply three convolutional layers,which means we learn the information about 3 neighbors hops. After that we aply a pooling layer to combine the information of the individual nodes, we want to perform graph-level prediction.\n",
    "\n",
    "Always keep in mind that different learning problems (node,edge or graph prediction) require different GNN architectures.\n",
    "\n",
    "For example, for node-level prediction you will often encounter masks. For graph-level predictions on the other hand you need to combine the node embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc825ac-2d6b-4a75-93f6-fe8ea5aac0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import linear \n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, Topkpooling, global_mean_pool\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gap\n",
    "embeding_size = 64\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        # Init parent\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        \n",
    "        # GCN Layers\n",
    "        self.initial_conv = GCNConv(data.num_features, embedding_size)\n",
    "        self_conv1 = GCNConv(embedding_size, embedding_size)\n",
    "        self_conv1 = GCNConv(embedding_size, embedding_size)\n",
    "        self_conv1 = GCNConv(embedding_size, embedding_size)\n",
    "# Note, That,s the reason why we also pass the batch_index to the forward function\n",
    "# it will be used to select the relevant nodes for the pooling operation\n",
    "        # Output layer \n",
    "        # showing we want to perform regression\n",
    "        self.out = Linear(embedding_size*2, data.num_classess)\n",
    "        \n",
    "    def  forward(self, x, edge_index, batch_index):\n",
    "        # first Conv layer\n",
    "        hidden = self.initial_conv(x, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "        \n",
    "        # Other Conv layers\n",
    "        hidden = self.conv1(hidden, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "        hidden = self.conv2(hidden, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "        hidden = self.conv3(hidden, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Global pooling layer (stack different aggregation)\n",
    "        hidden = torch.cat([gap(hidden, batch_index),\n",
    "                            gap(hidden, batch_index)], dim=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Apply a final (linear) Classifier.\n",
    "        out = self.out(hidden)\n",
    "        \n",
    "        \n",
    "        return out, hidden\n",
    "        \n",
    "        \n",
    "        \n",
    "        modelGCN()\n",
    "        print(model)\n",
    "         print(\"Number of parameters: \", sum(p.numeI() for p in model.parameter()))                           \n",
    "                                    \n",
    "                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7db5894-ed9f-472b-bbc0-e66f001c2c31",
   "metadata": {},
   "source": [
    "+ Global Graph Pooling in GNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3f9110-0549-491d-bf3b-c8a7be7c6ae8",
   "metadata": {},
   "source": [
    "We want to perform Graph lable predictions, therefore we need to combine the node states of our graph into one representation. \n",
    "One first idea could be simply to paint , so basically,we would have the first node and the second node and so on. But the problem is that ,for one graph we might have 20 nodes and for another one we might have 50 nodes,so the size of this representation will be dynamic and will change from graph to graph.\n",
    "\n",
    "And therefore, we need a global pooling mechanism that can squeeze any number of node into one fixed presentation and here we used a combination of mean and max pooling. This means we take the mean of all of these nodes and we take the Max of all of these node features,then we can eventually concactinate the information of the mean pooling and the max pooling. All of our graph information stands embedded in this final representation. There exists more intelligent ways instead of mean and max.\n",
    "\n",
    "Another alternative is to perform the graph pooling. It means the input graph is reduced over time. Fist you start with 5 nodes , 4nodes and so on until you end up with the representation that contains all the information about the graph.\n",
    "\n",
    "For now ,we will simply pass the graph over the layers,perform the message passing,and in the final layers summarize all the information of the nodes features from the individual node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c355653-dd5b-4aa2-abd9-96a6d0b07725",
   "metadata": {},
   "source": [
    "+ We could also reduce the embeddings but as we have large molecules we use 64\n",
    "\n",
    "+ The more layers we add the more information we get about the graph\n",
    "\n",
    "+ For the regression problem ,we use a linear layer as the final output layer.\n",
    "\n",
    "+ We try to use not too many parameters as we only have ~1k sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a8269f-2c4a-4158-8c0a-abd6da7e3583",
   "metadata": {},
   "source": [
    "+ Binary Mask for Node-Level Predictions\n",
    "\n",
    "Incase ,you are working with node or edge level preictions, you might have encounterd binary masks. This means that for the training and the predictions, you dont have all of the nodes available.\n",
    "\n",
    "For example, for the training ,you will only have node 1, 2 and 4 available. And for the prediction ,you only want to perform on node 3 and 5.This is why you often encounter binary mask in these nodes and prediction problems. These masks basically tells you which node to use for each of the task.\n",
    "\n",
    "For example, if you want to perform predictions, you will use the mask to only get predictions for these two nodes . This is just a side node, so basically ,just use them to mask out the nodes you are not interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c533021d-a248-42a2-8195-f70a296a4b53",
   "metadata": {},
   "source": [
    "###### Training the GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82696b64-c391-4e3c-b6d4-bc817c042e44",
   "metadata": {},
   "source": [
    "First ,we define the loss function,an optimizer ,which is adam in our case, the we specify the learning rate for our training , Then we will also,then we will also use the GPU since is available. Finally, we will use data loader from torch geometric for batches traning, we then pass 80% of our data to training loader and 20% to test loader, and the batch size is 64,which means we have 64 molecules in each of these batches.\n",
    "For the data loader batch chart goemetric looks a little different.\n",
    "We performed 2000 epochs, form the output the result is decreasing and this is good fo us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af25f367-e447-4532-917a-2f9919008564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Root mean squared error\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.pararmeters(), Ir=0.0007)\n",
    "\n",
    "#use GPU for training\n",
    "device = torch.deice(\"cuda:0\" if torch.cuda.is_available() size \"cpu\"\n",
    "model = model.to(device)\n",
    "                     \n",
    "                     \n",
    "# Wrap data in a data loader\n",
    "data_size = len(data)\n",
    "MUM_GrAPHS_PER_BATCH = 64\n",
    "loader = DataLoader(data[:int(data_size = 0.8),\n",
    "                    batch_size=NUM_GRAPHS_PER_BATCH, shffle=True)\n",
    "test_loader = DataLoader(data[int(data_size * 0.8):],\n",
    "                         batch_size=NUM_GRAPHS_pER_BATCH< shuffle=True\n",
    "                         \n",
    "def train(data):\n",
    "# Enumerate over the data\n",
    "for batch in loader:\n",
    "# Use GPU                         \n",
    "batch.to(device)\n",
    "# Reset Gradient\n",
    "optimizer.zero_Grad()\n",
    "# passing the node features and the connection info\n",
    "pred , embedding = model(batch.x.float(), batch.edge_index, batch.batch)\n",
    "# Calculateing the loss and gradient\n",
    "loss = torch.sqrt(loss-fn(pred, batch.y))\n",
    "loss.backward()  \n",
    "# Update  using the gradients\n",
    "optimizer.step()\n",
    "return loss, embedding\n",
    "                         \n",
    "print(\"Starting training...\"\n",
    "lossess = []\n",
    "for epoch in range(2000):\n",
    "    loss, h = train(data)\n",
    "    lossess.append(loss)\n",
    "    if epoch % 100 -- 0:\n",
    "    print(f\"Epoch (epoch) | train_loss (loss)')  \n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0458e294-3328-4be1-a0a6-2185f8710404",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Visualizing the Train loss\n",
    "\n",
    "# Visualize learning (training loss)\n",
    "import seaborn as sns\n",
    "losses_float = [float(loss.cpu().detach().numpy()) for loss in losses]\n",
    "loss_indices = [1 for 1,1 in enumerate(losses_float)]\n",
    "plt = sns.lineplot(loss_indices, losses_float)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c203a4-b279-418a-8a29-f5494f173f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We observe that though it is decreasing , it is quite noisy so we might need to twist the learning rate\n",
    "# But overall, it is decreasing and that is what we want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da248cb3-c153-43f4-8440-060cf4ff8322",
   "metadata": {},
   "source": [
    "##### Get a test Prediction\n",
    "\n",
    "We can also check the test error using our test data loader. We anlyze one of the batches. On the left we have the real prediction and on the right the prediction of our moodel.\n",
    "\n",
    "Note ,Each entry =One Moleculesolubility\n",
    "(in total 64 for the whole batch)\n",
    "\n",
    "Overall the predictions worked well. some are very close msome a bit far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9e8049-79d5-4693-96f8-60fec72cfe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d8bb4a-fe15-4e67-b6e6-9ba343f85f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the results for one batch\n",
    "test_batch = next(iter(test_loader))\n",
    "with torch.no_grad():\n",
    "    test_batch.to(device)\n",
    "    pred, embed = model(test_batch.x.float(), test_batch.edge_index, test_batch.batch)\n",
    "    df = pd.DataFrame()\n",
    "    df[\"y_real\"] = test_batch.y.tolist()\n",
    "    df[\"y_pred\"] = pred.tolist()\n",
    "    df[\"y_real\"] = df[\"y_real\"].apply(lambda row: row[0])\n",
    "    df[\"y_real\"] = df[\"y_real\"].apply(lambda row: row[0])\n",
    "    df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40380cc1-e36f-4bf3-b1e0-c8587843ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize this\n",
    "\n",
    "plt = sns.scatterplot(data=df, x=\"y_real\", y=\"y_pred\")\n",
    "plt.set(xlim=(-7, 2))\n",
    "plt.set(ylim-(-7,2))\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402a5aa6-5eae-4700-a981-faaf4c944f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "Overall we have a good model with a small architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb68e099-2eaf-47b4-90db-ff5caefacd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "+ Improving  the model/ More to play around with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace03649-3a8b-42e8-9cf8-4bfdc1c41a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "For example you can add\n",
    "\n",
    "+ Dropouts\n",
    "\n",
    "+ Other (more intelligent)pooling layers (all layers here: https://pytorch-geometricreadthedocs.io/en/latest/modules/n.html#)\n",
    "                                          \n",
    "+ Global Pooling Layers\n",
    "\n",
    "+  Batch Normalization \n",
    "                                          \n",
    "+  More Mp layers\n",
    "                                          \n",
    "+  Other hidden stae sizes\n",
    "                                          \n",
    "+ Test metrics(test error) and Hyperparameter optimization\n",
    "                                          \n",
    "                                          \n",
    "                                          \n",
    "  https://github.com/rusty1s/pytorch_geometric /tree/master/examples                                       \n",
    "                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c70bbe-1520-4010-af2c-f2aa900eadb4",
   "metadata": {},
   "source": [
    "+ Batching with Graphs / what happens in the Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750ee575-9879-4ac0-8733-48846c4e516a",
   "metadata": {},
   "source": [
    "+ Batching is commonly used for deep learning for reasons such as training speed or also more stable conversion. Using graph data, batching appears to be a bit more complex as we have graph of different shapes. For example on e of them have 5 nodes and one has 6 nodes and so on.\n",
    "\n",
    "The way this is handled is by concatinating the node features in a large matrix. And additonally combining the individaul Adjency information into  a huge Adjency matrix.\n",
    "\n",
    "Basically ,the 67 molecules appears to be one large graph with the ginat Adjencies matrix. The trick here isnthat the individaul graph are disconnected in this Adjencies matrix and therefore no information will be passed between the graph but only within the graph. For example, the message passing for graph 1 only happens among this  this node featue vectors.\n",
    "\n",
    "The advantage of this approach is that we can simply input a large graph and get the updated node embedding or all the individaul graphs.\n",
    "\n",
    "To know more go to pyplot geometric documentation.\n",
    "Note that the data loader does some heavy work for us from the background."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe34751d-079d-4fc6-9f60-21cf72fac16d",
   "metadata": {},
   "source": [
    "#### Graphs and Network: Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aa783a-2fc8-4636-b66e-c4898d9d84da",
   "metadata": {},
   "source": [
    "1. Choose the correct term to match each definition: Lines or curves that connect vertices.\n",
    "\n",
    "Edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a269f2d-948f-44fb-af58-59c69cb599eb",
   "metadata": {},
   "source": [
    "2. An edge that begins and ends at the same vertex.\n",
    "loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77afa8ee-952c-4c43-9459-215e2e83dd6c",
   "metadata": {},
   "source": [
    "3. Links that connect the same two vertices to one another.\n",
    "\n",
    "multiple edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c6ed46-3d64-4a27-af76-3ce4e37ccb3c",
   "metadata": {},
   "source": [
    "4. When the edges have a numerical representation (to indicate length, time, capacity etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7880f16c-6084-4cb4-b931-8013ccf2fe3c",
   "metadata": {},
   "source": [
    "Wighted graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b6e3c9-355b-4056-9506-69a9c8cdf579",
   "metadata": {},
   "source": [
    "5. No arrows are shown on the edges.\n",
    "\n",
    "undirected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a42949-e0db-4880-baaf-a6775037eaca",
   "metadata": {},
   "source": [
    "6. An undirected and unweighted graph with no multiple edges.\n",
    "\n",
    "simple graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e43a18-f7b3-45c4-9d42-90801243bbd4",
   "metadata": {},
   "source": [
    "7. A sequence of vertices for which each vertex in the sequence is joined to the next vertex in the sequence by an edge\n",
    "\n",
    "walk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d41b3-9290-43dd-a34e-37208bf00bab",
   "metadata": {},
   "source": [
    "8. A walk that doesn’t finish at the starting vertex.\n",
    "\n",
    "open"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c7346c-2218-4b74-829d-e7cba82b8fdd",
   "metadata": {},
   "source": [
    "9. A walk that has no repeat use of edges or vertices (except perhaps to end at the starting vertex).\n",
    "\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a835f61-a09f-420f-aed7-1784d0465e6d",
   "metadata": {},
   "source": [
    " Every path is a trail.\n",
    "    \n",
    "    true\n",
    "    \n",
    "but a trail is not a path    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad47f5a-14fe-487c-936a-e03126d45ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
