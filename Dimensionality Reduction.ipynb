{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b0d5e7d-11a2-4c93-b887-8e44238cf013",
   "metadata": {},
   "source": [
    "### MODULE 4: BIG DATA, MACHINE LEARNING AND NATURAL LANGUAGE PROCESSING\n",
    "\n",
    "#### Week 12: Day 1 – Dimensionality Reduction \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cdc83c-7862-4022-b958-37c69d27ec7a",
   "metadata": {},
   "source": [
    "feature selection and feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b23a640-7d4b-48ca-ba6b-2391074d5a4a",
   "metadata": {},
   "source": [
    "Dimensionality reduction involves reducing the number of input variables or columns in modeling data. LDA is a technique for multi-class classification that can be used to automatically perform dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dd9b78-12c9-4c9b-9acf-8020f333ef27",
   "metadata": {},
   "source": [
    "Feature Elimination: we reduce the feature space by elimination feature. The advantages of the feature elimination method include simplicity and maintainability features. We’ve also eliminated any benefits those dropped variables would bring.\n",
    "\n",
    "Feature Extraction: PCA is a technique for feature extraction. So it combines our input variables in a specific way, then we can drop the “least important” variables while still retaining the most valuable parts of all the variables.\n",
    "\n",
    "When should I use PCA?\n",
    "\n",
    "1. Do you want to reduce the no. of variables, but are not able to identify variables to completely remove from consideration?\n",
    "\n",
    "2. Do you want to ensure your variables are independent of one another?\n",
    "\n",
    "3. Are you comfortable making your independent variable less interpretable?\n",
    "\n",
    "2.1.2: How Principle Component Analysis (PCA) work?\n",
    "We are going to calculate a matrix that summarizes how our variables all relate to one another.\n",
    "\n",
    "We’ll then break this matrix down into two separate components: direction and magnitude. we can then understand the direction of our data and its magnitude.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416836fe-c431-48a6-8858-9716fb0fde09",
   "metadata": {},
   "source": [
    "The following are the advantages of LDA:\n",
    "1. Reduces overfitting because of reduction in the number of features\n",
    "2. Model training can be expedited.\n",
    "§ Disadvantages of LDA\n",
    "There are three major disadvantages of LDA:\n",
    "1. Not able to detect correlated features\n",
    "2. Cannot be used with unsupervised or unlabeled data\n",
    "3. Some amount of information is lost when you reduce features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ee4951-f4f3-4062-82d7-25213585cd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dimensionality Reduction with PCA and LDA Using\n",
    "Sklearn\n",
    "Dimensionality reduction refers to reducing the number of features in a dataset in\n",
    "such a way that the overall performance of the algorithms trained on the dataset is\n",
    "minimally affected. With dimensionality reduction, the training time of statistical\n",
    "algorithms can be significantly reduced, and data can be visualized more easily\n",
    "since it is not easy to visualize datasets in higher dimensions.\n",
    "There are two main approaches used for dimensionality reduction: Principal\n",
    "Component Analysis (PCA) and Linear Discriminant Analysis (LDA). In this\n",
    "chapter, you will study both of them.\n",
    "10.1. Principal Component A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa2beb-ce5f-4cd3-ab1b-2ca0f460733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y Use PCA?\n",
    "The following are the advantages of PCA:\n",
    "1. Correlated features can be detected and removed using PCA\n",
    "2. Reduces overfitting because of reduction in the number of features\n",
    "3. Model training can be expedited.\n",
    "§ Disadvantages of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85175e4-1933-46c0-b6a4-ec12f58cf62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "are two major disadvantages of PCA:\n",
    "1. You need to standardize the data before you apply PCA\n",
    "2. The independent variable becomes less integrable\n",
    "3. Some amount of information is lost when you reduce features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7777f26c-d3f6-4b64-b0d8-aa4009a7652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dimensionality Reduction: Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097e07ae-5717-41b2-a420-c04861648d50",
   "metadata": {},
   "source": [
    "1. ___Dimensionality reduction________________________ is simply the process of reducing the dimension of\n",
    "your feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2783b8c-5167-4045-a8b3-d81b6123e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. An example of a feature set is ___Dataset___________________."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49769427-3a76-4aa7-888b-fa2aba80c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. _____________________ refers to all the problems that arise when working with\n",
    "data in the higher dimensions that did not exist in the lower dimensions.\n",
    "\n",
    "Curse of dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fcec8e-ef5a-4d57-9422-32531b40670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "e curse of dimensionality refers to various phenomena that arise when analyzing and organizing data in high-dimensional spaces that do not occur in low-dimensional settings such as the three-dimensional physical space of everyday experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9359512a-2812-4bf3-83b5-622f9dafd4fb",
   "metadata": {},
   "source": [
    "4. What is a major motivation for performing dimensionality\n",
    "reduction?\n",
    "\n",
    "Avoiding overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c1b0e8-30a1-4456-8781-4e7bf2dbc109",
   "metadata": {},
   "source": [
    "5. What is feature selection?\n",
    "\n",
    "Identifying and selecting relevant features for a sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2556f6fe-8b95-4972-93dd-139dd5e13e41",
   "metadata": {},
   "source": [
    ". Feature selection can be done either manually or programmatically. This statement is wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8234c6b0-cb0c-4893-9011-89ea30b2c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. Two programmatic methods for feature selection are?\n",
    "Variance threshold and univariate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566b2478-60b4-4c04-86a3-8a8bce8d0e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "Variance threshold and univariate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1eef97-0ece-4a5e-91bb-e9b774bef4e2",
   "metadata": {},
   "source": [
    "8. _Univariate________________________ feature selection examines each feature individually to determine the strength of the relationship of the feature with the response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d0ccc3-266f-4d2f-b673-d3b865dab2fd",
   "metadata": {},
   "source": [
    "Univariate feature selection examines each feature individually to determine the strength of the relationship of the feature with the response variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe003c5e-defd-41e6-8de0-156277503657",
   "metadata": {},
   "source": [
    "9. Which of these is NOT a type of linear dimensionality reduction methods?\n",
    "\n",
    "rincipal Component Analysis\n",
    "Factor Analysis\n",
    "Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49b9d78-adcd-486a-8163-23c581c578e2",
   "metadata": {},
   "source": [
    "10. Which of these is a type of non-linear dimensionality reduction methods?\n",
    "\n",
    "t-distributed Stochastic Neighbor Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dbe759-42f4-4683-b67c-de5f2a30c340",
   "metadata": {},
   "source": [
    "Kernel PCA, t-distributed Stochastic Neighbor Embedding (t-SNE), Multidimensional Scaling (MDS) and Isometric mapping (Isomap) are examples of non-linear dimensionality reduction methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e72df06-dab7-4556-9ffd-8c926dae037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster analysis groups observation according to the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf28bb8-23cc-46f7-8ed6-533e4b6dcc08",
   "metadata": {},
   "source": [
    "###\n",
    "‎Cluster analysis algorithms · Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters). It is a main task of exploratory data analysis, and a common technique for statistical data analysis, used in many fields, including pattern recognition, image analysis, information retrieval, bioinformatics, data compression, computer graphics and machine learning.‎Hierarchical clustering · ‎Dbscan"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61fa8052-e645-491c-a8be-1f6810a06cd7",
   "metadata": {},
   "source": [
    "eg of clustering K-means\n",
    "\n",
    "you must explore all possible options \n",
    "clistering skills is used mostly in data science\n",
    "\n",
    "Application of clusterring\n",
    "for a company\n",
    "market segmentation\n",
    "using  a scatter plot\n",
    "young people that spend alot\n",
    "young people who dont spend alot\n",
    "middle people who spend alot\n",
    "middle\n",
    "benefits\n",
    "explore data and identify patterns\n",
    "pleliminary step\n",
    "used to draw conclusion\n",
    "\n",
    "image segmentation\n",
    "\n",
    "To enable you have a better pictorial view\n",
    "16,777,216 photos\n",
    "\n",
    "object recognition\n",
    "\n",
    "it helps machines to identify the world around them"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8b15922-2a2d-4cfc-bf6b-bb58284e6601",
   "metadata": {},
   "source": [
    "difference between classification and clustering\n",
    "\n",
    "+ Classification and clustering are techniques used in data mining to analyze collected data. Classification is used to label data, while clustering is used to group similar data instances together based on similarities among them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d92d7eb-d4e8-4e1d-93ba-b054c8e9d1f9",
   "metadata": {},
   "source": [
    "You must know how to measure the distance between them called eucledian distance you need to fing the angle between them\n",
    "\n",
    "it is called centroid\n",
    "\n",
    "the square root of the sum of the square distance of the diferences\n",
    "\n",
    "we will be finding the distance between clusters\n",
    "\n",
    "\n",
    "centroid is the mid point of the line between them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f569e2d4-08c2-41b7-962a-2acc44a446e5",
   "metadata": {},
   "source": [
    "K-mean Clustering\n",
    "\n",
    "\n",
    "k-means clustering is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid), serving as a prototype of the cluster. This results in a partitioning of the data space into Voronoi cells. k-means clustering minimizes within-cluster variances (squared Euclidean distances), but not regular Euclidean distances, which would be the more difficult Weber problem: the mean optimizes squared errors, whereas only the geometric median minimizes Euclidean distances. For instance, better Euclidean solutions can be found using k-medians and k-medoids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfc9655-2dca-4e20-89a6-8451038ea228",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clustering is used in unsupervised learning\n",
    "\n",
    "classification is used in surpervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1081e3-84e4-4830-9910-69526880147e",
   "metadata": {},
   "source": [
    "Application of clustering \n",
    "\n",
    "K-means clustering \n",
    "k is the no\n",
    "choose the number of clusters\n",
    "specify  the cluster seeds\n",
    "\n",
    "assign each point to a centoid ie closert to the seed\n",
    "adjust the centoid\n",
    "\n",
    "recalculate the centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3301b9e7-2556-4ef0-b0e6-e8eb0f635ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Unsupervised learning\n",
    "Clustering \n",
    "dimentionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474208ce-3124-47dc-8872-16607a029aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "itirative means repeatitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c482def-18dc-4e39-b243-9518491a077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k-means has two types\n",
    "\n",
    "elbow method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a45904-8a40-4287-8f9c-e88d822e557d",
   "metadata": {},
   "source": [
    "A row is a horizontal alignment of data, while a column is vertical. D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d3256-5480-4a26-85dd-35975c625ca5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aed4b78-a09c-47ed-9fa3-2bd8563800a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf5c57e4-52f3-4297-82c9-8c22cbc911b0",
   "metadata": {},
   "source": [
    "##### K-means Clustering: Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe96a64-4c63-488f-8251-c1d4e3339729",
   "metadata": {},
   "source": [
    "1. The goal of clustering a set of data is to ___________________."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5060e43-20be-46e9-9e8d-ea92f0211a13",
   "metadata": {},
   "source": [
    "ans Divide them into groups of data that are near each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b21622b-1012-42b3-8929-09038880e87d",
   "metadata": {},
   "source": [
    "The goal of clustering is to find distinct groups or “clusters” within a data set. Using a machine language algorithm, the tool creates groups where items in a similar group will, in general, have similar characteristics to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfa6bb1-cab8-4a26-8db8-f96ed9cbde91",
   "metadata": {},
   "source": [
    "2. . The k-means algorithm ____________________________. Choose all that apply."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4033c5d-f2a6-4881-a99f-ab49f1a64159",
   "metadata": {},
   "source": [
    "ans.\n",
    "\n",
    "Can converge to different final clustering, depending on initial choice of representatives\n",
    "\n",
    "Is widely used in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d3eb0-d9ef-428e-961c-378630a96824",
   "metadata": {},
   "source": [
    "The K-means algorithm can converge to different final clustering results, depending on initial choice of representatives. To avoid K-means getting stuck at a bad local optima, we should try using multiple randon initialization. The centroids in the K-means algorithm may not be any observed data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9385cf3c-16bc-4706-a204-47d1b8a1e492",
   "metadata": {},
   "source": [
    ". The choice of k, the number of clusters to partition a set of data into ___\n",
    "\n",
    "ans. Depends on why you are clustering the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9006a53d-f832-417b-88ef-711c605d32c2",
   "metadata": {},
   "source": [
    "4. Which of the following statements about the K-means algorithm are correct?\n",
    "\n",
    "\n",
    "ans :\n",
    "\n",
    "\n",
    "The K-means algorithm is sensitive to outliers.\n",
    "\n",
    "The centroids in the K-means algorithm may not be any observed data points.\n",
    "\n",
    "\n",
    "The centroids in the k-means algorithm may not be any observed data points. True. Because the centroids are simply the average of all points in a cluster, this may not be a point in the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8015a07a-277e-4cef-aa9b-d9675753a136",
   "metadata": {},
   "source": [
    "For different initializations, the K-means algorithm will definitely give the same clustering results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d654d35a-9cec-4c15-9fc2-30fc3814ef0e",
   "metadata": {},
   "source": [
    "Given kmeans iterative nature and the random initialization of centroids at the start of the algorithm, different initializations may lead to different clusters since kmeans algorithm may stuck in a local optimum and may not converge to global optimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc004db-3d01-4195-9035-de135ae9d44e",
   "metadata": {},
   "source": [
    "“K-means can't handle non-convex sets”. Convex sets: In Euclidean space, an object is convex if for every pair of points within the object, every point on the straight line segment that joins them is also within the object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec54e7e-5ef1-4df8-a62c-7d1c5110a64f",
   "metadata": {},
   "source": [
    "5. Considering the K-median algorithm, if points (0, 3), (2, 1), and (-2, 2) are the only points which are assigned to the first cluster now, what is the new centroid for this cluster?\n",
    "\n",
    "\n",
    "ans. 0,2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ef28c7-0068-42c0-8132-75d663c4841a",
   "metadata": {},
   "source": [
    "6. Considering the K-means algorithm, after current iteration, we have 3 centroids (0, 1) (2, 1), (-1, 2). Will points (2, 3) and (2, 0.5) be assigned to the same cluster in the next iteration?\n",
    "\n",
    "Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c69ad6-c0b3-4fb6-b01c-db754911306b",
   "metadata": {},
   "source": [
    "7. The Iris dataset contains information about Iris setosa and versicolor. What is the Euclidean distance between these two objects?\n",
    "\n",
    "\n",
    "ans 2.8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99cec81-081a-45b5-b9bb-e595ca6a24d5",
   "metadata": {},
   "source": [
    ". Which of the following statements are true? Choose all that apply."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24faf24-b3a7-46ae-9cd9-357bd4b00095",
   "metadata": {},
   "source": [
    "Answer ;\n",
    "\n",
    "Graphs, time-series data, text, and multimedia data are all examples of data types on which cluster analysis can be performed.\n",
    "\n",
    "Agglomerative clustering is an example of a hierarchical and distance-based clustering method.\n",
    "\n",
    "When dealing with high-dimensional data, we sometimes consider only a subset of the dimensions when performing cluster analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ef15c8-767f-444a-8141-b2110c38fe6b",
   "metadata": {},
   "source": [
    "9. Which of the following statements are true?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83dc054-67e7-4910-97e5-65dc1739b238",
   "metadata": {},
   "source": [
    "ans.  \n",
    "Clustering analysis in unsupervised learning since it does not require labeled training data.\n",
    "\n",
    "Clustering analysis has a wide range of applications in tasks such as data summarization, dynamic trend detection, multimedia analysis, and biological network analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a1c9c7-4be1-4c9e-996d-016639685920",
   "metadata": {},
   "source": [
    "What are the applications of clustering analysis?\n",
    "\n",
    "Clustering analysis is broadly used in many applications such as market research, pattern recognition, data analysis, and image processing.\n",
    "\n",
    "Clustering can also help marketers discover distinct groups in their customer base. And they can characterize their customer groups based on the purchasing patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6e46dd-bf7d-41ed-a06d-facfe7e55de9",
   "metadata": {},
   "source": [
    "It is impossible to cluster objects in a data stream. We must have all the data objects that we need to cluster ready before clustering can be performed. False.\n",
    "\n",
    "This is false because clustering algorithms can be adapted to perform clustering in a streaming fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb76e68-b69c-4e63-be7d-45c761d64693",
   "metadata": {},
   "source": [
    "10. What are some common considerations and requirements for cluster analysis?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ans\n",
    "\n",
    "\n",
    "We need to consider how to incorporate user preference for cluster size and shape into the clustering algorithm.\n",
    "\n",
    "In order to perform cluster analysis, we need to have a similarity measure between data objects.\n",
    "\n",
    "We need to be able to handle a mixture of different types of attributes (e.g., numerical, categorical).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17b0959-ea05-4213-891b-865d1a1be12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "+ Applications of clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a9ba3c-4c57-42e5-911a-08200efa4887",
   "metadata": {},
   "source": [
    "There are 7 examples of clustering algorithms in action.\n",
    "\n",
    "Identifying Fake News. Fake news is not a new phenomenon, but it is one that is becoming prolific. ...\n",
    "Spam filter. ...\n",
    "Marketing and Sales. ...\n",
    "Classifying network traffic. ...\n",
    "Identifying fraudulent or criminal activity. ...\n",
    "Document analysis. ...\n",
    "Fantasy Football and Sports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c9d76e-44ee-42df-9410-3d826222811c",
   "metadata": {},
   "source": [
    "types of clustering algorithm\n",
    "\n",
    "partitioned based clustering\n",
    "\n",
    "relatively efficient\n",
    "eg k means k median, fuzzy c -means\n",
    "\n",
    "\n",
    "+ Hierachical clustering \n",
    "produces trees of clusters\n",
    "e.g Agglomerative ,Divisive \n",
    "\n",
    "Density based clustering \n",
    "produces arbitrary shaped clusters \n",
    "e.g DBSCAN algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e820a383-14c4-4b9b-8250-9f8c5bfef4e4",
   "metadata": {},
   "source": [
    "+  Hierachical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd5af9-dc9c-42ea-a3a9-87b013194347",
   "metadata": {},
   "source": [
    "builds a hierachy of clusters where each node is a cluster consists of the clusters of its daughter nodes.\n",
    "\n",
    "It has two startegies \n",
    "\n",
    "Divisive\n",
    "you start with al observations in a llarge cluster and break it dowm into smaller pieces. it can also be defined as dividing the cluster of dividing cluster\n",
    "\n",
    "Agglomerative\n",
    "\n",
    "It is the opposite of divisive , it is button up where each observation starts in its own cluster and pairs as clusters are matched together as they move up the hierachy.\n",
    "\n",
    "Agglomeration means to emmasss or colllect things. this approach is more popular among data scientist\n",
    "\n",
    "E.g if we want to cluster 6 cities in America based on their distances from one another.\n",
    "\n",
    "hierarical clustering is represented as a dendrogram ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e96a1bb-7a50-4dc4-ad4a-e836a0d9ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "Why Use Hierarchical Clustering?\n",
    "Hierarchical clustering has the following advantages:\n",
    "1. Unlike K Means clustering, for hierarchical clustering, you do not have to sp\n",
    "the number of centroids clustering.\n",
    "2. With dendrograms, it is easier to interpret how data has been clustered.\n",
    "Disadvantages of Hierarchical Clustering Algorithm\n",
    "The following are some of the disadvantages of the hierarchical clustering\n",
    "algorithm:\n",
    "1. Doesn’t scale well on unseen data.\n",
    "2. Has higher time complexity compared to K Means clustering.\n",
    "3. Difficult to determine the number of clusters in case of a large dataset.\n",
    "In the next section, you will see how to perform agglomerative clusteri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d1fb8e-cb29-48a9-9dc1-a3dc6b1a06c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93de9c9-f4a3-4c91-b9ee-e8ef2e65aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Hierarchical Clustering: Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda760c1-5a19-4bc4-b687-66c404b48b71",
   "metadata": {},
   "source": [
    "1. Which of the following clustering type has characteristic shown in the below figure?\n",
    "\n",
    "\n",
    "hierachical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069be357-a05a-4944-a003-c37e056998ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Point out the correct statement.\n",
    "\n",
    "Hierarchical clustering is also called HCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a427d5a4-bfe2-4f16-96ee-88819769a60a",
   "metadata": {},
   "source": [
    "The choice of an appropriate metric will influence the shape of the clusters, as some elements may be close to one another according to one distance and farther away according to another.\n",
    "he choice of an appropriate metric will influence the shape of the clusters\n",
    "Hierarchical clustering is also called HCA\n",
    "In general, the merges and splits are determined in a greedy manner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b499b6-5624-40e3-a384-a221fe3a69f1",
   "metadata": {},
   "source": [
    "3. Which of the following is finally produced by Hierarchical Clustering?\n",
    "\n",
    "Tree showing how close things are to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6c3097-f607-4dd2-9cbc-4ad5a44715d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb6ea11-e61b-4956-a4d2-5cc0b0ff2bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final estimate of cluster centroids\n",
    "Tree showing how close things are to each other\n",
    "Assignment of each point to clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7fe345-bee5-4546-8b29-931a624267c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Which of the following is required by K-means clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eab272-7b5b-4f25-b5bd-4a4762ed3bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Defined distance metric\n",
    "Number of clusters\n",
    "Initial guess as to cluster centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e908979c-d13d-4f0d-a979-92be6d5a42d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "5.Which of the following combination is incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffdaef4-b887-44f8-90b0-88d5a00d218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Continuous – euclidean distance\n",
    "Continuous – correlation similarity\n",
    "Binary – manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706a305b-34bf-43e9-9c15-b9de25daa7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree showing how close things are to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a1c31a-5863-4839-ac58-d6bf44cb6116",
   "metadata": {},
   "outputs": [],
   "source": [
    "08173631392"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911eb4d6-96b4-4a61-b51f-27fa3d0ae6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph\n",
    "\n",
    "directed\n",
    "undirected\n",
    "\n",
    "Weighted graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9461f519-e8e2-4e98-8772-02ac1fd13382",
   "metadata": {},
   "source": [
    "● Weighted Graphs\n",
    "Many graphs can have edges containing a weight associated to\n",
    "represent a real world implication such as cost, distance, quantity \n",
    "\n",
    "\n",
    "Weighted graphs could be either directed or undirected graphs.\n",
    "The one we have in this example is an undirected weighted graph.\n",
    "The cost or distance from node green to orange and vice versa is 3.\n",
    "We could represent this relationship as a triplet like (u, v, w)\n",
    "which shows from where the edge is coming in, where it goes and\n",
    "the cost or distance between the two nodes. Like our previous\n",
    "example, if you want to travel between two cities, say city green and\n",
    "orange, we would have to pay off a cost of 3$ or in other terms, we\n",
    "would have to drive 3 miles. These metrics are self-defined and\n",
    "could be changed according to the situations. For a more\n",
    "elaborated example, consider you have to travel to the city pin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5978a80c-39dc-419c-8785-581f1ab13687",
   "metadata": {},
   "source": [
    "special graph\n",
    "\n",
    "tree\n",
    "\n",
    "The most important type of special graph is a tree. It’s an\n",
    "undirected graph with no cycles. Equivalently, it has N nodes andN — 1 edge\n",
    "\n",
    "\n",
    "● Rooted Tree\n",
    "A rooted tree is a tree with a designated root node where all other\n",
    "nodes are either coming towards the root or going away from the\n",
    "root\n",
    "\n",
    "The node which is in red color is the root node. The leftmost tree is\n",
    "called an In-tree because all other nodes are coming towards the\n",
    "root node. The two other trees are Out-trees, because all other\n",
    "nodes are going away from the root."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992412f1-490c-4139-9dd4-4e57a2297ed4",
   "metadata": {},
   "source": [
    "● Directed Acyclic Graphs (DAGs)\n",
    "\n",
    "DAGs are directed graphs with no cycles. These graphs play\n",
    "an important role in representing structures with dependencies\n",
    "such as schedulers and compilers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79643c1c-0d1e-4ce1-82dc-b51b3fa08b98",
   "metadata": {},
   "source": [
    "● Bi-Partite Graphs\n",
    "\n",
    "A Bi-Partite Graph is a one whose vertices could be divided into two\n",
    "disjoint sets, say U and V, where each edge in the graph connects\n",
    "the vertices between U and V. Another similar definition to a BiPartite Graph is that the graph would be two colourable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8b2191-fac0-413a-9b98-6cbef3ef2f6a",
   "metadata": {},
   "source": [
    "Complete Graph\n",
    "\n",
    "We call a graph Complete iff, each pair of vertices has a unique edge\n",
    "connecting between them. A complete graph with n vertices is\n",
    "denoted as Kn.\n",
    "\n",
    "Complete graphs are considered to be the worst case graphs\n",
    "because of the number of edges to be traversed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8751562a-4850-4ffb-90fb-e1ab5add233a",
   "metadata": {},
   "source": [
    "Representation of Graphs\n",
    "\n",
    "\n",
    "Adjacency Matrix\n",
    "\n",
    "The efficient way is to use a matrix of size NxN where N is the\n",
    "number of nodes. We call this matrix an adjacency matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bad185-fa79-4235-8537-a388eb3a7384",
   "metadata": {},
   "source": [
    "Adjacency Lists\n",
    "\n",
    "Another important structure we use to store the node and edge\n",
    "information is an adjacency list. This is a map from nodes to lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c69588-d71d-48ee-9d47-93c7ae75bffd",
   "metadata": {},
   "source": [
    "● Edge Lists\n",
    "\n",
    "AN edge list is a way to represent a graph simply as an unordered\n",
    "list of edges. Assume the notation for any triplet (u, v, w) means:\n",
    "“ the cost from u to v is w”.\n",
    "\n",
    "The edge list is given in the right hand side corresponding to the\n",
    "directed weighted graph on the left hand side. Each pair in the list\n",
    "shows edge information between two nodes and associated weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ac55c3-d96e-486d-ba9a-c4c1755de23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "649d9889-9bf2-4ab8-91a5-066d884c8d61",
   "metadata": {},
   "source": [
    "Graphs size and shape can change\n",
    "\n",
    "isomophin two graphs that use thesame can also look diffent\n",
    "\n",
    "the structure of graph is non Eucledian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22357473-8f44-4590-a4ba-9818c5539d79",
   "metadata": {},
   "source": [
    "SCII, stands for American Standard Code for Information Interchange. It is a 7-bit character code where each individual bit represents a unique character. This page shows the extended ASCII table which is based on the Windows-1252 character set which is an 8 bit ASCII table with 256 characters and symbols. It includes all ASCII codes from standard ASCII, and it is a superset of ISO 8859-1 in terms of printable characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab42c16-b561-4c4b-af50-897bda614d76",
   "metadata": {},
   "source": [
    "Epoch comprise of one or more batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe34751d-079d-4fc6-9f60-21cf72fac16d",
   "metadata": {},
   "source": [
    "#### Graphs and Network: Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d456d8e0-a1c0-4822-acbe-f0abcec502ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Choose the correct term to match each definition: Lines or curves that connect vertices.\n",
    "\n",
    "Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258eb74a-8208-4bea-81fc-7b968cce3404",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. An edge that begins and ends at the same vertex.\n",
    "loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3569eb32-38b5-4fdf-9f25-4bf868399703",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Links that connect the same two vertices to one another.\n",
    "\n",
    "multiple edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb5ac1-a376-4633-90aa-8040d3c16e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. When the edges have a numerical representation (to indicate length, time, capacity etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdcc949-6c21-49f2-b8cf-d466d359e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wighted graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983b9165-86ad-4006-a9a7-dd56b2483258",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. No arrows are shown on the edges.\n",
    "\n",
    "undirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d6f71-f760-4a80-87b7-569f3f27d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. An undirected and unweighted graph with no multiple edges.\n",
    "\n",
    "simple graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b53e6c-5faa-4469-96d6-0c73c43c1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. A sequence of vertices for which each vertex in the sequence is joined to the next vertex in the sequence by an edge\n",
    "\n",
    "walk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7768c1f6-f12a-4b77-a589-eeea808fdc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. A walk that doesn’t finish at the starting vertex.\n",
    "open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfb273d-e9ef-4cb3-8f48-27309359423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. A walk that has no repeat use of edges or vertices (except perhaps to end at the starting vertex).\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23cdccf-712f-4d7e-8c3f-67fd7c5450b3",
   "metadata": {},
   "outputs": [],
   "source": [
    " Every path is a trail.\n",
    "    \n",
    "    true\n",
    "but a trail is not a path    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e4202b-90cc-4071-9b86-6f2b30da4cac",
   "metadata": {},
   "source": [
    "### Week 13 day 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42365165-ea15-4460-a2e2-fda6c2fcf5b3",
   "metadata": {},
   "source": [
    "### Time Series Forecasting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7ac0b1-d7d0-4e38-8846-b3e65b1145e2",
   "metadata": {},
   "source": [
    "Time series forecasting occurs when you make scientific predictions based on historical time stamped data. It involves building models through historical analysis and using them to make observations and drive future strategic decision-making. An important distinction in forecasting is that at the time of the work, the future outcome is completely unavailable and can only be estimated through careful analysis and evidence-based priors."
   ]
  },
  {
   "cell_type": "raw",
   "id": "74169816-29f7-410a-81e6-719e0c8b479b",
   "metadata": {},
   "source": [
    "Types of models to use\n",
    "\n",
    "ARIMA\n",
    "moving average( PACF)\n",
    "\n",
    "auto regressive and intergrated moving average ( ACF for moving average)\n",
    "\n",
    "base line model \n",
    "you can check whether base line or ARIMA model is better \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03295540-6753-40b3-af28-25cb408491ef",
   "metadata": {},
   "source": [
    "Diference between machine learning and time series. time series has to do with trends and seasons and it has just two few columns and it does not deal on fependent and independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad47f5a-14fe-487c-936a-e03126d45ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e43aa0a-26c5-4476-9931-35a47d9ab014",
   "metadata": {},
   "source": [
    "install the preiction on a list so as to test it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b02ea-da3c-479a-ae32-758e55d1d8ec",
   "metadata": {},
   "source": [
    "trends are patterns , we have upward and downward trend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fa2231-8b41-466d-a219-4afe3bb4fcfe",
   "metadata": {},
   "source": [
    "size dont have a bracket \n",
    "sampoo.size and shape are characterictics of the data,so they dont carry bracket\n",
    "\n",
    "Sampoo.describe() is a function and you can manipulate it. \n",
    "\n",
    "We smoothen our time series using the moving average\n",
    "\n",
    "it uses the rolling function to achieve it\n",
    "\n",
    "for e.g you choose 5 windows, ti will find the average of the 5 and plot the average as the point so as to have a smoother time series.\n",
    "\n",
    "shift () shift the index by desired number  using the base line model. base model is an initial model, when we now access other models we can now choose to accept it or reject it.\n",
    "\n",
    "We concatinate ie combine \n",
    "\n",
    "THe drop any function is temporary, if you want it to be permament, you need to put inplace=True else if you run the code again ,it will return to the old code.\n",
    "\n",
    "we now import the mean square metrics to calculate the error\n",
    "\n",
    "We will implement the square root to give us our error\n",
    "\n",
    "Auto regressive intergrated moving average (ARIMA)\n",
    "\n",
    "ACF : Auto regression\n",
    "\n",
    "PCAF  : Moving Average\n",
    "intergrated \n",
    "p auto regression\n",
    "d iis the degree of ifferential\n",
    "\n",
    "Moving average is the auto correllation\n",
    "in a situation you dont know the pvalue to use , you can use a range 0-5 ,6-10 and you put it in a loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2504868b-e9e2-46d0-9397-8a993b11b997",
   "metadata": {},
   "source": [
    "A baseline model is essentially a simple model that acts as a reference in a machine learning project. Its main function is to contextualize the results of trained models. Baseline models usually lack complexity and may have little predictive power. Regardless, their inclusion is a necessity for many reasons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5816d92e-d515-4d89-8957-9c3efe7d24ab",
   "metadata": {},
   "source": [
    "The CONCAT function combines the text from multiple ranges and/or strings, but it doesn't provide delimiter or IgnoreEmpty arguments. CONCAT replaces the CONCATENATE function. However, the CONCATENATE function will stay available for compatibility with earlier versions of Excel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
